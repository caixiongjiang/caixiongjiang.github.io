<!DOCTYPE html>
<html><head>
<title>有限资源下的预训练方案</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="穷孩子的深度学习玩法">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="有限资源下的预训练方案" />
<meta property="og:description" content="穷孩子的深度学习玩法" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%9C%89%E9%99%90%E8%B5%84%E6%BA%90%E4%B8%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%A1%88/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2022-10-13T18:18:05+08:00" />
<meta property="article:modified_time" content="2022-10-14T09:19:06+08:00" />












<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="mailto:nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2024 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%9c%89%e9%99%90%e8%b5%84%e6%ba%90%e4%b8%8b%e7%9a%84%e9%a2%84%e8%ae%ad%e7%bb%83%e6%96%b9%e6%a1%88" onclick="onNavClick(`#有限资源下的预训练方案-nav`)" id="有限资源下的预训练方案-nav">
									有限资源下的预训练方案
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e9%a2%84%e8%ae%ad%e7%bb%83%e7%9a%84%e4%b8%a4%e7%a7%8d%e6%96%b9%e6%a1%88" onclick="onNavClick(`#预训练的两种方案-nav`)" id="预训练的两种方案-nav">
									预训练的两种方案
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#swin_transfomer%e7%9a%84%e8%ae%ad%e7%bb%83%e6%96%b9%e6%a1%88" onclick="onNavClick(`#swin_transfomer的训练方案-nav`)" id="swin_transfomer的训练方案-nav">
									swin_Transfomer的训练方案
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%9c%89%e9%99%90%e8%b5%84%e6%ba%90%e4%b8%8b%e7%9a%84%e9%a2%84%e8%ae%ad%e7%bb%83%e6%96%b9%e6%a1%88" onclick="onNavClick(`#有限资源下的预训练方案-nav`)" id="有限资源下的预训练方案-nav">
									有限资源下的预训练方案
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e9%a2%84%e8%ae%ad%e7%bb%83%e7%9a%84%e4%b8%a4%e7%a7%8d%e6%96%b9%e6%a1%88" onclick="onNavClick(`#预训练的两种方案-nav`)" id="预训练的两种方案-nav">
									预训练的两种方案
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#swin_transfomer%e7%9a%84%e8%ae%ad%e7%bb%83%e6%96%b9%e6%a1%88" onclick="onNavClick(`#swin_transfomer的训练方案-nav`)" id="swin_transfomer的训练方案-nav">
									swin_Transfomer的训练方案
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img_title.jpg')"
                    
                
            >
                <div class="post-title">
                    有限资源下的预训练方案
                    
                    <div class="post-subtitle">
                        穷孩子的深度学习玩法
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2022-10-13 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[深度学习]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/deep_learning">Deep_learning</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            32 min
                            
                            39 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <p>其实有一个月没更新了！因为之前做的实验有了一丢丢成果，所以花了半个月时间写了一篇论文，试投了sci 4区的期刊，祝自己好运吧！</p>
<p>然后这是我新研究的方向就是swin transformer系列分割模型，先来做个最基本的工作！</p>
<h3 id="有限资源下的预训练方案">有限资源下的预训练方案</h3>
<p>最近在使用swin_Transformer的骨干网络模型做图像分割，但该骨干网络又十分依赖于预训练。</p>
<h4 id="预训练的两种方案">预训练的两种方案</h4>
<p>第一种就是直接拿swin_Transformer的图像分类网络在ImageNet_1k和ImageNet_22k的数据集直接的预训练权重，直接载入你的模型和目标数据进行训练。（一般需要先锁权重让剩余的网络参数迭代一下，再解锁进行迭代）</p>
<p>第二种就是拿你组建好的图像分割模型在分割数据集（例如VOC2012BST，或者更大的ADE20k数据集）上进行预训练，然后将得到的权重加载到你的目标数据集上进行迭代。</p>
<h4 id="swin_transfomer的训练方案">swin_Transfomer的训练方案</h4>
<p>首先先下载swin_Transformer的预训练权重，包括两个input_image_size(224$\times$224,384$\times$384)，4个model_size(Swin_T,Swin_S,Swin_B,Swin_L)都有在ImageNet1k和ImageNet22k的预训练权重。</p>
<p>预训练权重地址(在release的v1.0.0和v1.0.8):<a href="https://github.com/SwinTransformer/storage/releases/">https://github.com/SwinTransformer/storage/releases/</a></p>
<p>首先构建分割网络，swin_TransUnet</p>
<p>Swin_transformer.py(对源码进行微调，加了3个输出特征图):</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">172
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">173
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">174
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">175
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">176
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">177
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">178
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">179
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">180
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">181
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">182
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">183
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">184
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">185
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">186
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">187
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">188
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">189
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">190
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">191
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">192
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">193
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">194
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">195
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">196
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">197
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">198
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">199
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">200
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">201
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">202
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">203
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">204
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">205
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">206
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">207
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">208
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">209
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">210
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">211
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">212
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">213
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">214
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">215
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">216
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">217
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">218
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">219
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">220
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">221
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">222
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">223
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">224
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">225
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">226
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">227
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">228
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">229
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">230
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">231
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">232
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">233
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">234
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">235
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">236
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">237
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">238
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">239
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">240
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">241
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">242
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">243
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">244
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">245
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">246
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">247
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">248
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">249
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">250
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">251
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">252
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">253
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">254
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">255
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">256
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">257
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">258
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">259
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">260
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">261
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">262
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">263
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">264
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">265
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">266
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">267
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">268
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">269
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">270
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">271
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">272
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">273
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">274
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">275
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">276
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">277
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">278
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">279
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">280
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">281
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">282
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">283
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">284
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">285
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">286
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">287
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">288
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">289
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">290
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">291
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">292
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">293
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">294
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">295
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">296
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">297
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">298
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">299
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">300
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">301
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">302
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">303
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">304
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">305
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">306
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">307
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">308
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">309
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">310
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">311
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">312
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">313
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">314
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">315
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">316
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">317
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">318
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">319
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">320
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">321
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">322
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">323
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">324
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">325
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">326
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">327
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">328
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">329
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">330
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">331
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">332
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">333
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">334
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">335
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">336
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">337
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">338
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">339
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">340
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">341
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">342
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">343
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">344
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">345
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">346
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">347
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">348
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">349
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">350
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">351
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">352
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">353
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">354
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">355
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">356
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">357
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">358
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">359
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">360
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">361
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">362
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">363
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">364
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">365
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">366
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">367
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">368
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">369
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">370
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">371
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">372
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">373
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">374
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">375
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">376
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">377
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">378
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">379
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">380
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">381
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">382
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">383
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">384
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">385
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">386
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">387
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">388
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">389
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">390
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">391
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">392
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">393
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">394
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">395
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">396
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">397
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">398
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">399
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">400
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">401
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">402
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">403
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">404
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">405
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">406
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">407
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">408
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">409
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">410
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">411
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">412
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">413
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">414
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">415
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">416
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">417
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">418
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">419
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">420
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">421
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">422
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">423
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">424
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">425
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">426
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">427
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">428
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">429
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">430
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">431
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">432
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">433
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">434
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">435
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">436
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">437
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">438
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">439
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">440
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">441
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">442
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">443
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">444
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">445
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">446
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">447
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">448
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">449
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">450
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">451
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">452
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">453
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">454
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">455
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">456
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">457
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">458
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">459
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">460
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">461
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">462
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">463
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">464
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">465
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">466
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">467
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">468
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">469
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">470
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">471
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">472
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">473
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">474
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">475
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">476
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">477
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">478
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">479
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">480
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">481
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">482
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">483
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">484
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">485
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">486
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">487
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">488
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">489
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">490
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">491
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">492
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">493
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">494
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">495
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">496
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">497
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">498
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">499
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">500
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">501
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">502
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">503
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">504
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">505
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">506
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">507
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">508
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">509
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">510
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">511
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">512
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">513
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">514
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">515
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">516
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">517
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">518
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">519
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">520
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">521
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">522
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">523
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">524
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">525
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">526
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">527
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">528
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">529
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">530
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">531
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">532
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">533
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">534
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">535
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">536
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">537
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">538
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">539
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">540
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">541
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">542
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">543
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">544
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">545
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">546
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">547
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">548
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">549
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">550
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">551
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">552
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">553
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">554
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">555
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">556
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">557
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">558
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">559
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">560
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">561
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">562
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">563
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">564
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">565
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">566
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">567
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">568
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">569
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">570
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">571
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">572
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">573
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">574
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">575
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">576
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">577
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">578
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">579
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">580
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">581
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">582
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">583
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">584
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">585
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">586
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">587
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">588
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">589
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">590
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">591
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">592
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">593
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">594
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">595
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">596
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">597
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">598
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">599
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">600
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">601
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">602
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">603
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">604
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">605
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">606
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">607
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">608
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">609
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">610
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">611
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">612
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">613
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">614
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">615
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">616
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">617
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">618
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">619
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">620
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">621
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">622
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">623
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">624
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">625
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">626
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">627
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">628
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">629
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">630
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">631
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">632
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">633
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">634
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">635
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">636
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">637
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">638
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">639
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">640
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">641
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">642
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">643
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">644
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">645
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">646
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">647
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">648
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">649
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">650
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">651
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">652
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">653
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">654
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">655
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">656
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">657
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">658
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">659
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">660
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">661
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">662
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">663
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">664
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">665
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">666
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">667
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">668
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">669
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">670
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">671
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">672
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">673
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">674
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">675
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">676
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">677
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">678
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">679
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">680
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">681
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">682
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">683
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">684
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">685
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">686
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">687
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">688
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">689
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">690
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">691
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">692
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">693
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">694
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">695
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">696
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">697
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">698
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">699
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">700
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">701
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">702
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">703
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">704
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">705
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">706
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">707
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">708
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">709
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">710
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">711
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">712
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">713
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">714
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">715
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">716
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">717
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">718
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">719
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">720
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">721
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">722
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">723
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cd5555">&#34;&#34;&#34; Swin Transformer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    - https://arxiv.org/pdf/2103.14030
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">Code/weights from https://github.com/microsoft/Swin-Transformer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">nn</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn.functional</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">F</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.utils.checkpoint</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">checkpoint</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">typing</span> <span style="color:#8b008b;font-weight:bold">import</span> Optional
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">drop_path_f</span>(x, drop_prob: <span style="color:#658b00">float</span> = <span style="color:#b452cd">0.</span>, training: <span style="color:#658b00">bool</span> = <span style="color:#8b008b;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    the original name is misleading as &#39;Drop Connect&#39; is a different form of dropout in a separate paper...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I&#39;ve opted for
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    changing the layer and argument names to &#39;drop path&#39; rather than mix DropConnect as a layer name and use
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#39;survival rate&#39; as the argument.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> drop_prob == <span style="color:#b452cd">0.</span> <span style="color:#8b008b">or</span> <span style="color:#8b008b">not</span> training:
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>    keep_prob = <span style="color:#b452cd">1</span> - drop_prob
</span></span><span style="display:flex;"><span>    shape = (x.shape[<span style="color:#b452cd">0</span>],) + (<span style="color:#b452cd">1</span>,) * (x.ndim - <span style="color:#b452cd">1</span>)  <span style="color:#228b22"># work with diff dim tensors, not just 2D ConvNets</span>
</span></span><span style="display:flex;"><span>    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
</span></span><span style="display:flex;"><span>    random_tensor.floor_()  <span style="color:#228b22"># binarize</span>
</span></span><span style="display:flex;"><span>    output = x.div(keep_prob) * random_tensor
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> output
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">DropPath</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, drop_prob=<span style="color:#8b008b;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(DropPath, self).__init__()
</span></span><span style="display:flex;"><span>        self.drop_prob = drop_prob
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> drop_path_f(x, self.drop_prob, self.training)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">window_partition</span>(x, window_size: <span style="color:#658b00">int</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    将feature map按照window_size划分成一个个没有重叠的window
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        x: (B, H, W, C)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (int): window size(M)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        windows: (num_windows*B, window_size, window_size, C)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    B, H, W, C = x.shape
</span></span><span style="display:flex;"><span>    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># permute: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H//Mh, W//Mh, Mw, Mw, C]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># view: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B*num_windows, Mh, Mw, C]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># contiguous()方法是为了解决permute之后数据内存不再连续的问题</span>
</span></span><span style="display:flex;"><span>    windows = x.permute(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">1</span>, <span style="color:#b452cd">3</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">4</span>, <span style="color:#b452cd">5</span>).contiguous().view(-<span style="color:#b452cd">1</span>, window_size, window_size, C)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> windows
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">window_reverse</span>(windows, window_size: <span style="color:#658b00">int</span>, H: <span style="color:#658b00">int</span>, W: <span style="color:#658b00">int</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    将一个个window还原成一个feature map
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        windows: (num_windows*B, window_size, window_size, C)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (int): Window size(M)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        H (int): Height of image（分割前）
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        W (int): Width of image（分割前）
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        x: (B, H, W, C)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    B = <span style="color:#658b00">int</span>(windows.shape[<span style="color:#b452cd">0</span>] / (H * W / window_size / window_size))
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># view: [B*num_windows, Mh, Mw, C] -&gt; [B, H//Mh, W//Mw, Mh, Mw, C]</span>
</span></span><span style="display:flex;"><span>    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># permute: [B, H//Mh, W//Mw, Mh, Mw, C] -&gt; [B, H//Mh, Mh, W//Mw, Mw, C]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># view: [B, H//Mh, Mh, W//Mw, Mw, C] -&gt; [B, H, W, C]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># contiguous()方法是为了解决permute之后数据内存不再连续的问题</span>
</span></span><span style="display:flex;"><span>    x = x.permute(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">1</span>, <span style="color:#b452cd">3</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">4</span>, <span style="color:#b452cd">5</span>).contiguous().view(B, H, W, -<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">PatchEmbed</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    2D Image to Patch Embedding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, patch_size=<span style="color:#b452cd">4</span>, in_c=<span style="color:#b452cd">3</span>, embed_dim=<span style="color:#b452cd">96</span>, norm_layer=<span style="color:#8b008b;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        patch_size = (patch_size, patch_size)
</span></span><span style="display:flex;"><span>        self.patch_size = patch_size
</span></span><span style="display:flex;"><span>        self.in_chans = in_c
</span></span><span style="display:flex;"><span>        self.embed_dim = embed_dim
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 下采样通过一个卷积层来代替patch merging</span>
</span></span><span style="display:flex;"><span>        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)
</span></span><span style="display:flex;"><span>        self.norm = norm_layer(embed_dim) <span style="color:#8b008b;font-weight:bold">if</span> norm_layer <span style="color:#8b008b;font-weight:bold">else</span> nn.Identity()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        _, _, H, W = x.shape <span style="color:#228b22"># 获取图像的高度和宽度</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># padding</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 如果输入图片的H，W不是patch_size的整数倍，需要进行padding</span>
</span></span><span style="display:flex;"><span>        pad_input = (H % self.patch_size[<span style="color:#b452cd">0</span>] != <span style="color:#b452cd">0</span>) <span style="color:#8b008b">or</span> (W % self.patch_size[<span style="color:#b452cd">1</span>] != <span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> pad_input:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># to pad the last 3 dimensions,</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># (W_left, W_right, H_top,H_bottom, C_front, C_back)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            在宽度方向的右侧padding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            在高度方向的底部padding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>            x = F.pad(x, (<span style="color:#b452cd">0</span>, self.patch_size[<span style="color:#b452cd">1</span>] - W % self.patch_size[<span style="color:#b452cd">1</span>],
</span></span><span style="display:flex;"><span>                          <span style="color:#b452cd">0</span>, self.patch_size[<span style="color:#b452cd">0</span>] - H % self.patch_size[<span style="color:#b452cd">0</span>],
</span></span><span style="display:flex;"><span>                          <span style="color:#b452cd">0</span>, <span style="color:#b452cd">0</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 下采样patch_size倍</span>
</span></span><span style="display:flex;"><span>        x = self.proj(x)
</span></span><span style="display:flex;"><span>        _, _, H, W = x.shape
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># flatten: [B, C, H, W] -&gt; [B, C, HW] 从维度2开始展平，将H和W进行展平</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># transpose: [B, C, HW] -&gt; [B, HW, C] 交换维度</span>
</span></span><span style="display:flex;"><span>        x = x.flatten(<span style="color:#b452cd">2</span>).transpose(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>        x = self.norm(x)  <span style="color:#228b22"># layer normal处理</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x, H, W
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">PatchMerging</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">r</span><span style="color:#cd5555">&#34;&#34;&#34; Patch Merging Layer.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        dim (int): Number of input channels.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, dim, norm_layer=nn.LayerNorm):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># dim与论文中的C相等（相当于是patch embedding之后的第一个stage需要的特征图深度）</span>
</span></span><span style="display:flex;"><span>        self.dim = dim
</span></span><span style="display:flex;"><span>        self.reduction = nn.Linear(<span style="color:#b452cd">4</span> * dim, <span style="color:#b452cd">2</span> * dim, bias=<span style="color:#8b008b;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>        self.norm = norm_layer(<span style="color:#b452cd">4</span> * dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x, H, W):
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        x: B, H*W, C
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        B, L, C = x.shape
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">assert</span> L == H * W, <span style="color:#cd5555">&#34;input feature has wrong size&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x = x.view(B, H, W, C)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># padding</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 如果输入feature map的H，W不是2的整数倍，需要进行padding</span>
</span></span><span style="display:flex;"><span>        pad_input = (H % <span style="color:#b452cd">2</span> == <span style="color:#b452cd">1</span>) <span style="color:#8b008b">or</span> (W % <span style="color:#b452cd">2</span> == <span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> pad_input:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># to pad the last 3 dimensions, starting from the last dimension and moving forward.</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># pad方法是从后往前padding的</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># (C_front, C_back, W_left, W_right, H_top, H_bottom)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># 注意这里的Tensor通道是[B, H, W, C]，所以会和官方文档有些不同</span>
</span></span><span style="display:flex;"><span>            <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            在宽度方向的右侧进行padding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            在高度方向的底部进行padding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>            x = F.pad(x, (<span style="color:#b452cd">0</span>, <span style="color:#b452cd">0</span>, <span style="color:#b452cd">0</span>, W % <span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>, H % <span style="color:#b452cd">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x0 = x[:, <span style="color:#b452cd">0</span>::<span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>::<span style="color:#b452cd">2</span>, :]  <span style="color:#228b22"># [B, H/2, W/2, C]  H方向从0开始以2为间隔，W方向从0开始以2位间隔（图中的蓝色方块）</span>
</span></span><span style="display:flex;"><span>        x1 = x[:, <span style="color:#b452cd">1</span>::<span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>::<span style="color:#b452cd">2</span>, :]  <span style="color:#228b22"># [B, H/2, W/2, C]  H方向从1开始以2为间隔，W方向从0开始以2位间隔（图中的绿色方块）</span>
</span></span><span style="display:flex;"><span>        x2 = x[:, <span style="color:#b452cd">0</span>::<span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>::<span style="color:#b452cd">2</span>, :]  <span style="color:#228b22"># [B, H/2, W/2, C]  H方向从0开始以2为间隔，W方向从1开始以2位间隔（图中的黄色方块）</span>
</span></span><span style="display:flex;"><span>        x3 = x[:, <span style="color:#b452cd">1</span>::<span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>::<span style="color:#b452cd">2</span>, :]  <span style="color:#228b22"># [B, H/2, W/2, C]  H方向从0开始以2为间隔，W方向从1开始以2位间隔（图中的红色方块）</span>
</span></span><span style="display:flex;"><span>        x = torch.cat([x0, x1, x2, x3], -<span style="color:#b452cd">1</span>)  <span style="color:#228b22"># [B, H/2, W/2, 4*C] # 在通道维度进行拼接</span>
</span></span><span style="display:flex;"><span>        x = x.view(B, -<span style="color:#b452cd">1</span>, <span style="color:#b452cd">4</span> * C)  <span style="color:#228b22"># [B, H/2*W/2, 4*C] 将H和W维度进行展平</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x = self.norm(x)                             <span style="color:#228b22"># 进行layer normal</span>
</span></span><span style="display:flex;"><span>        x = self.reduction(x)  <span style="color:#228b22"># [B, H/2*W/2, 2*C]   # 全连接层调整通道数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">Mlp</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34; MLP as used in Vision Transformer, MLP-Mixer and related networks
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_features, hidden_features=<span style="color:#8b008b;font-weight:bold">None</span>, out_features=<span style="color:#8b008b;font-weight:bold">None</span>, act_layer=nn.GELU, drop=<span style="color:#b452cd">0.</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        out_features = out_features <span style="color:#8b008b">or</span> in_features
</span></span><span style="display:flex;"><span>        hidden_features = hidden_features <span style="color:#8b008b">or</span> in_features
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.fc1 = nn.Linear(in_features, hidden_features)
</span></span><span style="display:flex;"><span>        self.act = act_layer()
</span></span><span style="display:flex;"><span>        self.drop1 = nn.Dropout(drop)
</span></span><span style="display:flex;"><span>        self.fc2 = nn.Linear(hidden_features, out_features)
</span></span><span style="display:flex;"><span>        self.drop2 = nn.Dropout(drop)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x = self.fc1(x)
</span></span><span style="display:flex;"><span>        x = self.act(x)
</span></span><span style="display:flex;"><span>        x = self.drop1(x)
</span></span><span style="display:flex;"><span>        x = self.fc2(x)
</span></span><span style="display:flex;"><span>        x = self.drop2(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">WindowAttention</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">r</span><span style="color:#cd5555">&#34;&#34;&#34; Window based multi-head self attention (W-MSA) module with relative position bias.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    It supports both of shifted and non-shifted window.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        dim (int): Number of input channels.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (tuple[int]): The height and width of the window.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        num_heads (int): Number of attention heads.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        proj_drop (float, optional): Dropout ratio of output. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, dim, window_size, num_heads, qkv_bias=<span style="color:#8b008b;font-weight:bold">True</span>, attn_drop=<span style="color:#b452cd">0.</span>, proj_drop=<span style="color:#b452cd">0.</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        self.dim = dim
</span></span><span style="display:flex;"><span>        self.window_size = window_size  <span style="color:#228b22"># [Mh, Mw]</span>
</span></span><span style="display:flex;"><span>        self.num_heads = num_heads
</span></span><span style="display:flex;"><span>        head_dim = dim // num_heads
</span></span><span style="display:flex;"><span>        self.scale = head_dim ** -<span style="color:#b452cd">0.5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># define a parameter table of relative position bias</span>
</span></span><span style="display:flex;"><span>        self.relative_position_bias_table = nn.Parameter(
</span></span><span style="display:flex;"><span>            torch.zeros((<span style="color:#b452cd">2</span> * window_size[<span style="color:#b452cd">0</span>] - <span style="color:#b452cd">1</span>) * (<span style="color:#b452cd">2</span> * window_size[<span style="color:#b452cd">1</span>] - <span style="color:#b452cd">1</span>), num_heads))  <span style="color:#228b22"># [2*Mh-1 * 2*Mw-1, nH]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># get pair-wise relative position index for each token inside the window</span>
</span></span><span style="display:flex;"><span>        coords_h = torch.arange(self.window_size[<span style="color:#b452cd">0</span>])
</span></span><span style="display:flex;"><span>        coords_w = torch.arange(self.window_size[<span style="color:#b452cd">1</span>])
</span></span><span style="display:flex;"><span>        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  <span style="color:#228b22"># [2, Mh, Mw]</span>
</span></span><span style="display:flex;"><span>        coords_flatten = torch.flatten(coords, <span style="color:#b452cd">1</span>)  <span style="color:#228b22"># [2, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># [2, Mh*Mw, 1] - [2, 1, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        relative_coords = coords_flatten[:, :, <span style="color:#8b008b;font-weight:bold">None</span>] - coords_flatten[:, <span style="color:#8b008b;font-weight:bold">None</span>, :]  <span style="color:#228b22"># [2, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        relative_coords = relative_coords.permute(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>).contiguous()  <span style="color:#228b22"># [Mh*Mw, Mh*Mw, 2]</span>
</span></span><span style="display:flex;"><span>        relative_coords[:, :, <span style="color:#b452cd">0</span>] += self.window_size[<span style="color:#b452cd">0</span>] - <span style="color:#b452cd">1</span>  <span style="color:#228b22"># shift to start from 0</span>
</span></span><span style="display:flex;"><span>        relative_coords[:, :, <span style="color:#b452cd">1</span>] += self.window_size[<span style="color:#b452cd">1</span>] - <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>        relative_coords[:, :, <span style="color:#b452cd">0</span>] *= <span style="color:#b452cd">2</span> * self.window_size[<span style="color:#b452cd">1</span>] - <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>        relative_position_index = relative_coords.sum(-<span style="color:#b452cd">1</span>)  <span style="color:#228b22"># [Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        self.register_buffer(<span style="color:#cd5555">&#34;relative_position_index&#34;</span>, relative_position_index)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.qkv = nn.Linear(dim, dim * <span style="color:#b452cd">3</span>, bias=qkv_bias)
</span></span><span style="display:flex;"><span>        self.attn_drop = nn.Dropout(attn_drop)
</span></span><span style="display:flex;"><span>        self.proj = nn.Linear(dim, dim)
</span></span><span style="display:flex;"><span>        self.proj_drop = nn.Dropout(proj_drop)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        nn.init.trunc_normal_(self.relative_position_bias_table, std=<span style="color:#b452cd">.02</span>)
</span></span><span style="display:flex;"><span>        self.softmax = nn.Softmax(dim=-<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x, mask: Optional[torch.Tensor] = <span style="color:#8b008b;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            x: input features with shape of (num_windows*B, Mh*Mw, C)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># [batch_size*num_windows, Mh*Mw, total_embed_dim]</span>
</span></span><span style="display:flex;"><span>        B_, N, C = x.shape
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># qkv(): -&gt; [batch_size*num_windows, Mh*Mw, 3 * total_embed_dim]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, 3, num_heads, embed_dim_per_head]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># permute: -&gt; [3, batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span>
</span></span><span style="display:flex;"><span>        qkv = self.qkv(x).reshape(B_, N, <span style="color:#b452cd">3</span>, self.num_heads, C // self.num_heads).permute(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>, <span style="color:#b452cd">3</span>, <span style="color:#b452cd">1</span>, <span style="color:#b452cd">4</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span>
</span></span><span style="display:flex;"><span>        q, k, v = qkv.unbind(<span style="color:#b452cd">0</span>)  <span style="color:#228b22"># make torchscript happy (cannot use tensor as tuple)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># transpose: -&gt; [batch_size*num_windows, num_heads, embed_dim_per_head, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        q = q * self.scale
</span></span><span style="display:flex;"><span>        attn = (q @ k.transpose(-<span style="color:#b452cd">2</span>, -<span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># relative_position_bias_table.view: [Mh*Mw*Mh*Mw,nH] -&gt; [Mh*Mw,Mh*Mw,nH]</span>
</span></span><span style="display:flex;"><span>        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-<span style="color:#b452cd">1</span>)].view(
</span></span><span style="display:flex;"><span>            self.window_size[<span style="color:#b452cd">0</span>] * self.window_size[<span style="color:#b452cd">1</span>], self.window_size[<span style="color:#b452cd">0</span>] * self.window_size[<span style="color:#b452cd">1</span>], -<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        relative_position_bias = relative_position_bias.permute(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">0</span>, <span style="color:#b452cd">1</span>).contiguous()  <span style="color:#228b22"># [nH, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        attn = attn + relative_position_bias.unsqueeze(<span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> mask <span style="color:#8b008b">is</span> <span style="color:#8b008b">not</span> <span style="color:#8b008b;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># mask: [nW, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>            nW = mask.shape[<span style="color:#b452cd">0</span>]  <span style="color:#228b22"># num_windows</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># attn.view: [batch_size, num_windows, num_heads, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># mask.unsqueeze: [1, nW, 1, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(<span style="color:#b452cd">1</span>).unsqueeze(<span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>            attn = attn.view(-<span style="color:#b452cd">1</span>, self.num_heads, N, N)
</span></span><span style="display:flex;"><span>            attn = self.softmax(attn)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            attn = self.softmax(attn)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        attn = self.attn_drop(attn)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># @: multiply -&gt; [batch_size*num_windows, num_heads, Mh*Mw, embed_dim_per_head]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># transpose: -&gt; [batch_size*num_windows, Mh*Mw, num_heads, embed_dim_per_head]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># reshape: -&gt; [batch_size*num_windows, Mh*Mw, total_embed_dim]</span>
</span></span><span style="display:flex;"><span>        x = (attn @ v).transpose(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>).reshape(B_, N, C)
</span></span><span style="display:flex;"><span>        x = self.proj(x)
</span></span><span style="display:flex;"><span>        x = self.proj_drop(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">SwinTransformerBlock</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">r</span><span style="color:#cd5555">&#34;&#34;&#34; Swin Transformer Block.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        dim (int): Number of input channels.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        num_heads (int): Number of attention heads.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (int): Window size.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        shift_size (int): Shift size for SW-MSA.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop (float, optional): Dropout rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        attn_drop (float, optional): Attention dropout rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop_path (float, optional): Stochastic depth rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, dim, num_heads, window_size=<span style="color:#b452cd">7</span>, shift_size=<span style="color:#b452cd">0</span>,
</span></span><span style="display:flex;"><span>                 mlp_ratio=<span style="color:#b452cd">4.</span>, qkv_bias=<span style="color:#8b008b;font-weight:bold">True</span>, drop=<span style="color:#b452cd">0.</span>, attn_drop=<span style="color:#b452cd">0.</span>, drop_path=<span style="color:#b452cd">0.</span>,
</span></span><span style="display:flex;"><span>                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        self.dim = dim
</span></span><span style="display:flex;"><span>        self.num_heads = num_heads
</span></span><span style="display:flex;"><span>        self.window_size = window_size
</span></span><span style="display:flex;"><span>        self.shift_size = shift_size
</span></span><span style="display:flex;"><span>        self.mlp_ratio = mlp_ratio
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">assert</span> <span style="color:#b452cd">0</span> &lt;= self.shift_size &lt; self.window_size, <span style="color:#cd5555">&#34;shift_size must in 0-window_size&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.norm1 = norm_layer(dim) <span style="color:#228b22"># Swim Transformer Block中第一个layer normal</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># W-MSA or SW-MSA</span>
</span></span><span style="display:flex;"><span>        self.attn = WindowAttention(
</span></span><span style="display:flex;"><span>            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads, qkv_bias=qkv_bias,
</span></span><span style="display:flex;"><span>            attn_drop=attn_drop, proj_drop=drop)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.drop_path = DropPath(drop_path) <span style="color:#8b008b;font-weight:bold">if</span> drop_path &gt; <span style="color:#b452cd">0.</span> <span style="color:#8b008b;font-weight:bold">else</span> nn.Identity() <span style="color:#228b22"># Swim Transformer Block中两个相同的drop path层</span>
</span></span><span style="display:flex;"><span>        self.norm2 = norm_layer(dim) <span style="color:#228b22"># 第二个layer normal层</span>
</span></span><span style="display:flex;"><span>        mlp_hidden_dim = <span style="color:#658b00">int</span>(dim * mlp_ratio)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># mlp层 act_layer代表激活函数，这里默认使用的是GELU drop代表MLP中drop out层</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># mlp的结构为: (Linear——&gt;GELU——&gt;Dropout——&gt;Linear——&gt;Dropout) 中间的通道数为mlp_hidden_dim = dim * mlp_ratio</span>
</span></span><span style="display:flex;"><span>        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x, attn_mask):
</span></span><span style="display:flex;"><span>        H, W = self.H, self.W
</span></span><span style="display:flex;"><span>        B, L, C = x.shape
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">assert</span> L == H * W, <span style="color:#cd5555">&#34;input feature has wrong size&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        shortcut = x <span style="color:#228b22"># 捷径分支（就是残差连接）</span>
</span></span><span style="display:flex;"><span>        x = self.norm1(x)
</span></span><span style="display:flex;"><span>        x = x.view(B, H, W, C)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># pad feature maps to multiples of window size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 把feature map给pad到window size的整数倍</span>
</span></span><span style="display:flex;"><span>        pad_l = pad_t = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>        pad_r = (self.window_size - W % self.window_size) % self.window_size <span style="color:#228b22"># 宽度方向右侧padding的列数</span>
</span></span><span style="display:flex;"><span>        pad_b = (self.window_size - H % self.window_size) % self.window_size <span style="color:#228b22"># 高度方向底部padding的行数</span>
</span></span><span style="display:flex;"><span>        x = F.pad(x, (<span style="color:#b452cd">0</span>, <span style="color:#b452cd">0</span>, pad_l, pad_r, pad_t, pad_b))
</span></span><span style="display:flex;"><span>        _, Hp, Wp, _ = x.shape <span style="color:#228b22"># 新的高和宽</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># cyclic shift</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.shift_size &gt; <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># SW—MSA （从上往下移动，从左往右移动，必须是负号）</span>
</span></span><span style="display:flex;"><span>            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># W-MSA</span>
</span></span><span style="display:flex;"><span>            shifted_x = x
</span></span><span style="display:flex;"><span>            attn_mask = <span style="color:#8b008b;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># partition windows</span>
</span></span><span style="display:flex;"><span>        x_windows = window_partition(shifted_x, self.window_size)  <span style="color:#228b22"># [nW*B, Mh, Mw, C]</span>
</span></span><span style="display:flex;"><span>        x_windows = x_windows.view(-<span style="color:#b452cd">1</span>, self.window_size * self.window_size, C)  <span style="color:#228b22"># [nW*B, Mh*Mw, C]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># W-MSA/SW-MSA</span>
</span></span><span style="display:flex;"><span>        attn_windows = self.attn(x_windows, mask=attn_mask)  <span style="color:#228b22"># [nW*B, Mh*Mw, C]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># merge windows</span>
</span></span><span style="display:flex;"><span>        attn_windows = attn_windows.view(-<span style="color:#b452cd">1</span>, self.window_size, self.window_size, C)  <span style="color:#228b22"># [nW*B, Mh, Mw, C]</span>
</span></span><span style="display:flex;"><span>        shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp)  <span style="color:#228b22"># [B, H&#39;, W&#39;, C]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># reverse cyclic shift</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.shift_size &gt; <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            x = shifted_x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> pad_r &gt; <span style="color:#b452cd">0</span> <span style="color:#8b008b">or</span> pad_b &gt; <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># 把前面pad的数据移除掉</span>
</span></span><span style="display:flex;"><span>            x = x[:, :H, :W, :].contiguous()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x = x.view(B, H * W, C)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># FFN</span>
</span></span><span style="display:flex;"><span>        x = shortcut + self.drop_path(x)
</span></span><span style="display:flex;"><span>        x = x + self.drop_path(self.mlp(self.norm2(x)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">BasicLayer</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    A basic Swin Transformer layer for one stage.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        dim (int): Number of input channels.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        depth (int): Number of blocks.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        num_heads (int): Number of attention heads.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (int): Local window size.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop (float, optional): Dropout rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        attn_drop (float, optional): Attention dropout rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, dim, depth, num_heads, window_size,
</span></span><span style="display:flex;"><span>                 mlp_ratio=<span style="color:#b452cd">4.</span>, qkv_bias=<span style="color:#8b008b;font-weight:bold">True</span>, drop=<span style="color:#b452cd">0.</span>, attn_drop=<span style="color:#b452cd">0.</span>,
</span></span><span style="display:flex;"><span>                 drop_path=<span style="color:#b452cd">0.</span>, norm_layer=nn.LayerNorm, downsample=<span style="color:#8b008b;font-weight:bold">None</span>, use_checkpoint=<span style="color:#8b008b;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>        self.dim = dim
</span></span><span style="display:flex;"><span>        self.depth = depth
</span></span><span style="display:flex;"><span>        self.window_size = window_size
</span></span><span style="display:flex;"><span>        self.use_checkpoint = use_checkpoint
</span></span><span style="display:flex;"><span>        self.shift_size = window_size // <span style="color:#b452cd">2</span>   <span style="color:#228b22"># shifted window每次移动的距离为窗口大小的一半</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># build blocks</span>
</span></span><span style="display:flex;"><span>        self.blocks = nn.ModuleList([
</span></span><span style="display:flex;"><span>            SwinTransformerBlock(
</span></span><span style="display:flex;"><span>                dim=dim,
</span></span><span style="display:flex;"><span>                num_heads=num_heads,
</span></span><span style="display:flex;"><span>                window_size=window_size,
</span></span><span style="display:flex;"><span>                shift_size=<span style="color:#b452cd">0</span> <span style="color:#8b008b;font-weight:bold">if</span> (i % <span style="color:#b452cd">2</span> == <span style="color:#b452cd">0</span>) <span style="color:#8b008b;font-weight:bold">else</span> self.shift_size,   <span style="color:#228b22"># 判断使用W-MSA还是使用SW-MSA</span>
</span></span><span style="display:flex;"><span>                mlp_ratio=mlp_ratio,
</span></span><span style="display:flex;"><span>                qkv_bias=qkv_bias,
</span></span><span style="display:flex;"><span>                drop=drop,
</span></span><span style="display:flex;"><span>                attn_drop=attn_drop,
</span></span><span style="display:flex;"><span>                drop_path=drop_path[i] <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#658b00">isinstance</span>(drop_path, <span style="color:#658b00">list</span>) <span style="color:#8b008b;font-weight:bold">else</span> drop_path,
</span></span><span style="display:flex;"><span>                norm_layer=norm_layer)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(depth)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># patch merging layer</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> downsample <span style="color:#8b008b">is</span> <span style="color:#8b008b">not</span> <span style="color:#8b008b;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            self.downsample = downsample(dim=dim, norm_layer=norm_layer)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            self.downsample = <span style="color:#8b008b;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">create_mask</span>(self, x, H, W):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># calculate attention mask for SW-MSA</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 保证Hp和Wp是window_size的整数倍</span>
</span></span><span style="display:flex;"><span>        Hp = <span style="color:#658b00">int</span>(np.ceil(H / self.window_size)) * self.window_size
</span></span><span style="display:flex;"><span>        Wp = <span style="color:#658b00">int</span>(np.ceil(W / self.window_size)) * self.window_size
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 拥有和feature map一样的通道排列顺序，方便后续window_partition</span>
</span></span><span style="display:flex;"><span>        img_mask = torch.zeros((<span style="color:#b452cd">1</span>, Hp, Wp, <span style="color:#b452cd">1</span>), device=x.device)  <span style="color:#228b22"># [1, Hp, Wp, 1]</span>
</span></span><span style="display:flex;"><span>        h_slices = (<span style="color:#658b00">slice</span>(<span style="color:#b452cd">0</span>, -self.window_size),
</span></span><span style="display:flex;"><span>                    <span style="color:#658b00">slice</span>(-self.window_size, -self.shift_size),
</span></span><span style="display:flex;"><span>                    <span style="color:#658b00">slice</span>(-self.shift_size, <span style="color:#8b008b;font-weight:bold">None</span>))
</span></span><span style="display:flex;"><span>        w_slices = (<span style="color:#658b00">slice</span>(<span style="color:#b452cd">0</span>, -self.window_size),
</span></span><span style="display:flex;"><span>                    <span style="color:#658b00">slice</span>(-self.window_size, -self.shift_size),
</span></span><span style="display:flex;"><span>                    <span style="color:#658b00">slice</span>(-self.shift_size, <span style="color:#8b008b;font-weight:bold">None</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        构建蒙版，见mask.png
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        cnt = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> h <span style="color:#8b008b">in</span> h_slices:
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">for</span> w <span style="color:#8b008b">in</span> w_slices:
</span></span><span style="display:flex;"><span>                img_mask[:, h, w, :] = cnt
</span></span><span style="display:flex;"><span>                cnt += <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        mask_windows = window_partition(img_mask, self.window_size)  <span style="color:#228b22"># [nW, Mh, Mw, 1] 将patch embedding之后patch拆分成一个个window</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        将每一个window按行展平， 见shifted_window.png
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        attn_mask的运行方式（以最后一个window为例）见attn_mask.png（分别为按行复制和按列复制）
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        相减之后对于不为0的区域填入-100，为0的区域填入0，见attn_mask2.png
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        mask_windows = mask_windows.view(-<span style="color:#b452cd">1</span>, self.window_size * self.window_size)  <span style="color:#228b22"># [nW, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        attn_mask = mask_windows.unsqueeze(<span style="color:#b452cd">1</span>) - mask_windows.unsqueeze(<span style="color:#b452cd">2</span>)  <span style="color:#228b22"># [nW, 1, Mh*Mw] - [nW, Mh*Mw, 1]（利用python的广播机制）</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># [nW, Mh*Mw, Mh*Mw]</span>
</span></span><span style="display:flex;"><span>        attn_mask = attn_mask.masked_fill(attn_mask != <span style="color:#b452cd">0</span>, <span style="color:#658b00">float</span>(-<span style="color:#b452cd">100.0</span>)).masked_fill(attn_mask == <span style="color:#b452cd">0</span>, <span style="color:#658b00">float</span>(<span style="color:#b452cd">0.0</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> attn_mask
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x, H, W):
</span></span><span style="display:flex;"><span>        attn_mask = self.create_mask(x, H, W)  <span style="color:#228b22"># [nW, Mh*Mw, Mh*Mw]  SW-MSA时使用的蒙版</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> blk <span style="color:#8b008b">in</span> self.blocks:
</span></span><span style="display:flex;"><span>            blk.H, blk.W = H, W
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#8b008b">not</span> torch.jit.is_scripting() <span style="color:#8b008b">and</span> self.use_checkpoint:
</span></span><span style="display:flex;"><span>                x = checkpoint.checkpoint(blk, x, attn_mask)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>                x = blk(x, attn_mask)
</span></span><span style="display:flex;"><span>            feat = x
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.downsample <span style="color:#8b008b">is</span> <span style="color:#8b008b">not</span> <span style="color:#8b008b;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            x = self.downsample(x, H, W)
</span></span><span style="display:flex;"><span>            H, W = (H + <span style="color:#b452cd">1</span>) // <span style="color:#b452cd">2</span>, (W + <span style="color:#b452cd">1</span>) // <span style="color:#b452cd">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x, H, W, feat
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">SwinTransformer</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">r</span><span style="color:#cd5555">&#34;&#34;&#34; Swin Transformer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">          https://arxiv.org/pdf/2103.14030
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        patch_size (int | tuple(int)): Patch size. Default: 4                                  patch embedding的下采样倍数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        in_chans (int): Number of input image channels. Default: 3
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        num_classes (int): Number of classes for classification head. Default: 1000
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        embed_dim (int): Patch embedding dimension. Default: 96                                C=96
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        depths (tuple(int)): Depth of each Swin Transformer layer.                             默认的每一个stage中的Swim Transformer Block的数量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        num_heads (tuple(int)): Number of attention heads in different layers.                 在Swim Transformer Block中采用的注意力头的个数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        window_size (int): Window size. Default: 7                                             Window的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4                MLP模块当中第一个全连接层翻倍数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True     在自注意力模块中是否使用偏置
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop_rate (float): Dropout rate. Default: 0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        attn_drop_rate (float): Attention dropout rate. Default: 0
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        drop_path_rate (float): Stochastic depth rate. Default: 0.1
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        patch_norm (bool): If True, add normalization after patch embedding. Default: True
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, patch_size=<span style="color:#b452cd">4</span>, in_chans=<span style="color:#b452cd">3</span>, num_classes=<span style="color:#b452cd">1000</span>,
</span></span><span style="display:flex;"><span>                 embed_dim=<span style="color:#b452cd">96</span>, depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">6</span>, <span style="color:#b452cd">2</span>), num_heads=(<span style="color:#b452cd">3</span>, <span style="color:#b452cd">6</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">24</span>),
</span></span><span style="display:flex;"><span>                 window_size=<span style="color:#b452cd">7</span>, mlp_ratio=<span style="color:#b452cd">4.</span>, qkv_bias=<span style="color:#8b008b;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>                 drop_rate=<span style="color:#b452cd">0.</span>, attn_drop_rate=<span style="color:#b452cd">0.</span>, drop_path_rate=<span style="color:#b452cd">0.1</span>,
</span></span><span style="display:flex;"><span>                 norm_layer=nn.LayerNorm, patch_norm=<span style="color:#8b008b;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>                 use_checkpoint=<span style="color:#8b008b;font-weight:bold">False</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>().__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.num_classes = num_classes
</span></span><span style="display:flex;"><span>        self.num_layers = <span style="color:#658b00">len</span>(depths)
</span></span><span style="display:flex;"><span>        self.embed_dim = embed_dim
</span></span><span style="display:flex;"><span>        self.patch_norm = patch_norm
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># stage4输出特征矩阵的channels</span>
</span></span><span style="display:flex;"><span>        self.num_features = <span style="color:#658b00">int</span>(embed_dim * <span style="color:#b452cd">2</span> ** (self.num_layers - <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>        self.mlp_ratio = mlp_ratio
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># split image into non-overlapping patches</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        patch embedding 对应论文中的patch partition和Linear embedding
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self.patch_embed = PatchEmbed(
</span></span><span style="display:flex;"><span>            patch_size=patch_size, in_c=in_chans, embed_dim=embed_dim,
</span></span><span style="display:flex;"><span>            norm_layer=norm_layer <span style="color:#8b008b;font-weight:bold">if</span> self.patch_norm <span style="color:#8b008b;font-weight:bold">else</span> <span style="color:#8b008b;font-weight:bold">None</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 接在patch embedding之后的drop out层</span>
</span></span><span style="display:flex;"><span>        self.pos_drop = nn.Dropout(p=drop_rate)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># stochastic depth  一系列drop_rate的设置策略  linspace(初始数值，末尾数值，step)</span>
</span></span><span style="display:flex;"><span>        dpr = [x.item() <span style="color:#8b008b;font-weight:bold">for</span> x <span style="color:#8b008b">in</span> torch.linspace(<span style="color:#b452cd">0</span>, drop_path_rate, <span style="color:#658b00">sum</span>(depths))]  <span style="color:#228b22"># stochastic depth decay rule</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># build layers</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        构建stage1,2,3,4
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        self.layers = nn.ModuleList()
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> i_layer <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(self.num_layers):
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># 注意这里构建的stage和论文图中有些差异</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># 这里的stage不包含该stage的patch_merging层，包含的是下个stage的</span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># 顺序：Swim Transformer Block后跟着patch merging</span>
</span></span><span style="display:flex;"><span>            layers = BasicLayer(dim=<span style="color:#658b00">int</span>(embed_dim * <span style="color:#b452cd">2</span> ** i_layer),
</span></span><span style="display:flex;"><span>                                depth=depths[i_layer],
</span></span><span style="display:flex;"><span>                                num_heads=num_heads[i_layer],
</span></span><span style="display:flex;"><span>                                window_size=window_size,
</span></span><span style="display:flex;"><span>                                mlp_ratio=self.mlp_ratio,
</span></span><span style="display:flex;"><span>                                qkv_bias=qkv_bias,
</span></span><span style="display:flex;"><span>                                drop=drop_rate,
</span></span><span style="display:flex;"><span>                                attn_drop=attn_drop_rate,
</span></span><span style="display:flex;"><span>                                drop_path=dpr[<span style="color:#658b00">sum</span>(depths[:i_layer]):<span style="color:#658b00">sum</span>(depths[:i_layer + <span style="color:#b452cd">1</span>])], <span style="color:#228b22"># 针对当前stage中每一个swim transformer block采用的drop_rate</span>
</span></span><span style="display:flex;"><span>                                norm_layer=norm_layer,
</span></span><span style="display:flex;"><span>                                downsample=PatchMerging <span style="color:#8b008b;font-weight:bold">if</span> (i_layer &lt; self.num_layers - <span style="color:#b452cd">1</span>) <span style="color:#8b008b;font-weight:bold">else</span> <span style="color:#8b008b;font-weight:bold">None</span>, <span style="color:#228b22"># 前三个stage有patch merging 第四个stage没有patch merging</span>
</span></span><span style="display:flex;"><span>                                use_checkpoint=use_checkpoint)
</span></span><span style="display:flex;"><span>            self.layers.append(layers)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># backbone部分结束，在分类模型上需要添加的部分</span>
</span></span><span style="display:flex;"><span>        self.norm = norm_layer(self.num_features)
</span></span><span style="display:flex;"><span>        self.avgpool = nn.AdaptiveAvgPool1d(<span style="color:#b452cd">1</span>) <span style="color:#228b22"># 全局平均池化</span>
</span></span><span style="display:flex;"><span>        self.head = nn.Linear(self.num_features, num_classes) <span style="color:#8b008b;font-weight:bold">if</span> num_classes &gt; <span style="color:#b452cd">0</span> <span style="color:#8b008b;font-weight:bold">else</span> nn.Identity() <span style="color:#228b22"># 分类头</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.apply(self._init_weights) <span style="color:#228b22"># 权重初始化</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">_init_weights</span>(self, m):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#658b00">isinstance</span>(m, nn.Linear):
</span></span><span style="display:flex;"><span>            nn.init.trunc_normal_(m.weight, std=<span style="color:#b452cd">.02</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#658b00">isinstance</span>(m, nn.Linear) <span style="color:#8b008b">and</span> m.bias <span style="color:#8b008b">is</span> <span style="color:#8b008b">not</span> <span style="color:#8b008b;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>                nn.init.constant_(m.bias, <span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> <span style="color:#658b00">isinstance</span>(m, nn.LayerNorm):
</span></span><span style="display:flex;"><span>            nn.init.constant_(m.bias, <span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>            nn.init.constant_(m.weight, <span style="color:#b452cd">1.0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># x: [B, L, C] L=H*W</span>
</span></span><span style="display:flex;"><span>        x, H, W = self.patch_embed(x)
</span></span><span style="display:flex;"><span>        x = self.pos_drop(x) <span style="color:#228b22"># drop out层</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 依次经过4个stage</span>
</span></span><span style="display:flex;"><span>        i = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> layer <span style="color:#8b008b">in</span> self.layers:
</span></span><span style="display:flex;"><span>            x, H, W, feat = layer(x, H, W)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> i == <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>                feat1 = feat
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">elif</span> i == <span style="color:#b452cd">1</span>:
</span></span><span style="display:flex;"><span>                feat2 = feat
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">elif</span> i == <span style="color:#b452cd">2</span>:
</span></span><span style="display:flex;"><span>                feat3 = feat
</span></span><span style="display:flex;"><span>            i += <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x = self.norm(x)  <span style="color:#228b22"># [B, L, C]</span>
</span></span><span style="display:flex;"><span>        x = self.avgpool(x.transpose(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>))  <span style="color:#228b22"># [B, C, 1]</span>
</span></span><span style="display:flex;"><span>        x = torch.flatten(x, <span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        x = self.head(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x, H, W, feat1, feat2, feat3
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_tiny_patch4_window7_224</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">1000</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-1K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">7</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">96</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">6</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">3</span>, <span style="color:#b452cd">6</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">24</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_small_patch4_window7_224</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">1000</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-1K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">7</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">96</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">3</span>, <span style="color:#b452cd">6</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">24</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_base_patch4_window7_224</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">1000</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-1K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">7</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">128</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">8</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">32</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_base_patch4_window12_384</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">1000</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-1K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">12</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">128</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">8</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">32</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_base_patch4_window7_224_in22k</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">21841</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-22K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">7</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">128</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">8</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">32</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_base_patch4_window12_384_in22k</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">21841</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-22K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">12</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">128</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">8</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">32</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_large_patch4_window7_224_in22k</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">21841</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-22K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22k.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">7</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">192</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">6</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">24</span>, <span style="color:#b452cd">48</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">swin_large_patch4_window12_384_in22k</span>(num_classes: <span style="color:#658b00">int</span> = <span style="color:#b452cd">21841</span>, **kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># trained ImageNet-22K</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth</span>
</span></span><span style="display:flex;"><span>    model = SwinTransformer(in_chans=<span style="color:#b452cd">3</span>,
</span></span><span style="display:flex;"><span>                            patch_size=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>                            window_size=<span style="color:#b452cd">12</span>,
</span></span><span style="display:flex;"><span>                            embed_dim=<span style="color:#b452cd">192</span>,
</span></span><span style="display:flex;"><span>                            depths=(<span style="color:#b452cd">2</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">18</span>, <span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>                            num_heads=(<span style="color:#b452cd">6</span>, <span style="color:#b452cd">12</span>, <span style="color:#b452cd">24</span>, <span style="color:#b452cd">48</span>),
</span></span><span style="display:flex;"><span>                            num_classes=num_classes,
</span></span><span style="display:flex;"><span>                            **kwargs)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> model
</span></span></code></pre></td></tr></table>
</div>
</div><p>swinTS_TransUnet.py(目前设备显存只够玩比较小的两个model_size😩):</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">172
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">173
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">174
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">175
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">176
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">177
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">178
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">179
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">180
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">181
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">182
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">183
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">184
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">185
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">186
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">187
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">188
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">189
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">190
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">191
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">192
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">193
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_tiny_patch4_window7_224 <span style="color:#8b008b;font-weight:bold">as</span> create_model_T_224
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_small_patch4_window7_224 <span style="color:#8b008b;font-weight:bold">as</span> create_model_S_224
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_base_patch4_window7_224 <span style="color:#8b008b;font-weight:bold">as</span> create_model_B_224
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_base_patch4_window12_384 <span style="color:#8b008b;font-weight:bold">as</span> create_model_B_384
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_large_patch4_window7_224_in22k <span style="color:#8b008b;font-weight:bold">as</span> create_model_L_224
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">nets.swin_transformer</span> <span style="color:#8b008b;font-weight:bold">import</span> swin_large_patch4_window12_384_in22k <span style="color:#8b008b;font-weight:bold">as</span> create_model_L_384
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">nn</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">conv_block</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Convolution Block
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_ch, out_ch):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(conv_block, self).__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.conv = nn.Sequential(
</span></span><span style="display:flex;"><span>            nn.Conv2d(in_ch, out_ch, kernel_size=<span style="color:#b452cd">3</span>, stride=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(out_ch),
</span></span><span style="display:flex;"><span>            nn.ReLU(inplace=<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.Conv2d(out_ch, out_ch, kernel_size=<span style="color:#b452cd">3</span>, stride=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(out_ch),
</span></span><span style="display:flex;"><span>            nn.ReLU(inplace=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out = self.conv(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">up_conv</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Up Convolution Block
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_ch, out_ch):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(up_conv, self).__init__()
</span></span><span style="display:flex;"><span>        self.up = nn.Sequential(
</span></span><span style="display:flex;"><span>            nn.Upsample(scale_factor=<span style="color:#b452cd">2</span>),
</span></span><span style="display:flex;"><span>            nn.Conv2d(in_ch, out_ch, kernel_size=<span style="color:#b452cd">3</span>, stride=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(out_ch),
</span></span><span style="display:flex;"><span>            nn.ReLU(inplace=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        out = self.up(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">swinTS_TransUnet</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    embed_dim:96,128,192
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, num_classes=<span style="color:#b452cd">21</span>, pretrained=<span style="color:#8b008b;font-weight:bold">False</span>, backbone=<span style="color:#cd5555">&#34;swin_T_224&#34;</span>, embed_dim=<span style="color:#b452cd">96</span>, base=<span style="color:#b452cd">64</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(swinTS_TransUnet, self).__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> backbone == <span style="color:#cd5555">&#34;swin_T_224&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_T_224(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> backbone == <span style="color:#cd5555">&#34;swin_S_224&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_S_224(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> backbone == <span style="color:#cd5555">&#34;swin_B_224&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_B_224(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> backbone == <span style="color:#cd5555">&#34;swin_B_384&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_B_384(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> backbone == <span style="color:#cd5555">&#34;swin_L_224&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_L_224(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">elif</span> backbone == <span style="color:#cd5555">&#34;swin_L_384&#34;</span>:
</span></span><span style="display:flex;"><span>            self.swin_backbone = create_model_L_384(num_classes=<span style="color:#b452cd">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 将swin transfomer的分类头去掉</span>
</span></span><span style="display:flex;"><span>        remove_head = nn.Sequential()
</span></span><span style="display:flex;"><span>        self.swin_backbone.avgpool = remove_head
</span></span><span style="display:flex;"><span>        self.swin_backbone.head = remove_head
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        fiters = [base, base * <span style="color:#b452cd">2</span>, base * <span style="color:#b452cd">4</span>, base * <span style="color:#b452cd">8</span>, base * <span style="color:#b452cd">16</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># bottle_neck</span>
</span></span><span style="display:flex;"><span>        self.bottle = nn.Sequential(
</span></span><span style="display:flex;"><span>            nn.Conv2d(in_channels=<span style="color:#b452cd">8</span> * embed_dim, out_channels=fiters[<span style="color:#b452cd">4</span>], kernel_size=<span style="color:#b452cd">3</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(fiters[<span style="color:#b452cd">4</span>]),
</span></span><span style="display:flex;"><span>            nn.ReLU(inplace=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 上采样+卷积</span>
</span></span><span style="display:flex;"><span>        self.up5 = up_conv(fiters[<span style="color:#b452cd">4</span>], fiters[<span style="color:#b452cd">3</span>])
</span></span><span style="display:flex;"><span>        self.up4 = up_conv(fiters[<span style="color:#b452cd">3</span>], fiters[<span style="color:#b452cd">2</span>])
</span></span><span style="display:flex;"><span>        self.up3 = up_conv(fiters[<span style="color:#b452cd">2</span>], fiters[<span style="color:#b452cd">1</span>])
</span></span><span style="display:flex;"><span>        self.up2 = up_conv(fiters[<span style="color:#b452cd">1</span>], fiters[<span style="color:#b452cd">0</span>])
</span></span><span style="display:flex;"><span>        self.up1 = up_conv(fiters[<span style="color:#b452cd">0</span>], fiters[<span style="color:#b452cd">0</span>] // <span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 卷积块</span>
</span></span><span style="display:flex;"><span>        self.conv5 = conv_block(<span style="color:#b452cd">4</span> * embed_dim + fiters[<span style="color:#b452cd">3</span>], fiters[<span style="color:#b452cd">3</span>])
</span></span><span style="display:flex;"><span>        self.conv4 = conv_block(<span style="color:#b452cd">2</span> * embed_dim + fiters[<span style="color:#b452cd">2</span>], fiters[<span style="color:#b452cd">2</span>])
</span></span><span style="display:flex;"><span>        self.conv3 = conv_block(embed_dim + fiters[<span style="color:#b452cd">1</span>], fiters[<span style="color:#b452cd">1</span>])
</span></span><span style="display:flex;"><span>        self.conv2 = conv_block(fiters[<span style="color:#b452cd">0</span>], fiters[<span style="color:#b452cd">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.final_conv = nn.Conv2d(in_channels=fiters[<span style="color:#b452cd">0</span>] // <span style="color:#b452cd">2</span>, out_channels=num_classes, kernel_size=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self.backbone = backbone
</span></span><span style="display:flex;"><span>        self.embed_dim = embed_dim
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x, H, W, feat1, feat2, feat3 = self.swin_backbone(x)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(x.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat1.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat2.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat3.shape)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 转回卷积网络所需要尺寸</span>
</span></span><span style="display:flex;"><span>        x = x.view(-<span style="color:#b452cd">1</span>, <span style="color:#b452cd">8</span> * self.embed_dim, H, W)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        _, size1, C1 = feat1.shape
</span></span><span style="display:flex;"><span>        feat1 = feat1.permute(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>).contiguous().view(-<span style="color:#b452cd">1</span>, C1, size1//(<span style="color:#b452cd">8</span>*H), <span style="color:#b452cd">8</span>*H)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        _, size2, C2 = feat2.shape
</span></span><span style="display:flex;"><span>        feat2 = feat2.permute(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>).contiguous().view(-<span style="color:#b452cd">1</span>, C2, size2//(<span style="color:#b452cd">4</span>*H), <span style="color:#b452cd">4</span>*H)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        _, size3, C3 = feat3.shape
</span></span><span style="display:flex;"><span>        feat3 = feat3.permute(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>).contiguous().view(-<span style="color:#b452cd">1</span>, C3, size3//(<span style="color:#b452cd">2</span>*H), <span style="color:#b452cd">2</span>*H)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat1.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat2.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(feat3.shape)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># print(x.shape)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 中间连接层</span>
</span></span><span style="display:flex;"><span>        x = self.bottle(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        d5 = self.up5(x)
</span></span><span style="display:flex;"><span>        d5 = torch.concat((d5, feat3), dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        a5 = self.conv5(d5)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        d4 = self.up4(a5)
</span></span><span style="display:flex;"><span>        d4 = torch.concat((d4, feat2), dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        a4 = self.conv4(d4)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        d3 = self.up3(a4)
</span></span><span style="display:flex;"><span>        d3 = torch.concat((d3, feat1), dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        a3 = self.conv3(d3)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        d2 = self.up2(a3)
</span></span><span style="display:flex;"><span>        a2 = self.conv2(d2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        d1 = self.up1(a2)
</span></span><span style="display:flex;"><span>        out = self.final_conv(d1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">freeze_backbone</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.backbone == <span style="color:#cd5555">&#34;swin_T_224&#34;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">for</span> param <span style="color:#8b008b">in</span> self.swin_backbone.parameters():
</span></span><span style="display:flex;"><span>                param.requires_grad = <span style="color:#8b008b;font-weight:bold">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">unfreeze_backbone</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> self.backbone == <span style="color:#cd5555">&#34;swin_T_224&#34;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">for</span> param <span style="color:#8b008b">in</span> self.swin_backbone.parameters():
</span></span><span style="display:flex;"><span>                param.requires_grad = <span style="color:#8b008b;font-weight:bold">True</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">getModelSize</span>(model):
</span></span><span style="display:flex;"><span>    param_size = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>    param_sum = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> param <span style="color:#8b008b">in</span> model.parameters():
</span></span><span style="display:flex;"><span>        param_size += param.nelement() * param.element_size()
</span></span><span style="display:flex;"><span>        param_sum += param.nelement()
</span></span><span style="display:flex;"><span>    buffer_size = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>    buffer_sum = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> buffer <span style="color:#8b008b">in</span> model.buffers():
</span></span><span style="display:flex;"><span>        buffer_size += buffer.nelement() * buffer.element_size()
</span></span><span style="display:flex;"><span>        buffer_sum += buffer.nelement()
</span></span><span style="display:flex;"><span>    all_size = (param_size + buffer_size) / <span style="color:#b452cd">1024</span> / <span style="color:#b452cd">1024</span>
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#39;模型总大小为：</span><span style="color:#cd5555">{:.3f}</span><span style="color:#cd5555">MB&#39;</span>.format(all_size))
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> (param_size, param_sum, buffer_size, buffer_sum, all_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">if</span> __name__ == <span style="color:#cd5555">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    model = swinTS_TransUnet(num_classes=<span style="color:#b452cd">3</span> + <span style="color:#b452cd">1</span>, pretrained=<span style="color:#8b008b;font-weight:bold">False</span>, backbone=<span style="color:#cd5555">&#34;swin_T_224&#34;</span>)
</span></span><span style="display:flex;"><span>    a, b, c, d, e = getModelSize(model)
</span></span><span style="display:flex;"><span>    x = torch.randn((<span style="color:#b452cd">3</span>, <span style="color:#b452cd">3</span>, <span style="color:#b452cd">224</span>, <span style="color:#b452cd">224</span>))
</span></span><span style="display:flex;"><span>    out = model(x)
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(out.shape)
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(model)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>第一种预训练方案：</p>
<p>直接加载预训练权重，需要注意的问题就是模型的key值在放入分割模型后会改变，直接加载权重是加载不进去的！所以需要根据权重和模型的key值对权重的key进行修改，具体修改方法知乎介绍的很多。</p>
</li>
<li>
<p>第二种预训练方案：虽说最好的方案是在ADE20k数据集上预训练，但其实我并没有那么好的训练设备支持我的训练速度。所以我想到了一个次优方案：</p>
<ul>
<li>首先，使用官方给出的分类网络预训练权重载入到我们的swin_transUnet中（需要变更权重的key值才能正确载入），进行锁权重50轮，释放权重150轮，一共是200轮的训练（每5轮计算一次验证集mIoU），拿到最高的权重</li>
<li>将前面拿到的权重再放到我们的目标数据集上进行不锁权重200轮的训练，因为权值文件基本已经全覆盖了。</li>
</ul>
</li>
</ul>
<blockquote>
<p>这应该是我在有限的资源（一张RTX 2060， 6G）下能做到的最优方案了，虽然这张卡在最小的模型下在VOC2012上也要跑20个小时左右。</p>
</blockquote>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2022-10-14</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/voc%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/">
			下回<br>VOC分割数据集制作
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%E4%BD%A0%E7%9A%84%E6%98%BE%E5%AD%98/">
			上回<br>充分利用你的显存，智能调节学习率
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2024 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
