<!DOCTYPE html>
<html><head>
<title>深度学习笔记（1-3节） </title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="毕业设计可能会使用深度学习，从暑假开始从头学习">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="深度学习笔记（1-3节） " />
<meta property="og:description" content="毕业设计可能会使用深度学习，从暑假开始从头学习" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-3%E8%8A%82/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2022-07-12T18:18:05+08:00" />
<meta property="article:modified_time" content="2022-07-12T18:19:06+08:00" />











<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="https://jarson-cai.gitee.io/jarson-cai-blog">
    MiFeng
</a>
<br>

<a href="nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2022 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a01-3%e8%8a%82" onclick="onNavClick(`#深度学习1-3节-nav`)" id="深度学习1-3节-nav">
									深度学习（1-3节）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%bb%8b%e7%bb%8d" onclick="onNavClick(`#深度学习介绍-nav`)" id="深度学习介绍-nav">
									深度学习介绍
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%ba%bf%e6%80%a7%e6%95%b4%e6%b5%81%e5%87%bd%e6%95%b0relu%e5%87%bd%e6%95%b0" onclick="onNavClick(`#线性整流函数relu函数-nav`)" id="线性整流函数relu函数-nav">
									线性整流函数（ReLU函数）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%bb%8b%e7%bb%8d" onclick="onNavClick(`#神经网络介绍-nav`)" id="神经网络介绍-nav">
									神经网络介绍
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0" onclick="onNavClick(`#监督学习-nav`)" id="监督学习-nav">
									监督学习
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bb%93%e6%9e%84%e5%8c%96%e6%95%b0%e6%8d%aevs%e9%9d%9e%e7%bb%93%e6%9e%84%e5%8c%96%e6%95%b0%e6%8d%ae" onclick="onNavClick(`#结构化数据vs非结构化数据-nav`)" id="结构化数据vs非结构化数据-nav">
									结构化数据vs非结构化数据
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%87%86%e7%a1%ae%e7%8e%87" onclick="onNavClick(`#深度学习的准确率-nav`)" id="深度学习的准确率-nav">
									深度学习的准确率
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#sigmoid%e5%87%bd%e6%95%b0" onclick="onNavClick(`#sigmoid函数-nav`)" id="sigmoid函数-nav">
									Sigmoid函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80" onclick="onNavClick(`#深度学习基础-nav`)" id="深度学习基础-nav">
									深度学习基础
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#logistic%e5%9b%9e%e5%bd%92" onclick="onNavClick(`#logistic回归-nav`)" id="logistic回归-nav">
									Logistic回归
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#梯度下降法-nav`)" id="梯度下降法-nav">
									梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%90%91%e9%87%8f%e5%8c%96%e6%8a%80%e6%9c%af" onclick="onNavClick(`#向量化技术-nav`)" id="向量化技术-nav">
									向量化技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#python%e4%b8%ad%e7%9a%84%e5%b9%bf%e6%92%ad" onclick="onNavClick(`#python中的广播-nav`)" id="python中的广播-nav">
									Python中的广播
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#numpy%e7%9a%84%e4%bd%bf%e7%94%a8" onclick="onNavClick(`#numpy的使用-nav`)" id="numpy的使用-nav">
									numpy的使用
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%b8%80" onclick="onNavClick(`#作业一-nav`)" id="作业一-nav">
									作业一
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%bc%96%e5%86%99" onclick="onNavClick(`#神经网络编写-nav`)" id="神经网络编写-nav">
									神经网络编写
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%a1%a8%e7%a4%ba" onclick="onNavClick(`#神经网络表示-nav`)" id="神经网络表示-nav">
									神经网络表示
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e8%ae%a1%e7%ae%97" onclick="onNavClick(`#神经网络的计算-nav`)" id="神经网络的计算-nav">
									神经网络的计算
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e4%b8%aa%e6%a0%b7%e6%9c%ac%e7%9a%84%e5%90%91%e9%87%8f%e5%8c%96" onclick="onNavClick(`#多个样本的向量化-nav`)" id="多个样本的向量化-nav">
									多个样本的向量化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e7%a7%8d%e6%bf%80%e6%b4%bb%e5%87%bd%e6%95%b0" onclick="onNavClick(`#多种激活函数-nav`)" id="多种激活函数-nav">
									多种激活函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%bf%80%e6%b4%bb%e5%87%bd%e6%95%b0%e7%9a%84%e5%af%bc%e6%95%b0" onclick="onNavClick(`#激活函数的导数-nav`)" id="激活函数的导数-nav">
									激活函数的导数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#神经网络的梯度下降法-nav`)" id="神经网络的梯度下降法-nav">
									神经网络的梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%9a%8f%e6%9c%ba%e5%88%9d%e5%a7%8b%e5%8c%96" onclick="onNavClick(`#随机初始化-nav`)" id="随机初始化-nav">
									随机初始化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%ba%8c" onclick="onNavClick(`#作业二-nav`)" id="作业二-nav">
									作业二
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a01-3%e8%8a%82" onclick="onNavClick(`#深度学习1-3节-nav`)" id="深度学习1-3节-nav">
									深度学习（1-3节）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%bb%8b%e7%bb%8d" onclick="onNavClick(`#深度学习介绍-nav`)" id="深度学习介绍-nav">
									深度学习介绍
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%ba%bf%e6%80%a7%e6%95%b4%e6%b5%81%e5%87%bd%e6%95%b0relu%e5%87%bd%e6%95%b0" onclick="onNavClick(`#线性整流函数relu函数-nav`)" id="线性整流函数relu函数-nav">
									线性整流函数（ReLU函数）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%bb%8b%e7%bb%8d" onclick="onNavClick(`#神经网络介绍-nav`)" id="神经网络介绍-nav">
									神经网络介绍
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0" onclick="onNavClick(`#监督学习-nav`)" id="监督学习-nav">
									监督学习
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bb%93%e6%9e%84%e5%8c%96%e6%95%b0%e6%8d%aevs%e9%9d%9e%e7%bb%93%e6%9e%84%e5%8c%96%e6%95%b0%e6%8d%ae" onclick="onNavClick(`#结构化数据vs非结构化数据-nav`)" id="结构化数据vs非结构化数据-nav">
									结构化数据vs非结构化数据
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%87%86%e7%a1%ae%e7%8e%87" onclick="onNavClick(`#深度学习的准确率-nav`)" id="深度学习的准确率-nav">
									深度学习的准确率
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#sigmoid%e5%87%bd%e6%95%b0" onclick="onNavClick(`#sigmoid函数-nav`)" id="sigmoid函数-nav">
									Sigmoid函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80" onclick="onNavClick(`#深度学习基础-nav`)" id="深度学习基础-nav">
									深度学习基础
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#logistic%e5%9b%9e%e5%bd%92" onclick="onNavClick(`#logistic回归-nav`)" id="logistic回归-nav">
									Logistic回归
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#梯度下降法-nav`)" id="梯度下降法-nav">
									梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%90%91%e9%87%8f%e5%8c%96%e6%8a%80%e6%9c%af" onclick="onNavClick(`#向量化技术-nav`)" id="向量化技术-nav">
									向量化技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#python%e4%b8%ad%e7%9a%84%e5%b9%bf%e6%92%ad" onclick="onNavClick(`#python中的广播-nav`)" id="python中的广播-nav">
									Python中的广播
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#numpy%e7%9a%84%e4%bd%bf%e7%94%a8" onclick="onNavClick(`#numpy的使用-nav`)" id="numpy的使用-nav">
									numpy的使用
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%b8%80" onclick="onNavClick(`#作业一-nav`)" id="作业一-nav">
									作业一
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%bc%96%e5%86%99" onclick="onNavClick(`#神经网络编写-nav`)" id="神经网络编写-nav">
									神经网络编写
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%a1%a8%e7%a4%ba" onclick="onNavClick(`#神经网络表示-nav`)" id="神经网络表示-nav">
									神经网络表示
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e8%ae%a1%e7%ae%97" onclick="onNavClick(`#神经网络的计算-nav`)" id="神经网络的计算-nav">
									神经网络的计算
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e4%b8%aa%e6%a0%b7%e6%9c%ac%e7%9a%84%e5%90%91%e9%87%8f%e5%8c%96" onclick="onNavClick(`#多个样本的向量化-nav`)" id="多个样本的向量化-nav">
									多个样本的向量化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e7%a7%8d%e6%bf%80%e6%b4%bb%e5%87%bd%e6%95%b0" onclick="onNavClick(`#多种激活函数-nav`)" id="多种激活函数-nav">
									多种激活函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%bf%80%e6%b4%bb%e5%87%bd%e6%95%b0%e7%9a%84%e5%af%bc%e6%95%b0" onclick="onNavClick(`#激活函数的导数-nav`)" id="激活函数的导数-nav">
									激活函数的导数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#神经网络的梯度下降法-nav`)" id="神经网络的梯度下降法-nav">
									神经网络的梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%9a%8f%e6%9c%ba%e5%88%9d%e5%a7%8b%e5%8c%96" onclick="onNavClick(`#随机初始化-nav`)" id="随机初始化-nav">
									随机初始化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%ba%8c" onclick="onNavClick(`#作业二-nav`)" id="作业二-nav">
									作业二
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img_title.jpg')"
                    
                
            >
                <div class="post-title">
                    深度学习笔记（1-3节） 
                    
                    <div class="post-subtitle">
                        毕业设计可能会使用深度学习，从暑假开始从头学习
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2022-07-12 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[深度学习&amp;计算机视觉]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/deep_learning">Deep_learning</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            36 min
                            
                            39 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="深度学习1-3节">深度学习（1-3节）</h2>
<h3 id="深度学习介绍">深度学习介绍</h3>
<h4 id="线性整流函数relu函数">线性整流函数（ReLU函数）</h4>
<p>通常意义下，线性整流函数指代数学中的斜坡函数，即
$$
f(x)=max(0,x)
$$
而在神经网络中，线性整流作为神经元的激活函数，定义了该神经元在线性变换$W^Tx+b$之后的非线性输出结果。换言之，对于进入神经元的来自上一层神经网络的输入向量$x$，使用线性整流激活函数的神经元会输出
$$
max(0,W^Tx+b)
$$
到下一层神经元或作为整个神经网络的输出。</p>
<h4 id="神经网络介绍">神经网络介绍</h4>
<p>神经网络的基本模型是神经元，由输入层，隐藏层，输出层组成。最基本的神经网络是计算映射的，输入层为$x$，在实际上一般表现为特征，输出层为y，一般为结果，隐藏层其实就是上面所说的权向量$W^t$。</p>
<h4 id="监督学习">监督学习</h4>
<p>监督学习也称为带标签的学习方式。监督学习是<code>从标记的训练数据</code>来推断一个功能的机器学习任务。训练数据包括一套训练示例。在监督学习中，每个实例都是由一个输入对象（通常为矢量）和一个期望的输出值（也称为监督信号）组成。</p>
<h4 id="结构化数据vs非结构化数据">结构化数据vs非结构化数据</h4>
<p>结构化数据指传统数据库中的数据，非结构化数据库是指音频，图片，文本等数据。</p>
<h4 id="深度学习的准确率">深度学习的准确率</h4>
<p>取决于你的神经网络复杂度以及训练集的大小，一般来说神经网络越复杂时，需要的训练数据也越多，这样训练出来的模型效果也更好。</p>
<h4 id="sigmoid函数">Sigmoid函数</h4>
<p>sigmoid函数也叫<code>Logistic</code>函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。Sigmoid作为激活函数有以下优缺点：</p>
<p>优点：平滑、易于求导。</p>
<p>缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法；反向传播时，很容易就会出现<code>梯度消失</code>的情况，从而无法完成深层网络的训练。</p>
<p>Sigmoid函数的公式如下：
$$
S(x)=\frac{1}{1+e^{-x}}
$$
函数图形如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img3.jpg" alt=""></p>
<h3 id="深度学习基础">深度学习基础</h3>
<blockquote>
<p>为了方便学习：</p>
<p>1.使用$(x,y)$来表示一个单独的样本</p>
<p>2.$x\in \R^{n_x}$代表$x$是$n_x$维的特征向量，$y\in {0,1}$代表标签$y$值为0或1</p>
<p>3.训练集由m个训练样本构成，$(x^{(1)},y^{(1)})$代表样本一，$(x^{(m)},y^{(m)})$代表最后一个样本m</p>
<p>4.$m=m_{train}+m_{test}$</p>
<p>5.构建神经网络时使用矩阵$X=\left[ \begin{matrix}|&amp;|&amp;&amp;|\ x^{\left( 1\right)  }&amp;x^{\left( 2\right)  }&amp;\cdots &amp;x^{\left( m\right)  }\ |&amp;|&amp;&amp;|\end{matrix} \right]  $，$m$是训练集样本的个数。</p>
<p>6.输出标签时，为了方便，也将y标签放入列中，$Y=\left[ \begin{matrix} y^{\left( 1\right)  }&amp;y^{\left( 2\right)  }&amp;\cdots &amp;y^{\left( m\right)  }\end{matrix} \right]  $,$Y\in\R^{1\times m}$</p>
</blockquote>
<h4 id="logistic回归">Logistic回归</h4>
<p>Logistic回归通常用于二元分类问题。</p>
<p>它通常的做法是将<code>sigmoid函数</code>作用于线性回归：
$$
\hat{y} =\sigma\left( W^{T}x+b\right)\quad \quad \text{其中} \sigma(z)=\frac{1}{1+e^{-z}}
$$
这会使得$\hat{y}$的范围在0~1之间</p>
<p>梯度下降法中的<code>损失函数</code>如下：
$$
L(\hat{y},y)=\frac12(\hat{y}-y)^2
$$
Logistic回归中使用的<code>损失函数</code>如下：
$$
L(\hat{y},y)=-(y\log\hat{y}+(1-y)\log(1-\hat{y}))
$$
当$y=1$时，$L(\hat{y},y)=-y\log\hat{y}$，为了使损失函数较小，$\hat{y}$必须比较大，而$\hat{y}$的取值范围在0~1之间，所以$\hat{y}$要接近于1；当$y=0$，$L(\hat{y},y)=-\log(1-\hat{y})$，$\hat{y}$必须比较小，而$\hat{y}$的取值范围在0~1之间，所以$\hat{y}$要接近于0。</p>
<blockquote>
<p>损失函数是在单个训练样本中定义的，在全体训练样本上的表现是由代价函数来定义的。</p>
</blockquote>
<p>代价函数的定义：
$$
\begin{split}
J(W,b)&amp;=\frac{1}{m}\sum^{m}<em>{i\  =\  1} L\left( \hat{y}^{\left( i\right)  } ,y^{\left( i\right)  }\right) \&amp;=-\frac{1}{m}\sum^m</em>{i=1}[y^{(i)}\log\hat{y}^{(i)}+(1-y^{(i)})\log(1-\hat{y}^{(i)})]\quad \quad \quad
\text{其中}\hat{y}^{(i)}\text{代表的是预测值}，y^{(i)}代表的是真实值
\end{split}
$$</p>
<h4 id="梯度下降法">梯度下降法</h4>
<p>我们可以将梯度下降法用下图来表示：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img1.jpg" alt=""></p>
<p>梯度下降法所做的事就是从初始点开始让$J(W,b)$朝<code>最陡的下坡方向</code>走一步,迭代次数不定。</p>
<p>其中$W$的迭代更新公式如下：
$$
W:=W-\alpha\frac{\partial J(W,b)}{\partial W} \quad \quad 其中\alpha 代表学习率，\frac{\partial J(W,b)}{\partial W} 代表该点的W对应的导数
\b:=b-\alpha\frac{\partial J(W,b)}{\partial b}\quad \quad 其中\alpha 代表学习率，\frac{\partial J(W,b)}{\partial b} 代表该点的b对应的导数
$$
这样会使$W$和$b$一步一步得接近使得$J(W,b)$最小的值。</p>
<blockquote>
<p>那么m个样本的梯度下降如何来表示呢？</p>
</blockquote>
<p>其实就是对$J(W,b)$函数分别对$W$和$b$求偏导,得到全局的梯度值。</p>
<blockquote>
<p>$W$和$b$的迭代过程：</p>
<p>1.对$W$和$b$设定初值，计算$J(W,b)$</p>
<p>2.通过$J(W,b)$对参数求偏导</p>
<p>3.使用$W$和$b$的原值减去学习率乘以偏导来迭代更新值</p>
<p>4.重复1~3步骤</p>
</blockquote>
<h4 id="向量化技术">向量化技术</h4>
<p>如果不使用向量化技术，在面对巨大的数据集时，你会用非常多的循环去解决迭代的问题，这往往会降低代码运行的速度。向量化技术使得这种计算过程变得更加快速。</p>
<p>比如$f=W^T$,如果$W$有n个维度，不使用向量化一般需要用长度为n的for循环遍历求解，向量化之后则用矩阵来求解，看一段<code>Python</code>代码：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">time</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>a = np.random.rand(<span style="color:#b452cd">1000000</span>)
</span></span><span style="display:flex;"><span>b = np.random.rand(<span style="color:#b452cd">1000000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 非向量化使用循环</span>
</span></span><span style="display:flex;"><span>c = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>tic = time.time()
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(<span style="color:#b452cd">1000000</span>):
</span></span><span style="display:flex;"><span>  c += a[i]*b[i]
</span></span><span style="display:flex;"><span>toc = time.time()
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;使用循环做法花费的时间为&#34;</span> + <span style="color:#658b00">str</span>(<span style="color:#b452cd">1000</span>*(toc - tic)) + <span style="color:#cd5555">&#34;ms&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 使用向量化技术</span>
</span></span><span style="display:flex;"><span>tic = time.time()
</span></span><span style="display:flex;"><span>c = np.dot(a, b)
</span></span><span style="display:flex;"><span>toc = time.time()
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;使用向量化技术花费的时间为&#34;</span> + <span style="color:#658b00">str</span>(<span style="color:#b452cd">1000</span>*(toc - tic)) + <span style="color:#cd5555">&#34;ms&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 运行结果如下：（保留一位小数）</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 使用循环做法花费时间为474.3ms</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 使用向量化技术花费的时间为1.5ms</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>我们在编写神经网络的时候，尽量要避免使用for循环</p>
</blockquote>
<p>再举个例子：
$$
v=\left[ \begin{matrix}v_{1}\ \vdots \ v_{n}\end{matrix} \right]  ==&gt;u=\left[ \begin{matrix}v_{1}\ \vdots \ v_{n}\end{matrix} \right]<br>
$$
可以这样编程（尽量使用numpy）:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># np.random.randint(a, b, size=(c, d)):</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 注：a-b表示生成[a,b]数的范围，后面size表示生成矩阵的大小</span>
</span></span><span style="display:flex;"><span>n = <span style="color:#b452cd">10000</span>
</span></span><span style="display:flex;"><span>v = np.random.randint(<span style="color:#b452cd">10</span>,<span style="color:#b452cd">11</span>,(<span style="color:#b452cd">1</span>,n))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 原始方法（for循环）</span>
</span></span><span style="display:flex;"><span>u = np.zero((n,<span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(n):
</span></span><span style="display:flex;"><span>  u[i]=math.exp(v[i])
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 使用numpy的内置函数，能比原来快很多</span>
</span></span><span style="display:flex;"><span>u = np.exp(v)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 同样还有np.log() np.abs() np.maximum(v,0) v**2 1/v</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>使用numpy简易表示Logistic回归的一轮迭代：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># Z = w^T*X+b</span>
</span></span><span style="display:flex;"><span>Z = np.dot(w.T,X)+b
</span></span><span style="display:flex;"><span><span style="color:#228b22"># A = sigmoid(Z) </span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">sigmoid_func</span>(Z):
</span></span><span style="display:flex;"><span>	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#b452cd">1</span>/(<span style="color:#b452cd">1</span>+np.exp(-z))
</span></span><span style="display:flex;"><span>A = sigmoid_func(Z)
</span></span><span style="display:flex;"><span>dZ = A - Y
</span></span><span style="display:flex;"><span>dw = <span style="color:#b452cd">1</span>/m * dZ
</span></span><span style="display:flex;"><span>db = <span style="color:#b452cd">1</span>/m * np.sum(dZ)
</span></span><span style="display:flex;"><span>w = w - a * dw <span style="color:#228b22"># a代表学习率</span>
</span></span><span style="display:flex;"><span>b = b - a * db 
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="python中的广播">Python中的广播</h4>
<table>
<thead>
<tr>
<th></th>
<th>苹果</th>
<th>牛肉</th>
<th>鸡蛋</th>
<th>土豆</th>
</tr>
</thead>
<tbody>
<tr>
<td>碳水化合物</td>
<td>56.0</td>
<td>0.0</td>
<td>4.4</td>
<td>68.0</td>
</tr>
<tr>
<td>蛋白质</td>
<td>1.2</td>
<td>104.0</td>
<td>52.0</td>
<td>8.0</td>
</tr>
<tr>
<td>脂肪</td>
<td>1.8</td>
<td>135.0</td>
<td>99.0</td>
<td>0.9</td>
</tr>
</tbody>
</table>
<p>求每种食物的每项指标占比：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>A = np.array([[<span style="color:#b452cd">56.0</span>, <span style="color:#b452cd">0.0</span>, <span style="color:#b452cd">4.4</span>, <span style="color:#b452cd">68.0</span>],
</span></span><span style="display:flex;"><span>              [<span style="color:#b452cd">1.2</span>, <span style="color:#b452cd">104.0</span>, <span style="color:#b452cd">52.0</span>, <span style="color:#b452cd">8.0</span>],
</span></span><span style="display:flex;"><span>              [<span style="color:#b452cd">1.8</span>, <span style="color:#b452cd">135.0</span>, <span style="color:#b452cd">99.0</span> <span style="color:#b452cd">0.9</span>]])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 对矩阵进行竖直方向求和</span>
</span></span><span style="display:flex;"><span>cal = A.sum(axis=<span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># reshape是O(1)操作，放心使用</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 这里的广播是将3*4的矩阵除以1*4的矩阵，然后进行自动广播</span>
</span></span><span style="display:flex;"><span>percentage = <span style="color:#b452cd">100</span>*A/cal.reshape(<span style="color:#b452cd">1</span>,<span style="color:#b452cd">4</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>再举一个特殊的例子：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>A = np.array([[<span style="color:#b452cd">1</span>],
</span></span><span style="display:flex;"><span>       				[<span style="color:#b452cd">2</span>],
</span></span><span style="display:flex;"><span>              [<span style="color:#b452cd">3</span>],
</span></span><span style="display:flex;"><span>              [<span style="color:#b452cd">4</span>]])
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 广播</span>
</span></span><span style="display:flex;"><span>A = A + <span style="color:#b452cd">100</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(A)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 结果：</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [[101]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [102]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [103]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [104]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如上所示，广播的规则如下：</p>
<p>一个$m\times n$的矩阵<code>加减乘除</code>一个$1\times n$的矩阵，python就会自动把它复制成$m\times n$的矩阵</p>
<p>一个$m\times n$的矩阵<code>加减乘除</code>一个$m\times 1$的矩阵，python就会自动把它复制成$m\times n$的矩阵</p>
<p>一个$m\times 1$的矩阵<code>加减乘除</code>一个常数，python就会自动把它复制成$m\times 1$的矩阵</p>
<p>一个$1\times m$的矩阵<code>加减乘除</code>一个常数，python就会自动把它复制成$1\times m$的矩阵</p>
<h4 id="numpy的使用">numpy的使用</h4>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 并不是一个向量，而是一个秩为1的数组</span>
</span></span><span style="display:flex;"><span>a = np.random.randn(<span style="color:#b452cd">5</span>)
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(a)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [-1.20936449  0.67825543  1.92816046 -0.55383946 -0.53203701]</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(a.shape)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># (5,)</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(a.T)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [-1.20936449  0.67825543  1.92816046 -0.55383946 -0.53203701]</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(np.dot(a,a.T))
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 6.23019719213342</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>b = np.random.randn(<span style="color:#b452cd">5</span>,<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(b)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [[ 1.83847239]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [ 0.43958321]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [-0.87437944]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [ 0.70296355]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [-0.1833722 ]]</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(b.T)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [[ 1.83847239  0.43958321 -0.87437944  0.70296355 -0.1833722 ]]</span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(np.dot(b,b.T))
</span></span><span style="display:flex;"><span><span style="color:#228b22"># [[ 3.37998075  0.8081616  -1.60752246  1.29237908 -0.33712473]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [ 0.8081616   0.1932334  -0.38436252  0.30901097 -0.08060734]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [-1.60752246 -0.38436252  0.7645394  -0.61465687  0.16033688]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [ 1.29237908  0.30901097 -0.61465687  0.49415775 -0.12890397]</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22">#  [-0.33712473 -0.08060734  0.16033688 -0.12890397  0.03362536]]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>从上面的例子可以看出，我们构建向量时尽量构建b这种类型的向量，不要使用数组，可以避免不必要的错误。</p>
<p>为了我们程序的运行正确，少点bug，可以使用assert声明函数。Python assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。断言可以在条件不满足程序运行的情况下直接返回错误，而不必等待程序运行后出现崩溃的情况。语法为<code>assert (表达式)</code>。</p>
<p>其中<code>np.squeeze()</code>可以将数组变成一个向量。</p>
<h4 id="作业一">作业一</h4>
<p>使用numpy手写Logistic回归，这里只写回归部分，数据处理部分略过：</p>
<p>两个偏导数公式如下：</p>
<p>$$ \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T\tag{7}$$</p>
<p>$$ \frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})\tag{8}$$</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">172
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">sigmoid</span>(z):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">	sigmoid激活函数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">	&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    s = <span style="color:#b452cd">1.0</span> / (<span style="color:#b452cd">1.0</span> + np.exp(-<span style="color:#b452cd">1.0</span> * z))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> s
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">initialize_with_zeros</span>(dim):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Argument:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    dim -- 输入数据的维度
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    w -- 初始化维度为(dim, 1)的向量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    b -- 初始化标量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    w = np.zeros((dim,<span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>    b = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(w.shape == (dim, <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(<span style="color:#658b00">isinstance</span>(b, <span style="color:#658b00">float</span>) <span style="color:#8b008b">or</span> <span style="color:#658b00">isinstance</span>(b, <span style="color:#658b00">int</span>))
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> w, b
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">propagate</span>(w, b, X, Y):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    代价函数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Argument:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    w -- 权重
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    b -- 偏移量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- (num_px*num_px*3, 1)维度的数据
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- 维度为(1, 样本数量)标签
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    cost -- 代价
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    dw -- 损失相对于 w 的梯度，因此维度与 w 相同
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    db -- 损失相对于 b 的梯度，因此维度与 b 相同
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    m = X.shape[<span style="color:#b452cd">1</span>] <span style="color:#228b22"># 样本数量</span>
</span></span><span style="display:flex;"><span>    A = sigmoid(np.dot(w.T, X) + b) <span style="color:#228b22"># 预测值</span>
</span></span><span style="display:flex;"><span>    cost = -(<span style="color:#b452cd">1.0</span>/m) * np.sum(Y * np.log(A) + (<span style="color:#b452cd">1</span> - Y) * np.log(<span style="color:#b452cd">1</span> - A))
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    dw = (<span style="color:#b452cd">1.0</span>/m) * np.dot(X, (A - Y).T)
</span></span><span style="display:flex;"><span>    db = (<span style="color:#b452cd">1.0</span>/m) * np.sum(A - Y)
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(dw.shape == w.shape)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(db.shape == b.shape)
</span></span><span style="display:flex;"><span>    cost = np.squeeze(cost) <span style="color:#228b22"># 将数组转化为向量（这里为防止bug）</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(cost.shape == ())
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    grads = {<span style="color:#cd5555">&#34;dw&#34;</span>: dw,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;db&#34;</span>: db}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> grads, cost
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">optimize</span>(w, b, X, Y, num_iterations, learning_rate, print_cost = <span style="color:#8b008b;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    w和b的迭代优化
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Argument:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    w -- 权重
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    b -- 偏移量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- (num_px*num_px*3, 1)维度的数据
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- 维度为(1, 样本数量)标签
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    num_iterations -- 优化迭代的次数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- 学习率
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    print_cost -- 如果为true，每迭代100次打印一次损失
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    params -- 包含权重 w 和偏差 b 的字典
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- 包含权重梯度和相对于成本函数的偏差梯度的字典
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    costs -- 优化期间计算的所有成本的列表，这将用于绘制学习曲线。
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    costs = []
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(num_iterations):
</span></span><span style="display:flex;"><span>        grads, cost = propagate(w, b, X, Y)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>        dw = grads[<span style="color:#cd5555">&#34;dw&#34;</span>]
</span></span><span style="display:flex;"><span>        db = grads[<span style="color:#cd5555">&#34;db&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        w = w - learning_rate * dw
</span></span><span style="display:flex;"><span>        b = b - learning_rate * db
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> i % <span style="color:#b452cd">100</span>:
</span></span><span style="display:flex;"><span>            costs.append(cost)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> print_cost <span style="color:#8b008b">and</span> i % <span style="color:#b452cd">100</span> == <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;Cost after iteration </span><span style="color:#cd5555">%i</span><span style="color:#cd5555">:</span><span style="color:#cd5555">%f</span><span style="color:#cd5555">&#34;</span> %(i, cost))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    params = {<span style="color:#cd5555">&#34;w&#34;</span>: w,
</span></span><span style="display:flex;"><span>              <span style="color:#cd5555">&#34;b&#34;</span>: b}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    grads = {<span style="color:#cd5555">&#34;dw&#34;</span>: dw,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;db&#34;</span>: db}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> params, grads
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">predict</span>(w, b, X):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    使用学习的逻辑回归参数 (w, b) 预测标签是 0 还是 1
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    w -- 权重
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    b -- 偏移量
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- (num_px*num_px*3, 样本数量)维度的数据
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y_prediction -- 一个numpy数组（向量），包含X中示例的所有预测（0/1）
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    m = X.shape[<span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>    Y_prediction = np.zeros((<span style="color:#b452cd">1</span>,m))
</span></span><span style="display:flex;"><span>    w = w.reshape(X.shape[<span style="color:#b452cd">0</span>], <span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    A = sigmoid(np.dot(w.T, X) + b)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(A.shape[<span style="color:#b452cd">1</span>]):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> A[<span style="color:#b452cd">0</span>, i] &gt; <span style="color:#b452cd">0.5</span>:
</span></span><span style="display:flex;"><span>            Y_prediction[<span style="color:#b452cd">0</span>, i] = <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            Y_prediction[<span style="color:#b452cd">0</span>, i] = <span style="color:#b452cd">0</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(Y_prediction.shape == (<span style="color:#b452cd">1</span>, m))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> Y_prediction
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">model</span>(X_train, Y_train, X_test, Y_test, num_iterations = <span style="color:#b452cd">2000</span>, learning_rate = <span style="color:#b452cd">0.5</span>, print_cost = <span style="color:#8b008b;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    构建逻辑回归模型
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X_train -- 训练样本 shape:(num_px * num_px * 3, m_train)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y_train -- 训练标签 shape:(1, m_train)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X_test -- 测试样本 shape:(num_px * num_px * 3, m_test)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y_test -- 测试标签 shape:(1, m_test)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    num_iterations -- 迭代次数 默认为2000
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- 学习率 默认为0.5
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    print_cost -- 是否打印代价
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    d -- 包含模型信息的字典
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    w, b = initialize_with_zeros(X_train.shape[<span style="color:#b452cd">0</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 训练</span>
</span></span><span style="display:flex;"><span>    parameter, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 训练结果</span>
</span></span><span style="display:flex;"><span>    w = parameter[<span style="color:#cd5555">&#34;w&#34;</span>]
</span></span><span style="display:flex;"><span>    b = parameter[<span style="color:#cd5555">&#34;b&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 预测</span>
</span></span><span style="display:flex;"><span>    Y_prediction_test = predict(w, b, X_test)
</span></span><span style="display:flex;"><span>    Y_prediction_train = predict(w, b, X_train)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 打印预测结果</span>
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;训练集 预测准确率：</span><span style="color:#cd5555">{}</span><span style="color:#cd5555"> %&#34;</span>.format(<span style="color:#b452cd">100</span> - np.mean(np.abs(Y_prediction_train - Y_train)) * <span style="color:#b452cd">100</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;测试集 预测准确率：</span><span style="color:#cd5555">{}</span><span style="color:#cd5555"> %&#34;</span>.format(<span style="color:#b452cd">100</span> - np.mean(np.abs(Y_prediction_test - Y_test)) * <span style="color:#b452cd">100</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    d = {<span style="color:#cd5555">&#34;cost&#34;</span>: costs,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;测试集预测正确个数&#34;</span>: Y_prediction_test,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;训练集预测正确个数&#34;</span>: Y_prediction_train,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;w&#34;</span>: w,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;b&#34;</span>: b,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;学习率&#34;</span>: learning_rate,
</span></span><span style="display:flex;"><span>         <span style="color:#cd5555">&#34;迭代轮数&#34;</span>: num_iterations}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> d
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#228b22">## 最后就可以使用model函数对已经经过数据处理的训练集和测试集进行训练和预测了</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="神经网络编写">神经网络编写</h3>
<h4 id="神经网络表示">神经网络表示</h4>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img2.jpg" alt=""></p>
<p>如上图所示，这是一个<code>双层神经网络</code>（一般输入层不作为层数）。最左边为输入层，代表单个样本的输入特征数；中间为隐藏层；最右边为输出层，一般代表预测值。中间的隐藏层是代表特征与预测值关系的一些表达式，类似于机器学习中的$W$和$b$。在这个图中，$W$是一个$4\times 3$的矩阵，$b$是一个$4\times 1$的矩阵，4代表隐藏层的个数，3代表输入的特征。</p>
<p>*需要注意的是这里的W和Logistic中讲的W是不一样的：因为这里的W是指整个隐藏层的W，计算时不用转置（4$\times$</p>
<p>3）；而Logostic中的W相当于只有一个节点的W，且计算时需要转置(3$\times$1)。*</p>
<h4 id="神经网络的计算">神经网络的计算</h4>
<p>将每个隐藏层分开单独和左边的输入层结合在一起看，神经网络其实就是多个类似于Logistic回归的结构。</p>
<p>所以上图隐藏层的计算过程如下：
$$
z^{[1]}_1 = {w^{[1]}_1}^{T}x+b^{[1]}_1,a^{[1]}_1=\sigma(z^{[1]}_1)\
z^{[1]}_2 = {w^{[1]}_2}^{T}x+b^{[1]}_2,a^{[1]}_2=\sigma(z^{[1]}_2)\
z^{[1]}_3 = {w^{[1]}_3}^{T}x+b^{[1]}_3,a^{[1]}_3=\sigma(z^{[1]}_3)\
z^{[1]}_4 = {w^{[1]}_4}^{T}x+b^{[1]}_4,a^{[1]}_4=\sigma(z^{[1]}_4)\
其中[]里代表的数字是第几层,这里是从隐藏层算起\下标的值代表的是该层的第几个节点\
\sigma(z)代表激活函数
$$
所以将上面的双层神经网络整个计算过程合并起来就变成了：
$$
第一层：隐藏层\
z^{[1]}=W^{[1]}x+b^{[1]}\
a^{[1]}=\sigma(z^{[1]})\
第二层：输出层\
z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}\
a^{[2]}=\sigma(z^{[2]})
$$</p>
<h4 id="多个样本的向量化">多个样本的向量化</h4>
<p>上面讲的计算过程是单个样本的计算过程，如果是多个样本，就要使用一个循环来计算。但是前面讲过样本的遍历可以使用向量化技术来加快运算速度。</p>
<p>所以我们把z和a关于样本的多个列合并在一起：
$$
Z^{[1]}=[z^{<a href="1">1</a>},z^{<a href="2">1</a>},\dots z^{<a href="m">1</a>}]\
A^{[1]}=[a^{<a href="1">1</a>},a^{<a href="2">1</a>},\dots a^{<a href="m">1</a>}]\
Z^{[2]}=[z^{<a href="1">2</a>},z^{<a href="2">2</a>},\dots z^{<a href="m">2</a>}]\
A^{[2]}=[a^{<a href="1">2</a>},a^{<a href="2">2</a>},\dots a^{<a href="m">2</a>}]\
m代表样本的数量,[]的值代表不同的层，行代表不同的节点(也叫隐藏单元)，列代表不同的样本
$$
所以计算过程变为了：
$$
Z^{[1]}=W^{[1]}X+b^{[1]}\
A^{[1]}=\sigma(Z^{[1]})\
Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}\
A^{[2]}=\sigma(Z^{[2]})\
这里的b不需要变是因为python自带的广播技术
$$</p>
<h4 id="多种激活函数">多种激活函数</h4>
<p>上面我们使用的激活函数为$\sigma(z)$也就是<code>sigmoid函数</code>。现在我们要介绍多种激活函数来进行对比：</p>
<ul>
<li>$tanh(z)$:</li>
</ul>
<p>$$
a=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\quad \quad 它的取值范围在[-1,1]\
$$</p>
<p>图像如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img4.jpg" alt=""></p>
<p>该函数的特点是所有的数据平均值接近0，如果需要进行该种数据中心化可以使用该函数。</p>
<p>通常来说激活函数选取$tanh(z)$都比使用<code>sigmoid</code>函数更好。但有一个例外是输出层，输出层经常使用<code>sigmoid函数</code>，或者使用二元分类时，使用<code>sigmoid函数</code>。为了表示不同的层之间使用不同的激活函数，我们通常会将激活函数用$g$来表示，使用$g^{[i]}$表示第i层的激活函数。</p>
<p><code>sigmoid函数</code>和$tanh(z)$函数共同的缺点是当$z$的值很大或者很小的时候，函数的斜率很接近0，也就是我们经常会说的梯度消失，拖慢梯度下降算法。</p>
<ul>
<li>ReLU：</li>
</ul>
<p>$$
a=max(0,z)
$$</p>
<p>图像如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img5.jpg" alt=""></p>
<ul>
<li>
<p>Leaky ReLU：
$$
a=max(cz,z)\quad \quad  c在这里是一个常数，通常取一个比较小的数，比如0.01或者0.001
$$
图像如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img6.jpg" alt=""></p>
<p>ReLU的缺点是，当$z$的值为负数的时候，它没有导数值。而Leaky ReLU解决了这个问题。</p>
</li>
</ul>
<blockquote>
<p>激活函数如何选择？</p>
</blockquote>
<p>激活函数的选择经验：</p>
<p>1.如果你在做二元分类时，输出一般为0或1，那么该网络的输出层激活函数选择sigmoid函数较好，其他所有单元都使用ReLU函数。使用ReLU函数最大的好处就是梯度下降比较快，也就是收敛的比较快。</p>
<p>2.有时候特定情况下会使用tanh(z)函数。</p>
<p>3.ReLU函数是最常用的激活函数</p>
<blockquote>
<p>为什么神经网络需要使用激活函数？</p>
</blockquote>
<p>我们来做一个公式推导：
$$
如果不使用激活函数:\
a^{[1]}=z^{[1]}=W^{[1]}x+b^{[1]}\
a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=(W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]})\
=W^{&rsquo;}x+b^{&rsquo;}
$$
可以看到如果不使用激活函数，无论你使用多庞大的神经网络，都始终在做线性激活函数，这就退化成了线形回归的内容。</p>
<h4 id="激活函数的导数">激活函数的导数</h4>
<p>当你使用神经网络进行反向传播时，需要计算激活函数的斜率或者导数。</p>
<ul>
<li>sigmoid函数</li>
</ul>
<p>$$
a=g(z)=\frac{1}{1+e^{-z}}\
g^{&rsquo;}(z)=\frac{dg(z)}{dz}=\frac{1}{1+e^{-z}}(1-\frac{1}{1+e^{-z}})=g(z)(1-g(z))=a(1-a)
$$</p>
<ul>
<li>tanh函数</li>
</ul>
<p>$$
a=g(z)=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\
g^{&rsquo;}(z)=\frac{dg(z)}{dz}=1-(\frac{e^z-e^{-z}}{e^z+e^{-z}})^2=1-g(z)^2=1-a^2
$$</p>
<ul>
<li>ReLU</li>
</ul>
<p>$$
a=g(z)=max(0,z)\
g^{&rsquo;}(z)=\begin{cases}
0,&amp; \text{如果}z&lt;0\
1,&amp; \text{如果}z&gt;0\
undefined,&amp;\text{如果}z=0
\end{cases}
$$</p>
<ul>
<li>Leaky ReLU</li>
</ul>
<p>$$
g(z)=max(0.01z,z)\
g^{&rsquo;}(z)=\begin{cases}
0.01&amp; \text{如果}z&lt;0\
1&amp; \text{如果}z&gt;0
\end{cases}
$$</p>
<h4 id="神经网络的梯度下降法">神经网络的梯度下降法</h4>
<p>以单隐藏层为例，写出它们的正向传播和反向传播的过程：</p>
<ul>
<li>正向传播：</li>
</ul>
<p>$$
Z^{[1]}=W^{[1]}X+b^{[1]}\
A^{[1]}=\sigma(Z^{[1]})\
Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}\
A^{[2]}=\sigma(Z^{[2]})
$$</p>
<ul>
<li>反向传播：</li>
</ul>
<p>$$
dZ^{[2]}=A^{[2]}-Y\
dW^{[2]}=\frac{1}{m}dZ^{[2]}{A^{[1]}}^T\
db^{[2]}=\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\
dZ^{[1]}={W^{[2]}}^TdZ^{[2]}<em>{g^{[1]}}^{&rsquo;}(Z^{[1]})\
这里的</em>代表逐个元素乘积\
dW^{[1]}=\frac{1}{m}dZ^{[1]}X^T\
db^{[1]}=\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)
$$</p>
<blockquote>
<p>np.sum的axis不同时：</p>
<p>1.np.sum(axis = 0)代表矩阵最外维度相加（如果最外维度为n，可以理解为n个二维矩阵直接相加）</p>
<p>2.np.sum(axis = 1)代表矩阵中间维度相加（相当于是二维矩阵内部对每列求和）</p>
<p>3.np.sum(axis = 2)代表矩阵最内维度相加（相当于是二维矩阵内部对每行求和）</p>
<p>keepdims=True是为了保证不输出秩为1的数组</p>
</blockquote>
<h4 id="随机初始化">随机初始化</h4>
<p>在Logistic回归中，我们把$w$和$b$都初始化为0向量，在神经网络中$W$不能这么初始化为0矩阵。因为这样会导致第一层在做计算时，每个隐藏单元所做的计算都是一模一样的，在反向传播时，不同隐藏单元激活函数的导数$dz^{[1]}_1$和$dz^{[1]}_2$是一样的。</p>
<p>我们的做法一般是对$W$随机初始化:
$$
W^{[1]}=np.random.randn((x,y))\times 0.01\
b^{[2]}=np.zeros((y,1))\
0.01代表权重，一般取比较小的值,这样能使梯度下降更快一些\这在使用sigmoid作为激活函数的网络更为明显（z值太大,导数接近0）；\x代表输入层的特征数；\y代表隐藏层的隐藏单元数目。
$$</p>
<h4 id="作业二">作业二</h4>
<p>写一个双层神经网络(没有数据处理的部分)：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">172
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">173
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">174
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">175
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">176
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">177
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">178
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">179
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">180
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">181
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">182
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">183
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">184
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">185
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">186
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">187
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">188
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">189
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">190
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">191
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">192
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">193
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">194
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">195
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">196
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">197
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">198
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">199
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">200
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">201
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">202
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">203
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">204
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">205
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">206
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">207
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">208
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">209
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">210
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">211
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">212
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">213
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">214
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">215
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">216
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">217
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">218
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">219
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">220
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">221
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">222
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">223
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">224
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">225
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">226
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">227
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">228
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">229
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">230
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">231
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">232
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">233
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">234
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">235
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">236
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">237
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">238
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">239
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">240
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">241
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">242
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">243
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">244
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">245
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">246
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">247
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">248
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">249
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">250
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">251
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">252
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">253
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">254
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">255
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">256
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">257
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">258
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">259
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">260
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">261
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">262
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">263
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">264
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">265
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">266
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">267
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">268
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">269
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">270
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">271
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">272
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">273
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">274
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">matplotlib.pyplot</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">plt</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">sigmoid</span>(z):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">	sigmoid激活函数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">	&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    s = <span style="color:#b452cd">1.0</span> / (<span style="color:#b452cd">1.0</span> + np.exp(-<span style="color:#b452cd">1.0</span> * z))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> s
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">layer_sizes</span>(X, Y):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- 输入数据 (输入层大小, 样本数量)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- 标签 (输出层大小, 样本数量)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_x -- 输入层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_h -- 隐藏层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_y -- 输出层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    n_x = X.shape[<span style="color:#b452cd">0</span>] <span style="color:#228b22"># 输入层的大小</span>
</span></span><span style="display:flex;"><span>    n_h = <span style="color:#b452cd">4</span>
</span></span><span style="display:flex;"><span>    n_y = Y.shape[<span style="color:#b452cd">0</span>] <span style="color:#228b22"># 输出层的大小</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> (n_x, n_h, n_y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">initialize_parameters</span>(n_x, n_h, n_y):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_x -- 输入层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_h -- 隐藏层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_y -- 输出层的大小
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    params -- 初始化参数的字典:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">              W1 -- weight matrix of shape (n_h, n_x)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">              b1 -- bias vector of shape (n_h, 1)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">              W2 -- weight matrix of shape (n_y, n_h)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">              b2 -- bias vector of shape (n_y, 1)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    np.random.seed(<span style="color:#b452cd">2</span>) <span style="color:#228b22"># 设置随机种子</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    W1 = np.random.randn((n_h, n_x))
</span></span><span style="display:flex;"><span>    b1 = np.zeros((n_h, <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>    W2 = np.random.rand((n_y, n_h))
</span></span><span style="display:flex;"><span>    b2 = np.zeros((n_y, <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(W1.shape == (n_h, n_x))
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(b1.shape == (n_h, <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(W2.shape == (n_y, n_h))
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(b2.shape == (n_y, <span style="color:#b452cd">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    parameters = {<span style="color:#cd5555">&#34;W1&#34;</span>: W1,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;b1&#34;</span>: b1,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;W2&#34;</span>: W2,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;b2&#34;</span>: b2}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward_propagation</span>(X, parameters):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    前向传播计算
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Argument:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- 输入数据 (n_x, m)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 初始化参数的字典 (output of initialization function)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    A2 -- 第二层sigmoid激活函数输出的结果
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    cache -- 中间权向量的字典 &#34;Z1&#34;, &#34;A1&#34;, &#34;Z2&#34; and &#34;A2&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>    
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    W1 = parameters[<span style="color:#cd5555">&#34;W1&#34;</span>]
</span></span><span style="display:flex;"><span>    b1 = parameters[<span style="color:#cd5555">&#34;b1&#34;</span>]
</span></span><span style="display:flex;"><span>    W2 = parameters[<span style="color:#cd5555">&#34;W2&#34;</span>]
</span></span><span style="display:flex;"><span>    b2 = parameters[<span style="color:#cd5555">&#34;b2&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Z1 = np.dot(W1, X) + b1 <span style="color:#228b22"># b1使用广播技术自动扩充</span>
</span></span><span style="display:flex;"><span>    A1 = np.tanh(Z1) <span style="color:#228b22"># 隐藏层使用tanh激活函数</span>
</span></span><span style="display:flex;"><span>    Z2 = np.dot(W2, A1) + b2 <span style="color:#228b22"># b2使用广播技术自动扩充</span>
</span></span><span style="display:flex;"><span>    A2 = sigmoid(Z2) <span style="color:#228b22"># 输出层使用sigmoid激活函数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(A2.shape == (<span style="color:#b452cd">1</span>, X.shape[<span style="color:#b452cd">1</span>])) <span style="color:#228b22"># X.shape[1]代表样本数量</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cache = {<span style="color:#cd5555">&#34;Z1&#34;</span>: Z1,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;A1&#34;</span>: A1,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;Z2&#34;</span>: Z2,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;A2&#34;</span>: A2}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> A2, cache
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">compute_cost</span>(A2, Y, parameters):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    计算代价函数 (13)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    A2 -- 第二层sigmoid激活函数输出的结果 维度(1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- 正确的标签 维度(1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 初始化参数的字典 W1, b1, W2 and b2
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    cost -- 代价函数结果
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    m = Y.shape[<span style="color:#b452cd">1</span>] <span style="color:#228b22"># 样本数量</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 计算代价函数</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># np.multiply(X, Y)是指X和Y对应位置两两相乘</span>
</span></span><span style="display:flex;"><span>    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(<span style="color:#b452cd">1</span> - A2), <span style="color:#b452cd">1</span> - Y)
</span></span><span style="display:flex;"><span>    cost = -np.sum(logprobs) / m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cost = np.squeeze(cost) <span style="color:#228b22"># 确保代价为我们期望的维度</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># isinstance() 函数来判断一个对象是否是一个已知的类型</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">assert</span>(<span style="color:#658b00">isinstance</span>(cost, <span style="color:#658b00">float</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">backward_propagation</span>(parameters, cache, X, Y):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    后向传播
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 参数初始化字典 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    cache -- 中间权向量的字典 &#34;Z1&#34;, &#34;A1&#34;, &#34;Z2&#34; and &#34;A2&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- 输入数据 维度(2, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- 正确标签 维度(1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- 参数渐变的字典
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    m = X.shape[<span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    W1 = parameters[<span style="color:#cd5555">&#34;W1&#34;</span>]
</span></span><span style="display:flex;"><span>    W2 = parameters[<span style="color:#cd5555">&#34;W2&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    A1 = cache[<span style="color:#cd5555">&#34;A1&#34;</span>]
</span></span><span style="display:flex;"><span>    A2 = cache[<span style="color:#cd5555">&#34;A2&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 后向传播计算</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># tanh()函数的导数为 g&#39;(a) = 1 - a^2</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    dZ2 = A2 - Y
</span></span><span style="display:flex;"><span>    dW2 = np.dot(dZ2, A1.T) / m
</span></span><span style="display:flex;"><span>    db2 = np.sum(dZ2, axis=<span style="color:#b452cd">1</span>, keepdims=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>    dZ1 = np.multiply(np.dot(W2.T, dZ2), <span style="color:#b452cd">1</span> - np.power(A1, <span style="color:#b452cd">2</span>)) <span style="color:#228b22"># 1-np.power(A1, 2)为tanh的导数</span>
</span></span><span style="display:flex;"><span>    dW1 = np.dot(dZ1, X.T) / m
</span></span><span style="display:flex;"><span>    db1 = np.sum(dZ1, axis=<span style="color:#b452cd">1</span>, keepdims=<span style="color:#8b008b;font-weight:bold">True</span>)/ m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    grads = {<span style="color:#cd5555">&#34;dW1&#34;</span>: dW1,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;db1&#34;</span>: db1,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;dW2&#34;</span>: dW2,
</span></span><span style="display:flex;"><span>             <span style="color:#cd5555">&#34;db2&#34;</span>: db2}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> grads
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">update_parameters</span>(parameters, grads, learning_rate = <span style="color:#b452cd">1.2</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    中间权重向量更新
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 更新前的参数 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- 用于参数更新的逆向传播参数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 更新后的参数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    W1 = parameters[<span style="color:#cd5555">&#34;W1&#34;</span>]
</span></span><span style="display:flex;"><span>    b1 = parameters[<span style="color:#cd5555">&#34;b1&#34;</span>]
</span></span><span style="display:flex;"><span>    W2 = parameters[<span style="color:#cd5555">&#34;W2&#34;</span>]
</span></span><span style="display:flex;"><span>    b2 = parameters[<span style="color:#cd5555">&#34;b2&#34;</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    dW1 = grads[<span style="color:#cd5555">&#34;dW1&#34;</span>]
</span></span><span style="display:flex;"><span>    db1 = grads[<span style="color:#cd5555">&#34;db1&#34;</span>]
</span></span><span style="display:flex;"><span>    dW2 = grads[<span style="color:#cd5555">&#34;dW2&#34;</span>]
</span></span><span style="display:flex;"><span>    db2 = grads[<span style="color:#cd5555">&#34;db2&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 权重向量更新</span>
</span></span><span style="display:flex;"><span>    W1 = W1 - dW1 * learning_rate
</span></span><span style="display:flex;"><span>    b1 = b1 - db1 * learning_rate
</span></span><span style="display:flex;"><span>    W2 = W2 - dW2 * learning_rate
</span></span><span style="display:flex;"><span>    b2 = b2 - db2 * learning_rate
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    parameters = {<span style="color:#cd5555">&#34;W1&#34;</span>: W1,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;b1&#34;</span>: b1,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;W2&#34;</span>: W2,
</span></span><span style="display:flex;"><span>                  <span style="color:#cd5555">&#34;b2&#34;</span>: b2}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">nn_model</span>(X, Y, n_h, num_iterations = <span style="color:#b452cd">10000</span>, print_cost=<span style="color:#8b008b;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- dataset of shape (2, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- labels of shape (1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    n_h -- size of the hidden layer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    num_iterations -- 循环迭代的次数
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    print_cost -- 如果为True,每1000次打印一次代价
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- 训练好的参数，用于预测
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    np.random.seed(<span style="color:#b452cd">3</span>)
</span></span><span style="display:flex;"><span>    n_x = layer_sizes(X, Y)[<span style="color:#b452cd">0</span>]
</span></span><span style="display:flex;"><span>    n_y = layer_sizes(X, Y)[<span style="color:#b452cd">2</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    parameters = initialize_parameters(n_x, n_h, n_y)
</span></span><span style="display:flex;"><span>    W1 = parameters[<span style="color:#cd5555">&#34;W1&#34;</span>]
</span></span><span style="display:flex;"><span>    b1 = parameters[<span style="color:#cd5555">&#34;b1&#34;</span>]
</span></span><span style="display:flex;"><span>    W2 = parameters[<span style="color:#cd5555">&#34;W2&#34;</span>]
</span></span><span style="display:flex;"><span>    b2 = parameters[<span style="color:#cd5555">&#34;b2&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># 循环</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(<span style="color:#b452cd">0</span>, num_iterations):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 计算前向传播</span>
</span></span><span style="display:flex;"><span>        A2, cache = forward_propagation(X, parameters)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 计算代价</span>
</span></span><span style="display:flex;"><span>        cost = compute_cost(X, parameters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 计算后向传播</span>
</span></span><span style="display:flex;"><span>        grads = backward_propagation(parameters, cache, X, Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 更新权向量</span>
</span></span><span style="display:flex;"><span>        parameters = update_parameters(parameters, grads) <span style="color:#228b22"># 学习率直接设置为默认值1.2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> print_cost <span style="color:#8b008b">and</span> (i % <span style="color:#b452cd">1000</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;第i次迭代之后的代价为:&#34;</span> + <span style="color:#658b00">str</span>(cost))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># ----------------------------------------- </span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">predict</span>(parameters, X):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    通过训练好的权重来预测X的类型
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- 输入数据 维度 (n_x, m)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    predictions -- 模型预测的结果 (red: 0 / blue: 1)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    A2, cache = forward_propagation(X, parameters)
</span></span><span style="display:flex;"><span>    prediction = (A2 &gt; <span style="color:#b452cd">0.5</span>) <span style="color:#228b22"># sigmoid函数的判别方式</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> prediction
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># -----------------------------------------</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 使用：</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 构建双层神经网络模型</span>
</span></span><span style="display:flex;"><span>parameters = nn_model(X, Y, n_h=<span style="color:#b452cd">4</span>, num_iterations=<span style="color:#b452cd">10000</span>, print_cost=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 绘制决策边界</span>
</span></span><span style="display:flex;"><span>plot_decision_boundary(<span style="color:#8b008b;font-weight:bold">lambda</span> x: predict(parameters, x.T), X, Y[<span style="color:#b452cd">0</span>, :])
</span></span><span style="display:flex;"><span>plt.title(<span style="color:#cd5555">&#34;Decision Boundary for hidden layer size &#34;</span> + <span style="color:#658b00">str</span>(<span style="color:#b452cd">4</span>))
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>因为有部分公式可能因为博客插件不支持的原因，完整的笔记请看:</strong>
<a href="https://github.com/caixiongjiang/deep-learning-computer-vision">https://github.com/caixiongjiang/deep-learning-computer-vision</a></p>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2022-07-12</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts">
			下回<br>已经到头啦。
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC13%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
			上回<br>第十三讲：heap&amp;priority_queue深度探索
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2022 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
