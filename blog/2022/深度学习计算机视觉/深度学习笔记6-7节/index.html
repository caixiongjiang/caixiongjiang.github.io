<!DOCTYPE html>
<html><head>
<title>深度学习笔记（6-7节） </title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="毕业设计可能会使用深度学习，从暑假开始从头学习">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="深度学习笔记（6-7节） " />
<meta property="og:description" content="毕业设计可能会使用深度学习，从暑假开始从头学习" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-7%E8%8A%82/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2022-07-22T18:18:05+08:00" />
<meta property="article:modified_time" content="2022-07-23T09:19:06+08:00" />












<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="https://jarson-cai.gitee.io/jarson-cai-blog">
    MiFeng
</a>
<br>

<a href="nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2022 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a06-7%e8%8a%82" onclick="onNavClick(`#深度学习6-7节-nav`)" id="深度学习6-7节-nav">
									深度学习（6-7节）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e4%bc%98%e5%8c%96%e7%ae%97%e6%b3%95" onclick="onNavClick(`#优化算法-nav`)" id="优化算法-nav">
									优化算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#mini-batch%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#mini-batch梯度下降法-nav`)" id="mini-batch梯度下降法-nav">
									Mini-batch梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%8c%87%e6%95%b0%e5%8a%a0%e6%9d%83%e5%b9%b3%e5%9d%87" onclick="onNavClick(`#指数加权平均-nav`)" id="指数加权平均-nav">
									指数加权平均
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%8a%a8%e9%87%8f%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#动量梯度下降法-nav`)" id="动量梯度下降法-nav">
									动量梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#rmsprop%e7%ae%97%e6%b3%95" onclick="onNavClick(`#rmsprop算法-nav`)" id="rmsprop算法-nav">
									RMSprop算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#adam%e7%ae%97%e6%b3%95" onclick="onNavClick(`#adam算法-nav`)" id="adam算法-nav">
									Adam算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%a6%e4%b9%a0%e7%8e%87%e8%a1%b0%e5%87%8f" onclick="onNavClick(`#学习率衰减-nav`)" id="学习率衰减-nav">
									学习率衰减
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%ba%94" onclick="onNavClick(`#作业五-nav`)" id="作业五-nav">
									作业五
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e8%b6%85%e5%8f%82%e6%95%b0%e8%b0%83%e8%af%95" onclick="onNavClick(`#超参数调试-nav`)" id="超参数调试-nav">
									超参数调试
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e8%b0%83%e8%af%95%e5%a4%84%e7%90%86" onclick="onNavClick(`#调试处理-nav`)" id="调试处理-nav">
									调试处理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%b8%ba%e8%b6%85%e5%8f%82%e6%95%b0%e9%80%89%e6%8b%a9%e5%90%88%e9%80%82%e7%9a%84%e8%8c%83%e5%9b%b4" onclick="onNavClick(`#为超参数选择合适的范围-nav`)" id="为超参数选择合适的范围-nav">
									为超参数选择合适的范围
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%b6%85%e5%8f%82%e6%95%b0%e8%ae%ad%e7%bb%83%e6%96%b9%e5%bc%8fpanda-vs-caviar" onclick="onNavClick(`#超参数训练方式panda-vs-caviar-nav`)" id="超参数训练方式panda-vs-caviar-nav">
									超参数训练方式：Panda VS Caviar
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bd%92%e4%b8%80%e5%8c%96%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#归一化网络-nav`)" id="归一化网络-nav">
									归一化网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#softmax%e5%9b%9e%e5%bd%92" onclick="onNavClick(`#softmax回归-nav`)" id="softmax回归-nav">
									softmax回归
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6" onclick="onNavClick(`#深度学习框架-nav`)" id="深度学习框架-nav">
									深度学习框架
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e5%85%ad" onclick="onNavClick(`#作业六-nav`)" id="作业六-nav">
									作业六
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a06-7%e8%8a%82" onclick="onNavClick(`#深度学习6-7节-nav`)" id="深度学习6-7节-nav">
									深度学习（6-7节）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e4%bc%98%e5%8c%96%e7%ae%97%e6%b3%95" onclick="onNavClick(`#优化算法-nav`)" id="优化算法-nav">
									优化算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#mini-batch%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#mini-batch梯度下降法-nav`)" id="mini-batch梯度下降法-nav">
									Mini-batch梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%8c%87%e6%95%b0%e5%8a%a0%e6%9d%83%e5%b9%b3%e5%9d%87" onclick="onNavClick(`#指数加权平均-nav`)" id="指数加权平均-nav">
									指数加权平均
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%8a%a8%e9%87%8f%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95" onclick="onNavClick(`#动量梯度下降法-nav`)" id="动量梯度下降法-nav">
									动量梯度下降法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#rmsprop%e7%ae%97%e6%b3%95" onclick="onNavClick(`#rmsprop算法-nav`)" id="rmsprop算法-nav">
									RMSprop算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#adam%e7%ae%97%e6%b3%95" onclick="onNavClick(`#adam算法-nav`)" id="adam算法-nav">
									Adam算法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%a6%e4%b9%a0%e7%8e%87%e8%a1%b0%e5%87%8f" onclick="onNavClick(`#学习率衰减-nav`)" id="学习率衰减-nav">
									学习率衰减
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e4%ba%94" onclick="onNavClick(`#作业五-nav`)" id="作业五-nav">
									作业五
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e8%b6%85%e5%8f%82%e6%95%b0%e8%b0%83%e8%af%95" onclick="onNavClick(`#超参数调试-nav`)" id="超参数调试-nav">
									超参数调试
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e8%b0%83%e8%af%95%e5%a4%84%e7%90%86" onclick="onNavClick(`#调试处理-nav`)" id="调试处理-nav">
									调试处理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%b8%ba%e8%b6%85%e5%8f%82%e6%95%b0%e9%80%89%e6%8b%a9%e5%90%88%e9%80%82%e7%9a%84%e8%8c%83%e5%9b%b4" onclick="onNavClick(`#为超参数选择合适的范围-nav`)" id="为超参数选择合适的范围-nav">
									为超参数选择合适的范围
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%b6%85%e5%8f%82%e6%95%b0%e8%ae%ad%e7%bb%83%e6%96%b9%e5%bc%8fpanda-vs-caviar" onclick="onNavClick(`#超参数训练方式panda-vs-caviar-nav`)" id="超参数训练方式panda-vs-caviar-nav">
									超参数训练方式：Panda VS Caviar
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bd%92%e4%b8%80%e5%8c%96%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#归一化网络-nav`)" id="归一化网络-nav">
									归一化网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#softmax%e5%9b%9e%e5%bd%92" onclick="onNavClick(`#softmax回归-nav`)" id="softmax回归-nav">
									softmax回归
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6" onclick="onNavClick(`#深度学习框架-nav`)" id="深度学习框架-nav">
									深度学习框架
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e4%bd%9c%e4%b8%9a%e5%85%ad" onclick="onNavClick(`#作业六-nav`)" id="作业六-nav">
									作业六
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img_title.jpg')"
                    
                
            >
                <div class="post-title">
                    深度学习笔记（6-7节） 
                    
                    <div class="post-subtitle">
                        毕业设计可能会使用深度学习，从暑假开始从头学习
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2022-07-22 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[深度学习]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/deep_learning">Deep_learning</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            41 min
                            
                            39 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="深度学习6-7节">深度学习（6-7节）</h2>
<h3 id="优化算法">优化算法</h3>
<h4 id="mini-batch梯度下降法">Mini-batch梯度下降法</h4>
<p>假设我们的样本数量为500w个，那么在进行梯度下降之前，我们需要先将500w个数据整合成一个大的向量$X$。Mini-batch的做法为将500w个样本按照每个子集为1000个样本等分。每个子集标记为$X^{\left{ 1\right}  }X^{\left{ 2\right}  },\dots,X^{\left{ 5000\right}  }$。相应的，除了需要拆分$X$，也需要拆分标签$Y$，拆分的方法和$X$相同。</p>
<p><strong>Mini-batch的原理是将同时原本对所有样本和标签同时进行梯度下降转变为同时只对一个子集进行梯度下降处理，处理5000次</strong>。需要注意代价函数也要改变，因为每次训练的样本个数改变了。</p>
<p>当你的<strong>训练集大小很大</strong>的时候，mini-batch梯度下降法比batch梯度下降法运行地更快。</p>
<p>batch梯度下降法和Mini-batch梯度下降法的代价随迭代的图像如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img22.jpg" alt=""></p>
<p>右边的图像出现波动的原因是：每次实现梯度下降的样本集不同，可能$X^{\left{ 1\right}  }$和$Y^{\left{ 1\right}  }$需要花费的代价更大，而$X^{\left{ 2\right}  }$和$Y^{\left{ 2\right}  }$花费的代价更少，从而形成一个噪声的现象。</p>
<p>那么mini-bash的大小如何决定呢？</p>
<blockquote>
<p>先看两种极端情况：</p>
<p>如果子集的大小为m，那么mini-bash梯度下降就变成了batch梯度下降；</p>
<p>如果子集的大小为1，那么mini-bash梯度下降就变成了<code>随机梯度下降法</code>，每个样本都是一个子集；</p>
<p>batch梯度下降每次下降的噪声会小一点，幅度会大一点（这里的噪声是指梯度下降的方向偏离目标）；而随机梯度下降大部分时间会向着全局最小值逼近，但有时候会远离最小值（刚好该样本是一个&rsquo;&lsquo;坏&rsquo;&lsquo;样本），随机梯度下降法永远不会收敛，而是会一直在最小值附近波动。</p>
<p>batch梯度下降在训练数据很大的时候，单次训练迭代时间过长，如果训练数据量较小的情况下效果较好；而随机梯度下降单次迭代很快，但却无法使用向量化技术对运算进行加速。我们的目的就是选择一个不大不小的size，使得我们的学习速率达到最快（梯度下降）。</p>
<p>最优的情况就是，单次选取的size大小的数据分布比较符合整体数据的分布，这样使得学习速率和运行效率都比较高。</p>
</blockquote>
<h4 id="指数加权平均">指数加权平均</h4>
<p>指数加权平均也称指数加权移动平均，通过它可以来计算局部的平均值，来描述数值的变化趋势，下面通过一个温度的例子来详细介绍一下。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img23.jpg" alt=""></p>
<p>上图是温度随时间变化的图像，我们通过温度的局部平均值（移动平均值）来描述温度的变化趋势，计算公式如下：
$$
v_t=\beta v_{t-1}+(1-\beta)\theta_{t}\
v_0=0\
v_1=0.9v_0+0.1\theta_1\
v_2=0.9v_1+0.1\theta_2\
\theta 代表当天的温度，v代表局部平均值
$$
当$\beta$为0.9时，可以将$v_t$看作$\frac{1}{1-\beta}=\frac{1}{1-0.9}=10$天的平均值。</p>
<p>当$\beta$变得越小，移动平均值的波动越大。</p>
<p>通过上面的公式往下推到，可以得到$v_{100}$的表达式：
$$
v_{100}=0.1\times\theta_{100}+0.1\times0.9\times\theta_{99}+\dots+0.1\times0.9^{99}\times\theta_1\
=0.1\times\sum_{i=1}^{100}0.9^{100-i}\times\theta_i
$$
当$\epsilon=1-\beta$时，$(1-\beta)^{\frac{1}{\epsilon}}\approx\frac{1}{e}\approx\frac{1}{1-\beta}$，所以可以将$v_t$看作$\frac{1}{1-\beta}=\frac{1}{1-0.9}=10$天的平均值。</p>
<blockquote>
<p>简单来说，普通的加权求平均值的方法每一项的权重是$\frac{1}{n}$，指数加权平均每一项的权重是指数递减的。</p>
</blockquote>
<ul>
<li>指数加权平均的偏差修正</li>
</ul>
<p>由于我们初始设置的$v_0$为0，这样会使前面几个$v_1,v_2\dots$的值与实际值相比偏小，我们通常会采取以下的办法来修正偏差：
$$
v_t=\frac{\beta v_{t-1}+(1-\beta)\theta_t}{1-\beta^t}
$$
这样修正的效果为随着t的增加，分母越来越接近1。相当于时间越短，修正的幅度越大，所以这个公式主要是为了修正早期的偏差。</p>
<h4 id="动量梯度下降法">动量梯度下降法</h4>
<p>我们将上面所说的<code>指数加权平均</code>的做法应用于神经网络的反向传播过程，如下：
$$
V_{dW}=\beta V_{dW}+(1-\beta)dW\
V_{db}=\beta V_{db}+(1-\beta)db\
W:=W-\alpha V_{dW},b:=b-\alpha V_{db}
$$
这样做可以减缓梯度下降的幅度，因为梯度下降不一定朝着最快的方向前进。如下图所示：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img24.jpg" alt=""></p>
<p>原本为蓝色的梯度下降会变成红色，纵轴摆动的方向变小了且上下摆动的幅度均值大概为0。这样一来，即使我增加学习率或者步长也不会出现紫色线这种偏离函数的情况。</p>
<p><em>$\beta$最常用的值为0.9，按照道理来说需要加上偏差修正。但实际上不会这么做，因为经过10次迭代之后，移动平均已经过了初始阶段，不再是一个具有偏差的预测值。</em></p>
<h4 id="rmsprop算法">RMSprop算法</h4>
<p>通过前面的算法可知，我们加快学习效率的方法是增加$W$方向的学习速率（图中的水平方向），降低$b$方向的学习速率（垂直方向）。公式如下：
$$
S_{dW}=\beta S_{dW}+(1-\beta)(dW)^2\
S_{db}=\beta S_{db}+(1-\beta)(db)^2\
W:=W-\alpha\frac{dW}{\sqrt{S_{dW}}+\epsilon}\
b:=b-\alpha\frac{db}{\sqrt{S_{db}}+\epsilon}\
式中，S_{dW}和S_{db}表示权重W和偏置值b在t−1轮迭代中的梯度动量\
超参数β一般取值为0.9，学习率\alpha一般取值为 0.001，ε是防止分母为零，一般去10^{-8}。
$$
我们会希望$S_{db}$较大，$S_{dW}$较小，这样可以使得$W$方向的变化更大，$b$方向的变化更小。结果变化如下图：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img25.jpg" alt=""></p>
<h4 id="adam算法">Adam算法</h4>
<p>Adam算法是将动量梯度下降法和RMSprop算法结合起来，公式如下：
$$
首先初始化V_{dW}=0,S_{dW}=0,V_{db}=0,S_{db}=0\
在第t次迭代时：\
使用当前的mini-batch计算dW,db\
V_{dW}=\beta_1V_{dW}+(1-\beta_1)dW,V_{db}=\beta_1V_{db}+(1-\beta)db\quad 动量梯度下降\
S_{dW}=\beta_2S_{dW}+(1-\beta_2)(dW)^2,S_{db}=\beta_2S_{db}+(1-\beta_2)(db)^2\quad SMSprob\
V_{dW}^{correct}=\frac{V_{dW}}{1-(\beta_1)^t},V_{db}^{correct}=\frac{V_{db}}{1-(\beta_1)^t}\
S_{dW}^{correct}=\frac{S_{dW}}{1-(\beta_2)^t},S_{db}^{correct}=\frac{S_{db}}{1-(\beta_2)^t}\
W:=W-\alpha\frac{V_{dW}^{correct}}{\sqrt{S_{dW}^{corret}}+\epsilon}\
b:=b-\alpha\frac{V_{db}^{correct}}{\sqrt{S_{db}^{corret}}+\epsilon}\
$$
<strong>Adam算法被证明具有更强的普适性，适用于更加广泛的结构。</strong></p>
<p>其中上述算法中的超参数使用值：
$$
\alpha是一个需要不断调整的值\
\beta_1推荐值为0.9\
\beta_2推荐值为0.999\
\epsilon推荐值为10^{-8}
$$</p>
<h4 id="学习率衰减">学习率衰减</h4>
<p>假设使用一个mini-batch的梯度下降方法，梯度下降会出现噪声，最后不会收敛，而是会在最小值之间波动。通过学习率衰减的办法，可以使得在梯度下降到最小值附近，波动的幅度变得很小。如下图所示（从蓝线到绿线的变化）：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img26.jpg" alt=""></p>
<p>学习率的设置公式如下：
$$
\alpha=\frac{1}{1+衰减率\times 代数}\alpha_0\ 
这里的代数是指迭代的次数,衰减率和\alpha是一个需要调整的参数。
$$</p>
<h4 id="作业五">作业五</h4>
<p>分别使用<code>mini-batch</code>，<code>动量梯度下降</code>，<code>Adam</code>算法对梯度下降进行加速。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">172
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">173
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">174
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">175
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">176
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">177
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">178
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">179
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">180
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">181
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">182
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">183
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">184
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">185
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">186
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">187
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">188
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">189
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">190
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">191
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">192
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">193
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">194
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">195
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">196
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">197
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">198
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">199
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">200
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">201
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">202
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">203
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">204
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">205
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">206
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">207
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">208
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">209
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">210
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">211
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">212
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">213
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">214
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">215
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">216
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">217
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">218
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">219
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">220
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">221
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">222
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">223
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">224
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">225
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">226
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">227
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">228
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">229
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">230
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">231
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">232
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">233
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">234
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">235
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">236
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">237
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">238
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">239
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">240
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">241
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">242
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">243
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">244
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">245
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">246
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">247
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">248
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">249
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">250
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">251
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">252
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">253
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">254
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">255
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">256
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">257
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">258
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">259
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">260
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">261
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">262
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># 导入库</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">matplotlib.pyplot</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">plt</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">scipy.io</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">math</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">sklearn</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">sklearn.datasets</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">opt_utils</span> <span style="color:#8b008b;font-weight:bold">import</span> load_params_and_grads, initialize_parameters, forward_propagation, backward_propagation
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">opt_utils</span> <span style="color:#8b008b;font-weight:bold">import</span> compute_cost, predict, predict_dec, plot_decision_boundary, load_dataset
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">testCases</span> <span style="color:#8b008b;font-weight:bold">import</span> *
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span>plt.rcParams[<span style="color:#cd5555">&#39;figure.figsize&#39;</span>] = (<span style="color:#b452cd">7.0</span>, <span style="color:#b452cd">4.0</span>) <span style="color:#228b22"># set default size of plots</span>
</span></span><span style="display:flex;"><span>plt.rcParams[<span style="color:#cd5555">&#39;image.interpolation&#39;</span>] = <span style="color:#cd5555">&#39;nearest&#39;</span>
</span></span><span style="display:flex;"><span>plt.rcParams[<span style="color:#cd5555">&#39;image.cmap&#39;</span>] = <span style="color:#cd5555">&#39;gray&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 参数更新</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">update_parameters_with_gd</span>(parameters, grads, learning_rate):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Update parameters using one step of gradient descent
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters to be updated:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;W&#39; + str(l)] = Wl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;b&#39; + str(l)] = bl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- python dictionary containing your gradients to update each parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;dW&#39; + str(l)] = dWl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;db&#39; + str(l)] = dbl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- the learning rate, scalar.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your updated parameters 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(parameters) // <span style="color:#b452cd">2</span> <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Update rule for each parameter</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(L):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#34;W&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * grads[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#34;b&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * grads[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#228b22"># mini-batch</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">random_mini_batches</span>(X, Y, mini_batch_size = <span style="color:#b452cd">64</span>, seed = <span style="color:#b452cd">0</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Creates a list of random minibatches from (X, Y)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- input data, of shape (input size, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- true &#34;label&#34; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    mini_batch_size -- size of the mini-batches, integer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    np.random.seed(seed)            <span style="color:#228b22"># To make your &#34;random&#34; minibatches the same as ours</span>
</span></span><span style="display:flex;"><span>    m = X.shape[<span style="color:#b452cd">1</span>]                  <span style="color:#228b22"># number of training examples</span>
</span></span><span style="display:flex;"><span>    mini_batches = []
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Step 1: Shuffle (X, Y) 洗牌</span>
</span></span><span style="display:flex;"><span>    permutation = <span style="color:#658b00">list</span>(np.random.permutation(m))
</span></span><span style="display:flex;"><span>    shuffled_X = X[:, permutation]
</span></span><span style="display:flex;"><span>    shuffled_Y = Y[:, permutation].reshape((<span style="color:#b452cd">1</span>,m))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.</span>
</span></span><span style="display:flex;"><span>    num_complete_minibatches = math.floor(m/mini_batch_size) <span style="color:#228b22"># number of mini batches of size mini_batch_size in your partitionning</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> k <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(<span style="color:#b452cd">0</span>, num_complete_minibatches):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + <span style="color:#b452cd">1</span>) * mini_batch_size]
</span></span><span style="display:flex;"><span>        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + <span style="color:#b452cd">1</span>) * mini_batch_size]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>        mini_batch = (mini_batch_X, mini_batch_Y)
</span></span><span style="display:flex;"><span>        mini_batches.append(mini_batch)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Handling the end case (last mini-batch &lt; mini_batch_size) 处理最后一个mini-batch小于64的情况。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> m % mini_batch_size != <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]
</span></span><span style="display:flex;"><span>        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>        mini_batch = (mini_batch_X, mini_batch_Y)
</span></span><span style="display:flex;"><span>        mini_batches.append(mini_batch)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> mini_batches
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 动量梯度下降：1.初始化参数 2.更新参数</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">initialize_velocity</span>(parameters):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Initializes the velocity as a python dictionary with:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                - keys: &#34;dW1&#34;, &#34;db1&#34;, ..., &#34;dWL&#34;, &#34;dbL&#34; 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;W&#39; + str(l)] = Wl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;b&#39; + str(l)] = bl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- python dictionary containing the current velocity.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#39;dW&#39; + str(l)] = velocity of dWl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#39;db&#39; + str(l)] = velocity of dbl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(parameters) // <span style="color:#b452cd">2</span> <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>    v = {}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Initialize velocity</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(L):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#39;dW&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;W&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#39;db&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;b&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> v
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">update_parameters_with_momentum</span>(parameters, grads, v, beta, learning_rate):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Update parameters using Momentum
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;W&#39; + str(l)] = Wl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;b&#39; + str(l)] = bl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- python dictionary containing your gradients for each parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;dW&#39; + str(l)] = dWl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;db&#39; + str(l)] = dbl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- python dictionary containing the current velocity:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#39;dW&#39; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#39;db&#39; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta -- the momentum hyperparameter, scalar
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- the learning rate, scalar
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your updated parameters 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- python dictionary containing your updated velocities
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(parameters) // <span style="color:#b452cd">2</span> <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Momentum update for each parameter</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(L):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 4 lines)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># compute velocities</span>
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#39;dW&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta * v[<span style="color:#cd5555">&#39;dW&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta) * grads[<span style="color:#cd5555">&#39;dW&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#39;db&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta * v[<span style="color:#cd5555">&#39;db&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta) * grads[<span style="color:#cd5555">&#39;db&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># update parameters</span>
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#39;W&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * v[<span style="color:#cd5555">&#39;dW&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#39;b&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * v[<span style="color:#cd5555">&#39;db&#39;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters, v
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Adma算法： 1.初始化V[dW],V[db],S[dW],S[db] 2.更新参数</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">initialize_adam</span>(parameters) :
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Initializes v and s as two python dictionaries with:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                - keys: &#34;dW1&#34;, &#34;db1&#34;, ..., &#34;dWL&#34;, &#34;dbL&#34; 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#34;W&#34; + str(l)] = Wl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#34;b&#34; + str(l)] = bl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- python dictionary that will contain the exponentially weighted average of the gradient.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#34;dW&#34; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    v[&#34;db&#34; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    s[&#34;dW&#34; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    s[&#34;db&#34; + str(l)] = ...
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(parameters) // <span style="color:#b452cd">2</span> <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>    v = {}
</span></span><span style="display:flex;"><span>    s = {}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Initialize v, s. Input: &#34;parameters&#34;. Outputs: &#34;v, s&#34;.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(L):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ### (approx. 4 lines)</span>
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;W&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;b&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>        s[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;W&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>        s[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = np.zeros(parameters[<span style="color:#cd5555">&#34;b&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)].shape)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> v, s
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">update_parameters_with_adam</span>(parameters, grads, v, s, t, learning_rate = <span style="color:#b452cd">0.01</span>,
</span></span><span style="display:flex;"><span>                                beta1 = <span style="color:#b452cd">0.9</span>, beta2 = <span style="color:#b452cd">0.999</span>,  epsilon = <span style="color:#b452cd">1e-8</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Update parameters using Adam
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;W&#39; + str(l)] = Wl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    parameters[&#39;b&#39; + str(l)] = bl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    grads -- python dictionary containing your gradients for each parameters:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;dW&#39; + str(l)] = dWl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                    grads[&#39;db&#39; + str(l)] = dbl
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- Adam variable, moving average of the first gradient, python dictionary
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    s -- Adam variable, moving average of the squared gradient, python dictionary
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- the learning rate, scalar.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta1 -- Exponential decay hyperparameter for the first moment estimates 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta2 -- Exponential decay hyperparameter for the second moment estimates 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    epsilon -- hyperparameter preventing division by zero in Adam updates
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your updated parameters 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    v -- Adam variable, moving average of the first gradient, python dictionary
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    s -- Adam variable, moving average of the squared gradient, python dictionary
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(parameters) // <span style="color:#b452cd">2</span>                 <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>    v_corrected = {}                         <span style="color:#228b22"># Initializing first moment estimate, python dictionary</span>
</span></span><span style="display:flex;"><span>    s_corrected = {}                         <span style="color:#228b22"># Initializing second moment estimate, python dictionary</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Perform Adam update on all parameters</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(L):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Moving average of the gradients. Inputs: &#34;v, grads, beta1&#34;. Output: &#34;v&#34;.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta1 * v[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta1) * grads[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        v[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta1 * v[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta1) * grads[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Compute bias-corrected first moment estimate. Inputs: &#34;v, beta1, t&#34;. Output: &#34;v_corrected&#34;.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        v_corrected[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = v[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (<span style="color:#b452cd">1</span> - beta1 ** t)
</span></span><span style="display:flex;"><span>        v_corrected[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = v[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (<span style="color:#b452cd">1</span> - beta1 ** t)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Moving average of the squared gradients. Inputs: &#34;s, grads, beta2&#34;. Output: &#34;s&#34;.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        s[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta2 * s[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta2) * np.multiply(grads[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)], grads[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)])
</span></span><span style="display:flex;"><span>        s[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = beta2 * s[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] + (<span style="color:#b452cd">1</span> - beta2) * np.multiply(grads[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)], grads[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)])
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Compute bias-corrected second raw moment estimate. Inputs: &#34;s, beta2, t&#34;. Output: &#34;s_corrected&#34;.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        s_corrected[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = s[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (<span style="color:#b452cd">1</span> - beta2 ** t)
</span></span><span style="display:flex;"><span>        s_corrected[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] = s[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (<span style="color:#b452cd">1</span> - beta2 ** t)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Update parameters. Inputs: &#34;parameters, learning_rate, v_corrected, s_corrected, epsilon&#34;. Output: &#34;parameters&#34;.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### START CODE HERE ### (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#34;W&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * v_corrected[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (epsilon + np.sqrt(s_corrected[<span style="color:#cd5555">&#34;dW&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]))
</span></span><span style="display:flex;"><span>        parameters[<span style="color:#cd5555">&#34;b&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] -= learning_rate * v_corrected[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)] / (epsilon + np.sqrt(s_corrected[<span style="color:#cd5555">&#34;db&#34;</span> + <span style="color:#658b00">str</span>(i + <span style="color:#b452cd">1</span>)]))
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters, v, s
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>使用不同算法加速的模型进行预测：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># 加载数据</span>
</span></span><span style="display:flex;"><span>train_X, train_Y = load_dataset()
</span></span></code></pre></td></tr></table>
</div>
</div><p>数据分布如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img31.jpg" alt=""></p>
<p>建立预测模型并使用三种不同的算法进行加速预测模型：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">model</span>(X, Y, layers_dims, optimizer, learning_rate = <span style="color:#b452cd">0.0007</span>, mini_batch_size = <span style="color:#b452cd">64</span>, beta = <span style="color:#b452cd">0.9</span>,
</span></span><span style="display:flex;"><span>          beta1 = <span style="color:#b452cd">0.9</span>, beta2 = <span style="color:#b452cd">0.999</span>,  epsilon = <span style="color:#b452cd">1e-8</span>, num_epochs = <span style="color:#b452cd">10000</span>, print_cost = <span style="color:#8b008b;font-weight:bold">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    3-layer neural network model which can be run in different optimizer modes.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    X -- input data, of shape (2, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Y -- true &#34;label&#34; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    layers_dims -- python list, containing the size of each layer
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    learning_rate -- the learning rate, scalar.
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    mini_batch_size -- the size of a mini batch
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta -- Momentum hyperparameter
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta1 -- Exponential decay hyperparameter for the past gradients estimates 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    epsilon -- hyperparameter preventing division by zero in Adam updates
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    num_epochs -- number of epochs
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    print_cost -- True to print the cost every 1000 epochs
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    parameters -- python dictionary containing your updated parameters 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    L = <span style="color:#658b00">len</span>(layers_dims)             <span style="color:#228b22"># number of layers in the neural networks</span>
</span></span><span style="display:flex;"><span>    costs = []                       <span style="color:#228b22"># to keep track of the cost</span>
</span></span><span style="display:flex;"><span>    t = <span style="color:#b452cd">0</span>                            <span style="color:#228b22"># initializing the counter required for Adam update</span>
</span></span><span style="display:flex;"><span>    seed = <span style="color:#b452cd">10</span>                        <span style="color:#228b22"># For grading purposes, so that your &#34;random&#34; minibatches are the same as ours</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Initialize parameters</span>
</span></span><span style="display:flex;"><span>    parameters = initialize_parameters(layers_dims)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Initialize the optimizer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> optimizer == <span style="color:#cd5555">&#34;gd&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">pass</span> <span style="color:#228b22"># no initialization required for gradient descent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">elif</span> optimizer == <span style="color:#cd5555">&#34;momentum&#34;</span>:
</span></span><span style="display:flex;"><span>        v = initialize_velocity(parameters)
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">elif</span> optimizer == <span style="color:#cd5555">&#34;adam&#34;</span>:
</span></span><span style="display:flex;"><span>        v, s = initialize_adam(parameters)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Optimization loop</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch</span>
</span></span><span style="display:flex;"><span>        seed = seed + <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> minibatch <span style="color:#8b008b">in</span> minibatches:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># Select a minibatch</span>
</span></span><span style="display:flex;"><span>            (minibatch_X, minibatch_Y) = minibatch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># Forward propagation</span>
</span></span><span style="display:flex;"><span>            a3, caches = forward_propagation(minibatch_X, parameters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># Compute cost</span>
</span></span><span style="display:flex;"><span>            cost = compute_cost(a3, minibatch_Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># Backward propagation</span>
</span></span><span style="display:flex;"><span>            grads = backward_propagation(minibatch_X, minibatch_Y, caches)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#228b22"># Update parameters</span>
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> optimizer == <span style="color:#cd5555">&#34;gd&#34;</span>:
</span></span><span style="display:flex;"><span>                parameters = update_parameters_with_gd(parameters, grads, learning_rate)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">elif</span> optimizer == <span style="color:#cd5555">&#34;momentum&#34;</span>:
</span></span><span style="display:flex;"><span>                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">elif</span> optimizer == <span style="color:#cd5555">&#34;adam&#34;</span>:
</span></span><span style="display:flex;"><span>                t = t + <span style="color:#b452cd">1</span> <span style="color:#228b22"># Adam counter</span>
</span></span><span style="display:flex;"><span>                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,
</span></span><span style="display:flex;"><span>                                                               t, learning_rate, beta1, beta2,  epsilon)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Print the cost every 1000 epoch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> print_cost <span style="color:#8b008b">and</span> i % <span style="color:#b452cd">1000</span> == <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#658b00">print</span> (<span style="color:#cd5555">&#34;Cost after epoch </span><span style="color:#cd5555">%i</span><span style="color:#cd5555">: </span><span style="color:#cd5555">%f</span><span style="color:#cd5555">&#34;</span> %(i, cost))
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> print_cost <span style="color:#8b008b">and</span> i % <span style="color:#b452cd">100</span> == <span style="color:#b452cd">0</span>:
</span></span><span style="display:flex;"><span>            costs.append(cost)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># plot the cost</span>
</span></span><span style="display:flex;"><span>    plt.plot(costs)
</span></span><span style="display:flex;"><span>    plt.ylabel(<span style="color:#cd5555">&#39;cost&#39;</span>)
</span></span><span style="display:flex;"><span>    plt.xlabel(<span style="color:#cd5555">&#39;epochs (per 100)&#39;</span>)
</span></span><span style="display:flex;"><span>    plt.title(<span style="color:#cd5555">&#34;Learning rate = &#34;</span> + <span style="color:#658b00">str</span>(learning_rate))
</span></span><span style="display:flex;"><span>    plt.show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> parameters
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 画图</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">plot_decision_boundary</span>(model, X, y):
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">#import pdb;pdb.set_trace()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Set min and max values and give it some padding</span>
</span></span><span style="display:flex;"><span>    x_min, x_max = X[<span style="color:#b452cd">0</span>, :].min() - <span style="color:#b452cd">1</span>, X[<span style="color:#b452cd">0</span>, :].max() + <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>    y_min, y_max = X[<span style="color:#b452cd">1</span>, :].min() - <span style="color:#b452cd">1</span>, X[<span style="color:#b452cd">1</span>, :].max() + <span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>    h = <span style="color:#b452cd">0.01</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Generate a grid of points with distance h between them</span>
</span></span><span style="display:flex;"><span>    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Predict the function value for the whole grid</span>
</span></span><span style="display:flex;"><span>    Z = model(np.c_[xx.ravel(), yy.ravel()])
</span></span><span style="display:flex;"><span>    Z = Z.reshape(xx.shape)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Plot the contour and training examples</span>
</span></span><span style="display:flex;"><span>    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)
</span></span><span style="display:flex;"><span>    plt.ylabel(<span style="color:#cd5555">&#39;x2&#39;</span>)
</span></span><span style="display:flex;"><span>    plt.xlabel(<span style="color:#cd5555">&#39;x1&#39;</span>)
</span></span><span style="display:flex;"><span>    y = y.reshape(X[<span style="color:#b452cd">0</span>,:].shape)<span style="color:#228b22">#must reshape,otherwise confliction with dimensions</span>
</span></span><span style="display:flex;"><span>    plt.scatter(X[<span style="color:#b452cd">0</span>, :], X[<span style="color:#b452cd">1</span>, :], c=y, cmap=plt.cm.Spectral)
</span></span><span style="display:flex;"><span>    plt.show()
</span></span><span style="display:flex;"><span> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>mini-batch：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22">#--------------------------------------------- mini-batch</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># train 3-layer model</span>
</span></span><span style="display:flex;"><span>layers_dims = [train_X.shape[<span style="color:#b452cd">0</span>], <span style="color:#b452cd">5</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>parameters = model(train_X, train_Y, layers_dims, optimizer = <span style="color:#cd5555">&#34;gd&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Predict</span>
</span></span><span style="display:flex;"><span>predictions = predict(train_X, train_Y, parameters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Plot decision boundary</span>
</span></span><span style="display:flex;"><span>plt.title(<span style="color:#cd5555">&#34;Model with Gradient Descent optimization&#34;</span>)
</span></span><span style="display:flex;"><span>axes = plt.gca()
</span></span><span style="display:flex;"><span>axes.set_xlim([-<span style="color:#b452cd">1.5</span>,<span style="color:#b452cd">2.5</span>])
</span></span><span style="display:flex;"><span>axes.set_ylim([-<span style="color:#b452cd">1</span>,<span style="color:#b452cd">1.5</span>])
</span></span><span style="display:flex;"><span>plot_decision_boundary(<span style="color:#8b008b;font-weight:bold">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)
</span></span></code></pre></td></tr></table>
</div>
</div><p>cost随迭代次数的变化结果如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img32.jpg" alt=""></p>
<p>准确率为0.79，分类结果分布如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img33.jpg" alt=""></p>
<p>动量下降(with mini-batch)：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># train 3-layer model</span>
</span></span><span style="display:flex;"><span>layers_dims = [train_X.shape[<span style="color:#b452cd">0</span>], <span style="color:#b452cd">5</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>parameters = model(train_X, train_Y, layers_dims, beta = <span style="color:#b452cd">0.9</span>, optimizer = <span style="color:#cd5555">&#34;momentum&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Predict</span>
</span></span><span style="display:flex;"><span>predictions = predict(train_X, train_Y, parameters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Plot decision boundary</span>
</span></span><span style="display:flex;"><span>plt.title(<span style="color:#cd5555">&#34;Model with Momentum optimization&#34;</span>)
</span></span><span style="display:flex;"><span>axes = plt.gca()
</span></span><span style="display:flex;"><span>axes.set_xlim([-<span style="color:#b452cd">1.5</span>,<span style="color:#b452cd">2.5</span>])
</span></span><span style="display:flex;"><span>axes.set_ylim([-<span style="color:#b452cd">1</span>,<span style="color:#b452cd">1.5</span>])
</span></span><span style="display:flex;"><span>plot_decision_boundary(<span style="color:#8b008b;font-weight:bold">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)
</span></span></code></pre></td></tr></table>
</div>
</div><p>cost随迭代次数的变化结果如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img34.jpg" alt=""></p>
<p>准确率为0.79，分类结果分布如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img35.jpg" alt=""></p>
<p>Adma算法（with mini-batch）：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># train 3-layer model</span>
</span></span><span style="display:flex;"><span>layers_dims = [train_X.shape[<span style="color:#b452cd">0</span>], <span style="color:#b452cd">5</span>, <span style="color:#b452cd">2</span>, <span style="color:#b452cd">1</span>]
</span></span><span style="display:flex;"><span>parameters = model(train_X, train_Y, layers_dims, optimizer = <span style="color:#cd5555">&#34;adam&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Predict</span>
</span></span><span style="display:flex;"><span>predictions = predict(train_X, train_Y, parameters)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># Plot decision boundary</span>
</span></span><span style="display:flex;"><span>plt.title(<span style="color:#cd5555">&#34;Model with Adam optimization&#34;</span>)
</span></span><span style="display:flex;"><span>axes = plt.gca()
</span></span><span style="display:flex;"><span>axes.set_xlim([-<span style="color:#b452cd">1.5</span>,<span style="color:#b452cd">2.5</span>])
</span></span><span style="display:flex;"><span>axes.set_ylim([-<span style="color:#b452cd">1</span>,<span style="color:#b452cd">1.5</span>])
</span></span><span style="display:flex;"><span>plot_decision_boundary(<span style="color:#8b008b;font-weight:bold">lambda</span> x: predict_dec(parameters, x.T), train_X, train_Y)
</span></span></code></pre></td></tr></table>
</div>
</div><p>cost随迭代次数的变化结果如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img36.jpg" alt=""></p>
<p>准确率为0.94，分类结果分布如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img37.jpg" alt=""></p>
<h3 id="超参数调试">超参数调试</h3>
<h4 id="调试处理">调试处理</h4>
<p>超参数一般有：学习率$\alpha$；动量梯度下降的$\beta$；Adma算法的$\beta_1,\beta_2,\epsilon$；神经网络的层数layers；隐藏层的数量；学习率衰减；<code>mini-bash size</code>等。</p>
<p>我们一般优先选择调试学习率$\alpha$，其次是隐藏层数量，<code>mini-batch size</code>和动量下降中的$\beta$。再其次调整的参数就是layers和学习率衰减了。Adma算法的三个参数一般设置为$\beta1=0.9,\beta_2 = 0.999,\epsilon=10^{-8}$，我们一般不会调整它。</p>
<p>在深度学习中，我们一般会通过矩阵随机取值的方式来调参，如下图：</p>
 <img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img38.jpg" style="zoom:50%;" />
<p>长宽分别代表超参数1，2的取值。一般会在矩阵内<code>随机取25个点来查看效果</code>，因为这样会得到25个不同的超参数1和25个不同的超参数2。</p>
<p>但如果为3个参数，那么我们可以在一个立方体内随机选择点。</p>
<p>超参数调试的技巧是从<code>粗糙到精细的过程</code>：经过粗略的调整，发现在某区域内效果较好，那么我们要做的是，放大这块区域，更加密集的取值，来获取最优点。</p>
<h4 id="为超参数选择合适的范围">为超参数选择合适的范围</h4>
<p>上面所说的随机取值并不是在有效值范围内的随机均匀取值，而是选择合适的步进值来探究超参数。对于隐藏层和隐藏单元的数量，随机均匀取值是合理的，但对某些参数的不合理的。</p>
<p>假设你认为学习率$\alpha$的取值范围是0.0001～1，取值范围内随机均匀取值会将90%的值集中在0.1到1里面，不合理。<strong>对于这种情况，一般先按0.0001，0.001，0.01，0.1，1作为分界点，在分界点之间随机均匀取值。</strong></p>
<p>在Python中你可以这样做：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>r = -<span style="color:#b452cd">4</span> * np.random.rand()
</span></span><span style="display:flex;"><span>a = np.power(<span style="color:#b452cd">10</span>, r)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 更多的取值情况为10^a~10^b</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 通过计算得到a和b的值，然后我们将r取值变为a~b之间的随机取值。</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>还有就是动量梯度下降$\beta$的取值，它意味着指数加权平均的大小，一般通过$1-\beta$来取范围。但因为是$1-\beta$，需要将排列顺序颠倒。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># r在[-3, -1]内</span>
</span></span><span style="display:flex;"><span>h = -<span style="color:#b452cd">1</span>
</span></span><span style="display:flex;"><span>l = -<span style="color:#b452cd">3</span>
</span></span><span style="display:flex;"><span>r = (h - l) * np.random.rand() + l
</span></span><span style="display:flex;"><span>beta = <span style="color:#b452cd">1</span> - np.power(<span style="color:#b452cd">10</span>, r)
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="超参数训练方式panda-vs-caviar">超参数训练方式：Panda VS Caviar</h4>
<p>如果没有很大的算力的情况下，可以根据天数来调整超参数来观察效果（每次只能运行一个模型）。（Panda）</p>
<p>在算力足够的情况下，同时训练不同的几个模型。（Caviar）</p>
<h4 id="归一化网络">归一化网络</h4>
<p>前面介绍过的输入归一化，可以使梯度下降时，更加不容易偏离方向，增大步长，加快学习速度。但这只针对了输入层，如果我们对所有隐藏层进行归一化，可以大大加快学习速率，这就是我们平常所说的<code>batch归一化</code>。实际做法一般是对$Z^{[l]}$进行归一化处理，做法如下：
$$
对于某一层的Z^{[l]}，有z^{(1)},z^{(2)},\dots,z^{(m)}\
u=\frac1m\sum_{i=1}^mz^{(i)}\
\sigma^2=\frac1m\sum_{i=1}^m(z^{(i)}-u)^2\
z_{norm}^{(i)}=\frac{z^{(i)}-u}{\sqrt{\sigma^2+\epsilon}}\
这样Z的每一个分量z值都已经标准化了，平均值为0，方差为1;\
但我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有不同的分布会有意义。\
\tilde{z}^{(i)}=\gamma z^{(i)}<em>{norm}+\beta\
这里的\gamma和\beta的作用是让你可以构造其他平均值和方差的隐藏单元值\
如果\gamma=\sqrt{\sigma^2+\epsilon},\beta=u\quad则\tilde{z}^{(i)}=z^{(i)}</em>{normal}
$$
<em>已经知道了如何对Z进行归一化，那么如何将其应用于神经网络中呢？</em></p>
<p>BatchNormal神经网络参数计算的过程如下：
$$
X \xrightarrow{W^{[1]},b^{[1]}}Z^{[1]} \xrightarrow[Batch Normal(BN)]{\gamma^{[1]},\beta^{[1]}}\tilde{z}^{[i]}\rightarrow a^{[1]}=g^{[1]}(\tilde{z}^{[i]}) \xrightarrow{W^{[2]},b^{[2]}}Z^{[2]}\rightarrow\dots
$$
<em>需要注意的是这里的$\gamma$和$\beta$是和$W$，$b$一样的参数，而不是超参数。所以在反向传播时，也需要计算$d\beta,d\gamma$来更新$\beta$和$\gamma$的值。而且常数项$b$代表变化后的Z平均值离0有多远，但是标准化之后的$z^{(i)}_{norm}$均值必定为0，所以我们可以直接将$b$去掉，转而使用后面的$\beta$参数来定义。</em></p>
<p><em>Batch Normal为什么奏效？</em></p>
<blockquote>
<p>用一个例子来解释就是：你的训练集都是黑猫或者其他动物，假设他们都分布于某一侧，将训练出来的模型去预测花色猫，效果就不好。花猫分布于另一侧，这样相当于不同于黑猫的x分布。你不能期待分布在左边的数据训练出来的模型能预测右边的数据。假设将左侧的数据进行Batch Normal，相当于人为将其分布均匀，比较能适应新的数据集，防止了Covarite shift。</p>
<p>放在深层神经网络来看就是前层参数的变化会影响后层的参数，归一化降低了这种影响，尽量只保持特征值带来的波动。</p>
</blockquote>
<p><em>Batch Normal和dropout正则化</em></p>
<blockquote>
<p>dropout正则化对隐藏单元进行随机删除，从而引入噪声，防止对某个神经单元过于依赖。而Batch Normal在每个mini-batch的均值方差与整体的均值方差不一致，引入加性噪声和乘性噪声，导致轻微的正则化。如果想减少这种影响，可以将mini-batch的值设置的更大，从而减少带来的噪声，减少正则化的效果！</p>
</blockquote>
<p><em>测试时的Batch Normal</em></p>
<blockquote>
<p>因为测试时是单个单个进行测试的，不能直接进行batch normal，因为无法知道均值和方差。所以我们使用训练集来估算均值和方差。通常估算的方法是通过指数加权平均来粗略估算均值和方差。</p>
</blockquote>
<h4 id="softmax回归">softmax回归</h4>
<p>假设我们的分类类别是多个而不是两个，相当于我们的输出层单元个数变成了多个，数量就是你要分出的类别数C。这时，输出层会变成C个概率值，输入为$x$的情况下，输出为$p(类别|x)$，所以输出层是维度为（C，1）的矩阵。</p>
<p>softmax激活函数公式如下：
$$
假设Z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]},L层有C个隐藏单元，所以Z^{[L]}的维度为（C，1）\
t=e^{(Z^{[L]})}\
a^{[L]}=\frac{t}{\sum_{j=1}^{C}t_j},a_j^{[L]}=\frac{t_i}{\sum_{j=1}^{C}t_j}\
a^{[L]}的维度为（C，1），可以看出softmax激活函数的特点为输入和输出都为（C，1）
$$
<em>使用softmax训练一个softmax分类器</em></p>
<blockquote>
<p>需要注意的是Softmax回归其实就是Logistic回归的推广，当Softmax回归的类C=2，就变成了Logistic回归。</p>
</blockquote>
<p>softmax网络的损失函数为：
$$
L(\hat{y},y)=-\sum_{j=1}^Cy_j\log{\hat{y_j}}
$$
代价函数为：
$$
J=\frac1m\sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})
$$
<strong>特别需要注意的是，softmax因为是一个多分类的问题，输入的$y$标签也是一个向量，$Y$会变成一个矩阵。比如有猫，狗，牛，蛇，那么蛇的样本标签$y=[0,0,0,1]^{T}$，向量化技术后，整体样本标签会成为一个（C，m）的矩阵。</strong></p>
<p>后向传播的公式：
$$
dz^{[L]}=\hat{y}-y\
$$</p>
<h4 id="深度学习框架">深度学习框架</h4>
<p>深度学习框架在市面上有很多，我们该如何选择？</p>
<ul>
<li>1.便于编程</li>
<li>2.运行速度</li>
<li>3.是否开源</li>
</ul>
<h4 id="作业六">作业六</h4>
<ul>
<li>tensorflow练习</li>
</ul>
<p>导入需要的库：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">math</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">h5py</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">matplotlib.pyplot</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">plt</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">tensorflow</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">tf</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">tensorflow.python.framework</span> <span style="color:#8b008b;font-weight:bold">import</span> ops
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">tf_utils</span> <span style="color:#8b008b;font-weight:bold">import</span> load_dataset, random_mini_batches, convert_to_one_hot, predict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span>np.random.seed(<span style="color:#b452cd">1</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>计算损失函数的例子：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_hat = tf.constant(<span style="color:#b452cd">36</span>, name=<span style="color:#cd5555">&#39;y_hat&#39;</span>)            <span style="color:#228b22"># Define y_hat 常量. Set to 36.</span>
</span></span><span style="display:flex;"><span>y = tf.constant(<span style="color:#b452cd">39</span>, name=<span style="color:#cd5555">&#39;y&#39;</span>)                    <span style="color:#228b22"># Define y. Set to 39</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>loss = tf.Variable((y - y_hat)**<span style="color:#b452cd">2</span>, name=<span style="color:#cd5555">&#39;loss&#39;</span>)  <span style="color:#228b22"># Create a variable for the loss</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>init = tf.global_variables_initializer()         <span style="color:#228b22"># When init is run later (session.run(init)),</span>
</span></span><span style="display:flex;"><span>                                                 <span style="color:#228b22"># the loss variable will be initialized and ready to be computed</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">with</span> tf.Session() <span style="color:#8b008b;font-weight:bold">as</span> session:                    <span style="color:#228b22"># Create a session and print the output</span>
</span></span><span style="display:flex;"><span>    session.run(init)                            <span style="color:#228b22"># Initializes the variables</span>
</span></span><span style="display:flex;"><span>    <span style="color:#658b00">print</span>(session.run(loss))                     <span style="color:#228b22"># Prints the loss</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>会话机制：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>a = tf.constant(<span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>b = tf.constant(<span style="color:#b452cd">10</span>)
</span></span><span style="display:flex;"><span>c = tf.multiply(a,b)
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(c)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sess = tf.Session()
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(sess.run(c))
</span></span></code></pre></td></tr></table>
</div>
</div><p>往函数喂数据:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># Change the value of x in the feed_dict</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x = tf.placeholder(tf.int64, name = <span style="color:#cd5555">&#39;x&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(sess.run(<span style="color:#b452cd">2</span> * x, feed_dict = {x: <span style="color:#b452cd">3</span>}))
</span></span><span style="display:flex;"><span>sess.close()
</span></span></code></pre></td></tr></table>
</div>
</div><p>初始化神经网络模型参数：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># GRADED FUNCTION: linear_function</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">linear_function</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Implements a linear function: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            Initializes W to be a random tensor of shape (4,3)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            Initializes X to be a random tensor of shape (3,1)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">            Initializes b to be a random tensor of shape (4,1)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    result -- runs the session for Y = WX + b 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    np.random.seed(<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ### (4 lines of code)</span>
</span></span><span style="display:flex;"><span>    X = tf.constant(np.random.randn(<span style="color:#b452cd">3</span>, <span style="color:#b452cd">1</span>), name=<span style="color:#cd5555">&#34;X&#34;</span>)
</span></span><span style="display:flex;"><span>    W = tf.constant(np.random.randn(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">3</span>), name=<span style="color:#cd5555">&#34;W&#34;</span>)
</span></span><span style="display:flex;"><span>    b = tf.constant(np.random.randn(<span style="color:#b452cd">4</span>, <span style="color:#b452cd">1</span>), name=<span style="color:#cd5555">&#34;b&#34;</span>)
</span></span><span style="display:flex;"><span>    Y = tf.add(tf.matmul(W, X), b)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ### </span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    sess = tf.Session()
</span></span><span style="display:flex;"><span>    result = sess.run(Y)
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ### </span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># close the session </span>
</span></span><span style="display:flex;"><span>    sess.close()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> result
</span></span></code></pre></td></tr></table>
</div>
</div><p>激活函数：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># GRADED FUNCTION: sigmoid</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">sigmoid</span>(z):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Computes the sigmoid of z
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    z -- input value, scalar or vector
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    results -- the sigmoid of z
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ### ( approx. 4 lines of code)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create a placeholder for x. Name it &#39;x&#39;.</span>
</span></span><span style="display:flex;"><span>    x = tf.placeholder(tf.float32, name=<span style="color:#cd5555">&#34;x&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># compute sigmoid(x)</span>
</span></span><span style="display:flex;"><span>    sigmoid = tf.sigmoid(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create a session, and run it. Please use the method 2 explained above. </span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># You should use a feed_dict to pass z&#39;s value to x. </span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">with</span> tf.Session() <span style="color:#8b008b;font-weight:bold">as</span> sess:
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Run session and call the output &#34;result&#34;</span>
</span></span><span style="display:flex;"><span>        result = sess.run(sigmoid, feed_dict={x:z})
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> result
</span></span></code></pre></td></tr></table>
</div>
</div><p>计算代价函数：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># GRADED FUNCTION: cost</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">cost</span>(logits, labels):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Computes the cost using the sigmoid cross entropy
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    labels -- vector of labels y (1 or 0) 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Note: What we&#39;ve been calling &#34;z&#34; and &#34;y&#34; in this class are respectively called &#34;logits&#34; and &#34;labels&#34; 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    in the TensorFlow documentation. So logits will feed into z, and labels into y. 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    cost -- runs the session of the cost (formula (2))
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ### </span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create the placeholders for &#34;logits&#34; (z) and &#34;labels&#34; (y) (approx. 2 lines)</span>
</span></span><span style="display:flex;"><span>    z = tf.placeholder(tf.float32, name=<span style="color:#cd5555">&#34;z&#34;</span>)
</span></span><span style="display:flex;"><span>    y = tf.placeholder(tf.float32, name=<span style="color:#cd5555">&#34;y&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Use the loss function (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z, labels = y)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create a session (approx. 1 line). See method 1 above.</span>
</span></span><span style="display:flex;"><span>    sess = tf.Session()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Run the session (approx. 1 line).</span>
</span></span><span style="display:flex;"><span>    cost = sess.run(cost, feed_dict={z:logits, y:labels})
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Close the session (approx. 1 line). See method 1 above.</span>
</span></span><span style="display:flex;"><span>    sess.close()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> cost
</span></span></code></pre></td></tr></table>
</div>
</div><p>独热编码：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># GRADED FUNCTION: one_hot_matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">one_hot_matrix</span>(labels, C):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Creates a matrix where the i-th row corresponds to the ith class number and the jth column
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                     will be 1. 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">                     
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    labels -- vector containing the labels 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    C -- number of classes, the depth of the one hot dimension
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    one_hot -- one hot matrix
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create a tf.constant equal to C (depth), name it &#39;C&#39;. (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    C = tf.constant(value = C, name=<span style="color:#cd5555">&#34;C&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Use tf.one_hot, be careful with the axis (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    one_hot_matrix = tf.one_hot(labels, C, axis=<span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create the session (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    sess = tf.Session()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Run the session (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    one_hot = sess.run(one_hot_matrix)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Close the session (approx. 1 line). See method 1 above.</span>
</span></span><span style="display:flex;"><span>    sess.close()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> one_hot
</span></span></code></pre></td></tr></table>
</div>
</div><p>初始化零一向量：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># GRADED FUNCTION: ones</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">ones</span>(shape):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Creates an array of ones of dimension shape
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Arguments:
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    shape -- shape of the array you want to create
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Returns: 
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    ones -- array containing only ones
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### START CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create &#34;ones&#34; tensor using tf.ones(...). (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    ones = tf.ones(shape)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Create the session (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    sess = tf.Session()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Run the session to compute &#39;ones&#39; (approx. 1 line)</span>
</span></span><span style="display:flex;"><span>    ones = sess.run(ones)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22"># Close the session (approx. 1 line). See method 1 above.</span>
</span></span><span style="display:flex;"><span>    sess.close()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">### END CODE HERE ###</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> ones
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>因为有部分公式可能因为博客插件不支持的原因，完整的笔记请看:</strong>
<a href="https://github.com/caixiongjiang/deep-learning-computer-vision">https://github.com/caixiongjiang/deep-learning-computer-vision</a></p>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2022-07-23</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts">
			下回<br>已经到头啦。
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-5%E8%8A%82/">
			上回<br>深度学习笔记（4-5节） 
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2022 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
