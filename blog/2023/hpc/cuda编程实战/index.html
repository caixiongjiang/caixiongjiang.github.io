<!DOCTYPE html>
<html><head>
<title>CUDA编程实战</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="CUDA编程实战">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="CUDA编程实战" />
<meta property="og:description" content="CUDA编程实战" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2023/hpc/cuda%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2023-07-19T18:18:05+08:00" />
<meta property="article:modified_time" content="2023-08-01T09:19:06+08:00" />
<meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2023/hpc/%E4%B8%AD%E7%A7%91%E5%A4%A7cuda%E6%95%99%E7%A8%8B/" /><meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/" />











<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="mailto:nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b%e5%ae%9e%e6%88%98" onclick="onNavClick(`#cuda编程实战-nav`)" id="cuda编程实战-nav">
									CUDA编程实战
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#hello-gpu" onclick="onNavClick(`#hello-gpu-nav`)" id="hello-gpu-nav">
									Hello GPU
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bd%91%e6%a0%bc%e5%9d%97%e7%ba%bf%e7%a8%8b" onclick="onNavClick(`#网格块线程-nav`)" id="网格块线程-nav">
									网格、块、线程
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d" onclick="onNavClick(`#显存分配-nav`)" id="显存分配-nav">
									显存分配
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%b7%a8%e6%ad%a5%e5%be%aa%e7%8e%af" onclick="onNavClick(`#跨步循环-nav`)" id="跨步循环-nav">
									跨步循环
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bc%82%e5%b8%b8%e5%a4%84%e7%90%86" onclick="onNavClick(`#异常处理-nav`)" id="异常处理-nav">
									异常处理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e5%8a%a0%e6%b3%95" onclick="onNavClick(`#矩阵加法-nav`)" id="矩阵加法-nav">
									矩阵加法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e6%80%a7%e8%83%bd%e5%88%86%e6%9e%90" onclick="onNavClick(`#cuda性能分析-nav`)" id="cuda性能分析-nav">
									CUDA性能分析
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e5%b1%9e%e6%80%a7" onclick="onNavClick(`#gpu属性-nav`)" id="gpu属性-nav">
									GPU属性
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d2" onclick="onNavClick(`#显存分配2-nav`)" id="显存分配2-nav">
									显存分配（2）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d3" onclick="onNavClick(`#显存分配3-nav`)" id="显存分配3-nav">
									显存分配（3）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e6%b5%81" onclick="onNavClick(`#cuda流-nav`)" id="cuda流-nav">
									CUDA流
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98" onclick="onNavClick(`#cuda共享内存-nav`)" id="cuda共享内存-nav">
									CUDA共享内存
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b%e5%ae%9e%e6%88%98" onclick="onNavClick(`#cuda编程实战-nav`)" id="cuda编程实战-nav">
									CUDA编程实战
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#hello-gpu" onclick="onNavClick(`#hello-gpu-nav`)" id="hello-gpu-nav">
									Hello GPU
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bd%91%e6%a0%bc%e5%9d%97%e7%ba%bf%e7%a8%8b" onclick="onNavClick(`#网格块线程-nav`)" id="网格块线程-nav">
									网格、块、线程
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d" onclick="onNavClick(`#显存分配-nav`)" id="显存分配-nav">
									显存分配
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%b7%a8%e6%ad%a5%e5%be%aa%e7%8e%af" onclick="onNavClick(`#跨步循环-nav`)" id="跨步循环-nav">
									跨步循环
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bc%82%e5%b8%b8%e5%a4%84%e7%90%86" onclick="onNavClick(`#异常处理-nav`)" id="异常处理-nav">
									异常处理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e5%8a%a0%e6%b3%95" onclick="onNavClick(`#矩阵加法-nav`)" id="矩阵加法-nav">
									矩阵加法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e6%80%a7%e8%83%bd%e5%88%86%e6%9e%90" onclick="onNavClick(`#cuda性能分析-nav`)" id="cuda性能分析-nav">
									CUDA性能分析
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e5%b1%9e%e6%80%a7" onclick="onNavClick(`#gpu属性-nav`)" id="gpu属性-nav">
									GPU属性
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d2" onclick="onNavClick(`#显存分配2-nav`)" id="显存分配2-nav">
									显存分配（2）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%98%be%e5%ad%98%e5%88%86%e9%85%8d3" onclick="onNavClick(`#显存分配3-nav`)" id="显存分配3-nav">
									显存分配（3）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e6%b5%81" onclick="onNavClick(`#cuda流-nav`)" id="cuda流-nav">
									CUDA流
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98" onclick="onNavClick(`#cuda共享内存-nav`)" id="cuda共享内存-nav">
									CUDA共享内存
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA_title.jpg')"
                    
                
            >
                <div class="post-title">
                    CUDA编程实战
                    
                    <div class="post-subtitle">
                        CUDA编程实战
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2023-07-19 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[HPC]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/cuda%E7%BC%96%E7%A8%8B">CUDA编程</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            44 min
                            
                            31 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="cuda编程实战">CUDA编程实战</h2>
<h3 id="hello-gpu">Hello GPU</h3>
<blockquote>
<p>编写第一个gpu程序</p>
</blockquote>
<p>一般来说，CUDA程序是<code>.cu</code>结尾的程序！</p>
<p>hello-gpu.cu:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>() {
</span></span><span style="display:flex;"><span>    printf(<span style="color:#cd5555">&#34;hello cpu</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>() {
</span></span><span style="display:flex;"><span>    printf(<span style="color:#cd5555">&#34;hello gpu</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    cpu();
</span></span><span style="display:flex;"><span>    gpu&lt;&lt;&lt;<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>&gt;&gt;&gt;();
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">// 等待cpu和gpu同步
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>__global__:</p>
<ul>
<li>__global__关键字代表以下<strong>函数将在GPU山运行并全局可调用。</strong></li>
<li>通过我们将在cpu上执行的代码称为主机代码，而在GPU上运行的代码称为设备代码。</li>
<li>注意返回类型为void。使用__global__关键字定义的函数需要返回void类型。</li>
</ul>
<p>gpu&laquo;&lt;1, 1&raquo;&gt;():</p>
<ul>
<li>通常，当调用要在GPU上运行的函数时，我们将这种函数称为<code>已启动的核函数</code>。</li>
<li>启动核函数之前必须提供执行的配置，在向核函数传递任何预期参数之前使用<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>语法完成配置。</li>
<li>程序员可通过执行配置为核函数启动指定线程层次结构，从而定义<code>线程组（也称为线程块）的数量</code>，以及要在<code>每个线程块中执行的线程数量</code>。这里就代表正在使用包含1线程（第二个配置参数）的1线程块（第一个配置参数）启动核函数。</li>
</ul>
<p>cudaDeviceSynchronize():</p>
<ul>
<li>与大部分c/c++代码不同，<strong>核函数启动方式为异步：CPU代码将继续执行而无需等待核函数完成启动。</strong></li>
<li>调用CUDA运行时提供的函数cudaDeviceSynchronize将导致主机（cpu）代码暂停，直至设备（GPU）代码执行完成，才能在cpu上恢复执行。</li>
</ul>
<blockquote>
<p>使用nvcc编译、链接、执行</p>
</blockquote>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nvcc -o hello-gpu hello-gpu.cu -run
</span></span></code></pre></td></tr></table>
</div>
</div><p>看到</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">hello</span> <span style="color:#8b008b;font-weight:bold">cpu</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">hello</span> <span style="color:#8b008b;font-weight:bold">gpu</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>说明你编译、链接、执行成功。</p>
<h3 id="网格块线程">网格、块、线程</h3>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img58.jpg" alt=""></p>
<p><em>注意，上述结构并不是硬件结构，而是软件逻辑概念！</em></p>
<p>一个GPU中有多个线程块，每个线程块中含有不同的线程，每个线程能执行一个程序。多个线程块组成一个网格。在实际的编程中，一个Block可以最多放1024个线程。</p>
<blockquote>
<p>如何使用CUDA编程语言来表示这些含义</p>
</blockquote>
<ul>
<li>gridDim.x 表示网格的线程块个数</li>
<li>blockIdx.x 表示当前块的索引</li>
<li>blockDim.x 表示块的线程数</li>
<li>threadIdx.x 表示当前中线程的索引</li>
</ul>
<p>假设执行<code>performWork&lt;&lt;&lt;2, 4&gt;&gt;&gt;()</code>代表线程块个数为2，块中的线程数为4</p>
<p>将我们的<code>hello-gpu.cu</code>文件修改执行一下，改成了<code>gpu&lt;&lt;&lt;2, 4&gt;&gt;&gt;()</code>，打印的结果为1个<code>cpu</code>和8个<code>gpu</code>。说明gpu的程序同时有8个线程一起执行了它。</p>
<p>我现在需要指定某个块中的某个CUDA线程来执行它，则需要通过两个索引值来判断：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>() {
</span></span><span style="display:flex;"><span>    printf(<span style="color:#cd5555">&#34;hello cpu</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (blockIdx.x == <span style="color:#b452cd">0</span> &amp;&amp; threadIdx.x == <span style="color:#b452cd">0</span>)
</span></span><span style="display:flex;"><span>    		printf(<span style="color:#cd5555">&#34;hello gpu</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    cpu();
</span></span><span style="display:flex;"><span>    gpu&lt;&lt;&lt;<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>&gt;&gt;&gt;();
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">// 等待cpu和gpu同步
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>执行的结果变为了一个cpu和一个gpu。</strong></p>
<p><strong>显而易见，在GPU上执行循环的复杂度由原来的O(n)变成了O(1)。</strong></p>
<p>题外话，CPU也能并发线程，那为什么CPU不好：其实CPU在软件层面上能同时开20个或者30个等线程，但这都是通过操作系统调度时间切片做到的，但实际上从物理的层面上只能同时跑8个线程，通过4个ALU同时跑4个线程，通过寄存器复制实现超线程扩展到8个。</p>
<h3 id="显存分配">显存分配</h3>
<blockquote>
<p>如何区分每个线程id</p>
</blockquote>
<p>通过计算<code>blockIdx.x * blockDim.x + threadIdx.x</code>的值区分不同的线程id。</p>
<blockquote>
<p>cpu分配内存/gpu分配显存</p>
</blockquote>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">//cpu
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#00688b;font-weight:bold">int</span> N = <span style="color:#b452cd">2</span> &lt;&lt; <span style="color:#b452cd">20</span>;
</span></span><span style="display:flex;"><span>size_t size = N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> *a;
</span></span><span style="display:flex;"><span>a = (<span style="color:#00688b;font-weight:bold">int</span> *)malloc(size);<span style="color:#228b22">//分配内存
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>free(a);
</span></span><span style="display:flex;"><span><span style="color:#228b22">//gpu
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#00688b;font-weight:bold">int</span> N = <span style="color:#b452cd">2</span> &lt;&lt; <span style="color:#b452cd">20</span>;
</span></span><span style="display:flex;"><span>size_t size = N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> *a;
</span></span><span style="display:flex;"><span>cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span>cudaFree(a);
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>需要注意的是cudaMallocManaged()分配的是统一内存，既可以被cpu使用，也可以被gpu使用。</strong></p>
<p>通过一个例子来学习显存分配：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdlib.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i++) {
</span></span><span style="display:flex;"><span>      	a[i] = i;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (i &lt; N) {
</span></span><span style="display:flex;"><span>      	A[i] *= <span style="color:#b452cd">2</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">if</span> (a[i] != i * <span style="color:#b452cd">2</span>) <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">const</span> <span style="color:#00688b;font-weight:bold">int</span> N = <span style="color:#b452cd">100</span>;
</span></span><span style="display:flex;"><span>  	size_t size = N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> * a;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//分配通用内存
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span>  	cpu(a, N); <span style="color:#228b22">// cpu进行操作
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	size_t threads = <span style="color:#b452cd">256</span>;<span style="color:#228b22">//线程块中线程的个数
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	size_t blocks = (N + threads - <span style="color:#b452cd">1</span>) / threads; <span style="color:#228b22">//向上取整计算
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a, N); <span style="color:#228b22">//gpu进行操作
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaDeviceSynchronize(); <span style="color:#228b22">//cpu和gpu同步(如果不进行同步check必然为error)
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	check(a, N) ? printf(<span style="color:#cd5555">&#34;ok&#34;</span>) : printf(<span style="color:#cd5555">&#34;error&#34;</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">/* 最后输出的结果为ok */</span>
</span></span><span style="display:flex;"><span>  	cudaFree(a);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>通用内存既可以被cpu调用也可以被gpu调用。</p>
<h3 id="跨步循环">跨步循环</h3>
<p>当需要并行的过程远大于线程数，便可以使用跨步循环，<code>跨了多少步，同一个线程就运行了多少次</code>：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdlib.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i++) {
</span></span><span style="display:flex;"><span>      	a[i] = i;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> threadi = blockIdx.x * blockDim.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> stride = gripDim.x * blockDim.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = threadi; i &lt; N; i += stride) {
</span></span><span style="display:flex;"><span>      	a[i] *= <span style="color:#b452cd">2</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> N) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">if</span> (a[i] != i * <span style="color:#b452cd">2</span>) <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">const</span> <span style="color:#00688b;font-weight:bold">int</span> N = <span style="color:#b452cd">100</span>;
</span></span><span style="display:flex;"><span>  	size_t size = N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> * a;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//分配通用内存
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span>  	cpu(a, N); <span style="color:#228b22">// cpu进行操作
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	size_t threads = <span style="color:#b452cd">256</span>;<span style="color:#228b22">//线程块中线程的个数
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	size_t blocks = <span style="color:#b452cd">1</span>;
</span></span><span style="display:flex;"><span>  	gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a, N); <span style="color:#228b22">//gpu进行操作
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaDeviceSynchronize(); <span style="color:#228b22">//cpu和gpu同步(如果不进行同步check必然为error)
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	check(a, N) ? printf(<span style="color:#cd5555">&#34;ok&#34;</span>) : printf(<span style="color:#cd5555">&#34;error&#34;</span>);
</span></span><span style="display:flex;"><span>  	cudaFree(a);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="异常处理">异常处理</h3>
<blockquote>
<p>普通函数异常处理</p>
</blockquote>
<p>假设一个分配内存的函数出现了错误，我们可以用cuda内置的<code>cudaError_t</code>类型来返回是否错误。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>cudaError_t err;
</span></span><span style="display:flex;"><span>err = cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">if</span> (err != cudaSuccess) {
</span></span><span style="display:flex;"><span>  	printf(<span style="color:#cd5555">&#34;Error: %s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, cudaGetErrirString(err));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Kernel函数的异常处理</p>
</blockquote>
<p>核函数的没有返回值，这需要如何处理，cuda也专门提供了<code>cudaGetLastError()</code>函数来返回是否错误：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a, N);
</span></span><span style="display:flex;"><span>err = cudaGetLastError();
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">if</span> (err != cudaSuccess) {
</span></span><span style="display:flex;"><span>  	printf(<span style="color:#cd5555">&#34;Error: %s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, cudaGetErrirString(err));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>在实际的c++编程中，我们通常会将其写成一个inline函数统一使用</strong>：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">inline</span> cudaError_t <span style="color:#008b45">checkCuda</span>(cudaError_t result) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (result != cudaSuccess) {
</span></span><span style="display:flex;"><span>      	fprintf(stderr, <span style="color:#cd5555">&#34;CUDA runtime error: %s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, cudaGetErrorString(result));
</span></span><span style="display:flex;"><span>      	assert(result == cudaSuccess);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> result;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>那么这段程序的调用方法就显而易见了：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>checkCuda(cudaGetLastError());
</span></span><span style="display:flex;"><span>checkCuda(cudaMallocManaged(&amp;a, size));
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>inline函数和普通函数的区别</p>
</blockquote>
<p>普通函数：</p>
<ol>
<li>普通函数定义通常放在头文件(.h)中，实现放在源文件(.cpp)中。</li>
<li>每次函数调用时，程序会跳转到函数的地址执行函数体中的代码。</li>
<li>普通函数适合处理较大的代码块和复杂的逻辑。</li>
</ol>
<p><code>inline</code>函数：</p>
<ol>
<li><code>inline</code>关键字用于建议编译器将函数调用处的代码替换为函数体中的代码，而不是通过跳转执行函数。</li>
<li><code>inline</code>函数通常定义放在头文件中，并且在同一编译单元内直接展开函数调用。</li>
<li>适用于短小的、频繁调用的函数，比如简单的getter和setter函数，以避免函数调用的开销。</li>
</ol>
<p>区别总结：</p>
<ol>
<li><code>inline</code>函数是对编译器的建议，而不是强制要求。编译器有权忽略<code>inline</code>关键字。</li>
<li>普通函数一般用于处理复杂的逻辑，而<code>inline</code>函数用于短小的频繁调用的代码块，以节省函数调用开销。</li>
<li><code>inline</code>函数在编译时展开代码，而普通函数是跳转执行函数体中的代码。</li>
</ol>
<p>需要注意的是，如果函数体较大或者在多个地方调用，编译器可能会忽略<code>inline</code>关键字，将其当作普通函数处理。此外，过度使用<code>inline</code>可能导致代码膨胀，增加代码段的大小，反而可能影响性能。**因此，<code>inline</code>应谨慎使用，最好只用于短小的、频繁调用的函数。**编译器在优化方面通常会自动处理函数的内联，不需要手动添加<code>inline</code>关键字。</p>
<h3 id="矩阵加法">矩阵加法</h3>
<blockquote>
<p>分别通过cpu和gpu实现矩阵的加法运算</p>
</blockquote>
<p>matrix.cu:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define N 64
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> r = blockDim.x * blockIdx.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> c = blockDim.y * blockIdx.y + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (r &lt; N &amp;&amp; c &lt; N) {
</span></span><span style="display:flex;"><span>      	c_gpu[r * N + c] = a[r * N + c] + b[r * N + c];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = a[r * N + c] + b[r * N + c];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	<span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * N + c] != c_gpu[r * N + c]) <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> *a, *b, *c_cpu, *c_gpu;
</span></span><span style="display:flex;"><span>  	size_t size = N * N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//分配globalmemory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span>  	cudaMallocManaged(&amp;b, size);
</span></span><span style="display:flex;"><span>  	cudaMallocManaged(&amp;c_cpu, size);
</span></span><span style="display:flex;"><span> 	 	cudaMallocManaged(&amp;c_gpu, size);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//初始化
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	a[r * N + c] = r;
</span></span><span style="display:flex;"><span>          	b[r * N + c] = c;
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>          	c_gpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  	dim3 threads(<span style="color:#b452cd">16</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	dim3 blocks((N + threads.x - <span style="color:#b452cd">1</span>) / threads.x, N + threads.y - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a, b, c_gpu);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//同步到cpu上
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	cpu(a, b, c_cpu);
</span></span><span style="display:flex;"><span>  	check(a, b, c_cpu, c_gpu) ? printf(<span style="color:#cd5555">&#34;ok!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>) : printf(<span style="color:#cd5555">&#34;error!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	cudaFree(a);
</span></span><span style="display:flex;"><span>  	cudaFree(b);
</span></span><span style="display:flex;"><span>  	cudaFree(c_cpu);
</span></span><span style="display:flex;"><span>  	cudaFree(c_gpu);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="cuda性能分析">CUDA性能分析</h3>
<blockquote>
<p>安装NVIDIA Nsight Systems</p>
</blockquote>
<ul>
<li>进入<a href="https://developer.nvidia.cn/gameworksdownload">官网</a>，下载<code>Nsight Systems</code>的Linux CLI的<code>.deb</code>版本</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img64.jpg" alt=""></p>
<ul>
<li>在本地进行安装：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo dpkg -i NsightSystems-linux-cli-public-2023.2.1.122-3259852.deb
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>在终端使用：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#228b22">#application是程序，application-arguments是程序参数</span>
</span></span><span style="display:flex;"><span>$ nsys [global-options] profile [options] &lt;application&gt; [application-arguments]
</span></span></code></pre></td></tr></table>
</div>
</div><p>参数的选择如下图所示：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img65.jpg" alt=""></p>
<ul>
<li>对上述矩阵加法的程序进行性能分析：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ nsys profile --stats=<span style="color:#658b00">true</span> matrix
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img66.jpg" alt=""></p>
<p><strong>可以看到我们的程序的大部分时间都花在了显存分配这件事上，那么我们优化的目标就是让GPU计算的时间占总时间的比重更大，那么程序的效率就会越高。</strong></p>
<h3 id="gpu属性">GPU属性</h3>
<p>GPU内部有许多称为<code>SM</code>的<strong>流多处理器</strong>，一个<code>SM</code>有多个流处理器，GPU在执行Kernel函数的时候，会让SM去处理Block。</p>
<p>SM会在<strong>一个名为<code>WARP</code>的线程块</strong>内创建、管理、调度和执行<strong>32</strong>个线程的线程组。所以线程数选32的倍数最佳！！</p>
<blockquote>
<p>GPU信息获取</p>
</blockquote>
<ul>
<li>编写CUDA程序获取：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> id;
</span></span><span style="display:flex;"><span>  	cudaGetDevice(&amp;id);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	cudaDeviceProp props;
</span></span><span style="display:flex;"><span>  	cudaGetDeviceProperties(&amp;props, id);
</span></span><span style="display:flex;"><span>  	printf(<span style="color:#cd5555">&#34;Device id: %d</span><span style="color:#cd5555">\n</span><span style="color:#cd5555"> \
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  	SM_num: %d</span><span style="color:#cd5555">\n</span><span style="color:#cd5555"> \
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  	capability major: %d</span><span style="color:#cd5555">\n</span><span style="color:#cd5555"> \
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  	capability minor: %d</span><span style="color:#cd5555">\n</span><span style="color:#cd5555"> \
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">  	warp size: %d</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>\
</span></span><span style="display:flex;"><span>   	, id, props.multiProcessorCount, props.major, props.minor, props.warp);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>编译运行后得到结果：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">Device</span> <span style="color:#8b008b;font-weight:bold">id</span><span style="color:#707a7c">:</span> <span style="color:#8b008b;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">SM_num</span><span style="color:#707a7c">:</span> <span style="color:#8b008b;font-weight:bold">28</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">capability</span> <span style="color:#8b008b;font-weight:bold">major</span><span style="color:#707a7c">:</span> <span style="color:#8b008b;font-weight:bold">8</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">capability</span> <span style="color:#8b008b;font-weight:bold">minor</span><span style="color:#707a7c">:</span> <span style="color:#8b008b;font-weight:bold">6</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">warp</span> <span style="color:#8b008b;font-weight:bold">size</span><span style="color:#707a7c">:</span> <span style="color:#8b008b;font-weight:bold">32</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>查询我的显卡（RTX3060）的流处理器总共有3564个，那么一个SM（流多处理器）的流处理器个数为128个。</p>
<h3 id="显存分配2">显存分配（2）</h3>
<p>前面我们使用的显存分配方式为<code>cudaMallocManaged()</code>方法，<strong>这种方法第一时间分配的其实并不是显存，而是统一内存（UM）。分配UM时，内存尚未驻留在主机（Host）上或设备（Device）上。主机或者设备尝试访问内存时会发生缺页中断，此时主机或者设备才会批量迁移所需要的数据。也就是说CPU和GPU访问该内存都会发生上述的事件。</strong></p>
<p>如果分配的内存既被CPU调用，又被GPU调用，那么便可以使用这种分配方式。</p>
<p>我们使用CUDA性能分析工具对前面<code>hello-gpu</code>的程序块进行分析：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ nsys profile --stats=<span style="color:#658b00">true</span> hello-gpu
</span></span></code></pre></td></tr></table>
</div>
</div><p>得到的部分信息如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img67.jpg" alt=""></p>
<p>可以看到有<code>HtoD</code>和<code>DtoH</code>，这是由缺页触发的。</p>
<blockquote>
<p>如何避免缺页触发内存拷贝？</p>
</blockquote>
<p>我们可以通过<code>cudaMemPrefetchAsync</code>函数将托管内存异步预取到GPU设备上或CPU。那么在代码上该如何操作(在前面matrix.cu上进行修改)：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define N 64
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> r = blockDim.x * blockIdx.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> c = blockDim.y * blockIdx.y + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (r &lt; N &amp;&amp; c &lt; N) {
</span></span><span style="display:flex;"><span>      	c_gpu[r * N + c] = a[r * N + c] + b[r * N + c];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = a[r * N + c] + b[r * N + c];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	<span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * N + c] != c_gpu[r * N + c]) <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> *a, *b, *c_cpu, *c_gpu;
</span></span><span style="display:flex;"><span>  	size_t size = N * N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//分配globalmemory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMallocManaged(&amp;a, size);
</span></span><span style="display:flex;"><span>  	cudaMallocManaged(&amp;b, size);
</span></span><span style="display:flex;"><span>  	cudaMallocManaged(&amp;c_cpu, size);
</span></span><span style="display:flex;"><span> 	 	cudaMallocManaged(&amp;c_gpu, size);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//初始化
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	a[r * N + c] = r;
</span></span><span style="display:flex;"><span>          	b[r * N + c] = c;
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>          	c_gpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//在GPU访问统一内存之前进行预取，防止发生缺页影响性能
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> id;
</span></span><span style="display:flex;"><span>  	cudaGetDevice(&amp;id);
</span></span><span style="display:flex;"><span>  	cudaMemPrefetchAsync(a, size, id);
</span></span><span style="display:flex;"><span>  	cudaMemPrefetchAsync(b, size, id);
</span></span><span style="display:flex;"><span>  	cudaMemPrefetchAsync(c_gpu, size, id);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  	dim3 threads(<span style="color:#b452cd">16</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	dim3 blocks((N + threads.x - <span style="color:#b452cd">1</span>) / threads.x, N + threads.y - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a, b, c_gpu);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//数据同步到CPU之前将GPU的内存预取到CPU上
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//同步到cpu上
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	cpu(a, b, c_cpu);
</span></span><span style="display:flex;"><span>  	check(a, b, c_cpu, c_gpu) ? printf(<span style="color:#cd5555">&#34;ok!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>) : printf(<span style="color:#cd5555">&#34;error!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	cudaFree(a);
</span></span><span style="display:flex;"><span>  	cudaFree(b);
</span></span><span style="display:flex;"><span>  	cudaFree(c_cpu);
</span></span><span style="display:flex;"><span>  	cudaFree(c_gpu);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>对旧的<code>matrix.cu</code>和新的<code>matrix.cu</code>分别进行编译并进行性能分析：</p>
<p>旧的matrix.cu:</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img68.jpg" alt=""></p>
<p>新的matrix.cu:</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img69.jpg" alt=""></p>
<p>明显可以看到内存拷贝的开销变少了。无论是Host-&gt;Device还是Device-&gt;Host。</p>
<h3 id="显存分配3">显存分配（3）</h3>
<p>那么CUDA编程中除了分配统一内存，是否可以直接分配GPU显存，或者CPU锁页内存。</p>
<ul>
<li><code>cudaMalloc</code>命令将直接为处于活动状态的GPU分配显存。这可以防止出现所有GPU分页错误，而代价是主机代码将无法访问该命令返回的指针。</li>
<li><code>cudaMallocHost</code>命令将直接为CPU分配内存。该命令可以&quot;固定&quot;内存（pinned memory）或&quot;锁页&quot;内存（page-locked memory）。它允许将内存异步拷贝至GPU或从GPU异步拷贝至内存。固定内存过多则会干扰CPU性能。释放固定内存时，应使用<code>cudaFreeHost</code>命令。</li>
<li>无论是从主机到设备还是设备到主机，<code>cudaMemcpy</code>命令均可拷贝（而非传输）内存。</li>
</ul>
<p>我们将之前的matrix.cu再次改写：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">87
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;assert&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define N 64
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a_gpu, <span style="color:#00688b;font-weight:bold">int</span> *b_gpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> r = blockDim.x * blockIdx.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> c = blockDim.y * blockIdx.y + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (r &lt; N &amp;&amp; c &lt; N) {
</span></span><span style="display:flex;"><span>      	c_gpu[r * N + c] = a_gpu[r * N + c] + b_gpu[r * N + c];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a_cpu, <span style="color:#00688b;font-weight:bold">int</span> *b_cpu, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = a_cpu[r * N + c] + b_cpu[r * N + c];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *c_cpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	<span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * N + c] != c_gpu[r * N + c]) <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">inline</span> cudaError_t <span style="color:#008b45">checkCuda</span>(cudaError_t result) {
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (result != cudaSuccess) {
</span></span><span style="display:flex;"><span>      	fprintf(stderr, <span style="color:#cd5555">&#34;CUDA runtime error: %s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, cudaGetErrorString(result));
</span></span><span style="display:flex;"><span>      	assert(result == cudaSuccess);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">return</span> result;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> *a_cpu, *b_cpu, *a_gpu, *b_gpu, *c_gpu2cpu, *c_cpu, *c_gpu;
</span></span><span style="display:flex;"><span>  	size_t size = N * N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//分配memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMallocHost(&amp;a_cpu, size);
</span></span><span style="display:flex;"><span>  	cudaMallocHost(&amp;b_cpu, size);
</span></span><span style="display:flex;"><span>  	cudaMallocHost(&amp;c_cpu, size);
</span></span><span style="display:flex;"><span>  	cudaMallocHost(&amp;c_gpu2cpu, size);
</span></span><span style="display:flex;"><span>  	cudaMalloc(&amp;a_gpu, size);
</span></span><span style="display:flex;"><span>  	cudaMalloc(&amp;b_gpu, size);
</span></span><span style="display:flex;"><span> 	 	cudaMalloc(&amp;c_gpu, size);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//初始化
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>          	a_cpu[r * N + c] = r;
</span></span><span style="display:flex;"><span>          	b_cpu[r * N + c] = c;
</span></span><span style="display:flex;"><span>          	c_cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>          	c_gpu2cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>          	<span style="color:#228b22">//c_gpu[r * N + c] = 0; 不能直接访问GPU
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  	cpu(a_cpu, b_cpu, c_cpu);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	dim3 threads(<span style="color:#b452cd">16</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	dim3 blocks((N + threads.x - <span style="color:#b452cd">1</span>) / threads.x, N + threads.y - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//理论上的内存拷贝，但其实不需要，因为锁页内存在CUDA中不会被映射到硬盘上，但可以直接被GPU调用
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaMemcpy(a_gpu, a_cpu, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>    cudaMemcpy(b_gpu, b_cpu, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>    gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a_gpu, b_gpu, c_gpu);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//同步到cpu上
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>  	cudaMemcpy(c_gpu2cpu, c_cpu, size, cudaMemcpyDeviceToHost);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	check(c_cpu, c_gpu) ? printf(<span style="color:#cd5555">&#34;ok!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>) : printf(<span style="color:#cd5555">&#34;error!</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	cudaFreeHost(a_cpu);
</span></span><span style="display:flex;"><span>  	cudaFreeHost(b_cpu);
</span></span><span style="display:flex;"><span>  	cudaFreeHost(c_cpu);
</span></span><span style="display:flex;"><span>  	cudaFreeHost(c_gpu2cpu);
</span></span><span style="display:flex;"><span>  	cudaFree(c_gpu);
</span></span><span style="display:flex;"><span>  	cudaFree(a_gpu);
</span></span><span style="display:flex;"><span>  	cudaFree(b_gpu);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>为什么GPU可以直接调用cudaMallocHost分配的锁页内存？</p>
</blockquote>
<p>在CUDA编程中，使用cudaMallocHost函数分配的内存是锁页内存，这意味着该内存页不会被交换到磁盘上，从而提高了访问速度。此外，<strong>锁页内存还可以直接与GPU内存进行数据传输，而不需要通过PCIe总线，从而进一步提高了数据传输速度。</strong></p>
<p>在CUDA编程中，GPU可以直接使用cudaMallocHost分配的锁页内存，是因为这些内存页已经被固定在物理内存中，并且可以直接映射到GPU的地址空间中。因此，在Kernel函数中可以直接访问这些内存页，而不需要进行额外的数据传输或者拷贝操作。</p>
<p>需要注意的是，在使用锁页内存时需要小心，因为它们会占用较多的系统内存，并且可能会导致系统变慢或者崩溃。因此，在使用锁页内存时需要谨慎考虑内存使用量，并且及时释放不再需要的内存。</p>
<h3 id="cuda流">CUDA流</h3>
<p>在CUDA编程中，流是按照顺序执行的一系列命令构成。在CUDA应用程序中，核函数的执行以及一些内存传输均在CUDA流中进行。</p>
<p>CUDA流行为的几项规则：</p>
<ul>
<li>在给定流中所有操作回按序执行。</li>
<li>就不同非默认流中的操作而言，无法保证会按彼此之间的任何特定顺序执行</li>
<li>默认流具有阻断能力，它会等待其他已在运行的所有流完成当前操作后才运行，但其自身运行完毕之前，也会阻碍其他流的运行。</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img70.jpg" alt=""></p>
<blockquote>
<p>CUDA流如何创建，运行机制是什么？</p>
</blockquote>
<p>用NVIDIA官方的例程来解释一下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">const</span> <span style="color:#00688b;font-weight:bold">int</span> N = <span style="color:#b452cd">1</span> &lt;&lt; <span style="color:#b452cd">20</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">kernel</span>(<span style="color:#00688b;font-weight:bold">float</span> *x, <span style="color:#00688b;font-weight:bold">int</span> n) {
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> tid = threadIdx.x + blockIdx.x +  blockDim.x;
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = tid; i &lt; n; i += blockDim.x * gridDim.x) {
</span></span><span style="display:flex;"><span>        x[i] += sqrt(pow(<span style="color:#b452cd">3.14159</span>, i));                                                                                                                                                                                                                                                                                                             
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">const</span> <span style="color:#00688b;font-weight:bold">int</span> num_streams = <span style="color:#b452cd">8</span>;
</span></span><span style="display:flex;"><span>    cudaStream_t streams[num_streams];
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">float</span> *data[num_streams];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; num_streams; i++) {
</span></span><span style="display:flex;"><span>        cudaStreamCreate(&amp;streams[i]);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        cudaMalloc(&amp;data[i], N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">//launch one worker kernel per stream
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>        kernel&lt;&lt;&lt;<span style="color:#b452cd">1</span>, <span style="color:#b452cd">64</span>, <span style="color:#b452cd">0</span>, streams[i]&gt;&gt;&gt;(data[i], N);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22">//launch a dummy kernel
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>        kernel&lt;&lt;&lt;<span style="color:#b452cd">1</span>, <span style="color:#b452cd">1</span>&gt;&gt;&gt;(<span style="color:#b452cd">0</span>, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaDeviceReset();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>上面的<code>kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;</code>代表使用默认流，如果没有这句话，那么上面的每次计算几乎是并行的，因为每个Kernel函数执行的时间较长，不是默认流的情况下，新的流不断执行Kernel函数，而上一个Kernel函数还没有执行完，就会出现类似于流水线并行的方式。</p>
<p>如果有这个虚拟的默认流程序，就会将所有的Kernel函数分割成按序进行。<strong>因为在非默认流有函数运行时，默认流程序会等待；在默认流执行函数时，非默认流的程序必须等待。</strong></p>
<blockquote>
<p>通过流实现内存分配</p>
</blockquote>
<p><code>cudaMemcpyAsync</code>可以从主机到设备或从设备到主机异步复制内存。</p>
<p><strong>与核函数的执行类似，<code>cudaMemcpyAsync</code>在默认情况下仅相对主机是异步的。默认情况下，它在默认流中执行，因此对于GPU上发生的其他CUDA操作而言，它是阻塞操作。</strong></p>
<p><code>cudaMemcpyAsync</code>函数将默认流作为可选的第5个参数。通过向其传递非默认流，可以将内存传输与其他默认流中发生的其他CUDA操作并发。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>cudaStream_t stream;
</span></span><span style="display:flex;"><span>cudaStreamCreate(&amp;stream);
</span></span><span style="display:flex;"><span>cudaMemcpyAsync(&amp;device_array[segmentOffset],
</span></span><span style="display:flex;"><span>               	&amp;host_array[segmentOffset],
</span></span><span style="display:flex;"><span>                segmentSize,
</span></span><span style="display:flex;"><span>                cudaMemcpyHostToDevice,
</span></span><span style="display:flex;"><span>               	stream);
</span></span></code></pre></td></tr></table>
</div>
</div><p>将<code>matrix_cudamalloc.cu</code>修改：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;assert.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define N 10000
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">gpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a_gpu, <span style="color:#00688b;font-weight:bold">int</span> *b_gpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> r = blockDim.x * blockIdx.x + threadIdx.x;
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> c = blockDim.y * blockIdx.y + threadIdx.y;
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> (r &lt; N &amp;&amp; c &lt; N) {
</span></span><span style="display:flex;"><span>        c_gpu[r * N + c] = a_gpu[r * N + c] + b_gpu[r * N + c];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">cpu</span>(<span style="color:#00688b;font-weight:bold">int</span> *a, <span style="color:#00688b;font-weight:bold">int</span> *b, <span style="color:#00688b;font-weight:bold">int</span> *c_cpu) {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>            c_cpu[r * N + c] = a[r * N + c] + b[r * N + c];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">int</span> *c_cpu, <span style="color:#00688b;font-weight:bold">int</span> *c_gpu) {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * N + c] != c_gpu[r * N + c]) {
</span></span><span style="display:flex;"><span>                <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">inline</span> cudaError_t <span style="color:#008b45">checkCuda</span>(cudaError_t result) {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> (result != cudaSuccess) {
</span></span><span style="display:flex;"><span>        fprintf(stderr, <span style="color:#cd5555">&#34;CUDA runtime error: %s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, cudaGetErrorString(result));
</span></span><span style="display:flex;"><span>        assert(result != cudaSuccess);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> result;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> *a_cpu, *b_cpu, *a_gpu, *b_gpu, *c_cpu, *c_gpu, *c_gpu2cpu;
</span></span><span style="display:flex;"><span>    size_t size = N * N * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">int</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;a_cpu, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;b_cpu, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;c_cpu, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;c_gpu2cpu, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;a_gpu, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;b_gpu, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;c_gpu, size);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">//初始化
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; N; r++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; N; c++) {
</span></span><span style="display:flex;"><span>            a_cpu[r * N + c] = r;
</span></span><span style="display:flex;"><span>            b_cpu[r * N + c] = c;
</span></span><span style="display:flex;"><span>            c_cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>            <span style="color:#228b22">// c_gpu[r * N + c] = 0;
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>            c_gpu2cpu[r * N + c] = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cpu(a_cpu, b_cpu, c_cpu);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dim3 threads(<span style="color:#b452cd">16</span>, <span style="color:#b452cd">16</span>, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>    dim3 blocks((N + threads.x - <span style="color:#b452cd">1</span>) / threads.x, (N + threads.y - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaStream_t s1, s2, s3;
</span></span><span style="display:flex;"><span>    cudaStreamCreate(&amp;s1);
</span></span><span style="display:flex;"><span>    cudaStreamCreate(&amp;s2);
</span></span><span style="display:flex;"><span>    cudaStreamCreate(&amp;s3);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">//操纵GPU之前需要拷贝内存（新显卡不需要这项操作也是可以的）
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaMemcpyAsync(a_gpu, a_cpu, size, cudaMemcpyHostToDevice, s1);
</span></span><span style="display:flex;"><span>    cudaMemcpyAsync(b_gpu, b_cpu, size, cudaMemcpyHostToDevice, s2);
</span></span><span style="display:flex;"><span>    gpu&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(a_gpu, b_gpu, c_gpu);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    checkCuda(cudaGetLastError());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaMemcpyAsync(c_gpu2cpu, c_gpu, size, cudaMemcpyDeviceToHost, s3);
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">//将数据同步到我们的cpu上
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    check(c_cpu, c_gpu2cpu) ? printf(<span style="color:#cd5555">&#34;ok</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>) : printf(<span style="color:#cd5555">&#34;error</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaStreamDestroy(s1);
</span></span><span style="display:flex;"><span>    cudaStreamDestroy(s2);
</span></span><span style="display:flex;"><span>    cudaFreeHost(a_cpu);
</span></span><span style="display:flex;"><span>    cudaFreeHost(b_cpu);
</span></span><span style="display:flex;"><span>    cudaFreeHost(c_cpu);
</span></span><span style="display:flex;"><span>    cudaFreeHost(c_gpu2cpu);
</span></span><span style="display:flex;"><span>    cudaFree(a_gpu);
</span></span><span style="display:flex;"><span>    cudaFree(b_gpu);
</span></span><span style="display:flex;"><span>    cudaFree(c_gpu);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以看到我们将内存拷贝的过程交给了流，通过CUDA性能分析工具分析了程序。单向的内存拷贝不会进行重叠，也就是说同一时间主机向设备或者设备向主机只能进行一次内存拷贝。</p>
<h3 id="cuda共享内存">CUDA共享内存</h3>
<p>共享内存其实所谓的<code>shared memory</code>，其能为<strong>同一个线程块内所有线程共享</strong>。共享内存是一种稀缺资源，若线程位于分配内存的线程块之外，则无法访问共享内存，且<strong>此类内存在核函数执行完毕之后就会立即被释放</strong>。共享内存带宽远高于全局内存（<code>global memory</code>），有助于优化性能。</p>
<blockquote>
<p>程序计时</p>
</blockquote>
<p>CUDA编程有专门用于计时的程序：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>cudaEvent_t startEvent, stopEvent;
</span></span><span style="display:flex;"><span>cudaEventCreate(&amp;startEvent);
</span></span><span style="display:flex;"><span>cudaEventCreate(&amp;stopEvent);
</span></span><span style="display:flex;"><span>cudaEventRecord(startEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>... <span style="color:#228b22">//中间夹需要计算时间的程序
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>cudaEventRecord(stopEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span><span style="color:#228b22">//由于这个cudaEvent这个操作是异步的，所以需要Synchronize一下
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>cudaEventSynchronize(stopEvent);
</span></span><span style="display:flex;"><span>cudaEventElapsedTime(&amp;ms, startEvent, stopEvent);
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>共享内存使用</p>
</blockquote>
<p>我们使用一个矩阵转置的例子来学习一下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">87
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">/* CUDA程序:矩阵转置实现 */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define TILE_DIM 32 </span><span style="color:#228b22">//假设每次能操纵的矩阵小块的宽和高为32
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#1e889b">#define BLOCK_SIZE 8 
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#define MX 2048
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#define MY 2048
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">transpose</span>(<span style="color:#00688b;font-weight:bold">float</span>* outputdata, <span style="color:#00688b;font-weight:bold">float</span>* inputdata) {
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> x = blockIdx.x * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> y = blockIdx.y * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> w = gridDim.x * TILE_DIM;
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> (x &gt;= MX || y &gt;= MY) <span style="color:#8b008b;font-weight:bold">return</span>; 
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; TILE_DIM; i += BLOCK_SIZE) {
</span></span><span style="display:flex;"><span>        outputdata[x * w + y + i] = inputdata[(y + i) * w + x];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">float</span> *c_cpu, <span style="color:#00688b;font-weight:bold">float</span> *c_gpu) {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; MX; r++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; MY; c++) {
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * MX + c] != c_gpu[r * MY + c]) {
</span></span><span style="display:flex;"><span>                <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    size_t size = MX * MY * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">float</span> *H_idata, *H_odata, *D_idata, *D_odata, *res;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">float</span> ms; <span style="color:#228b22">//用于记录程序计算使用的时间
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaMallocHost(&amp;H_idata, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;H_odata, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;res, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;D_idata, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;D_odata, size);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dim3 threads(TILE_DIM, BLOCK_SIZE, <span style="color:#b452cd">1</span>); <span style="color:#228b22">// 给定线程数为TILE_DIM * BLOCK_SIZE 
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    dim3 blocks((MX + TILE_DIM - <span style="color:#b452cd">1</span>) / threads.x, (MY + TILE_DIM - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; MX; i++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> j = <span style="color:#b452cd">0</span>; j &lt; MY; j++) {
</span></span><span style="display:flex;"><span>            H_idata[i * MY + j] = i * MY + j;
</span></span><span style="display:flex;"><span>            res[i * MY + j] = j * MY + i;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>  	cudaEvent_t startEvent, stopEvent;
</span></span><span style="display:flex;"><span>		cudaEventCreate(&amp;startEvent);
</span></span><span style="display:flex;"><span>		cudaEventCreate(&amp;stopEvent);
</span></span><span style="display:flex;"><span>		cudaEventRecord(startEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>    cudaMemcpy(D_idata, H_idata, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>    cudaMemcpy(D_odata, H_odata, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>		<span style="color:#228b22">// 开始计时
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaEventRecord(startEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; <span style="color:#b452cd">100</span>; i++) {
</span></span><span style="display:flex;"><span>      	transpose&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(D_odata, D_idata);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>		<span style="color:#228b22">// 停止计时
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaEventRecord(stopEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 异步操作等待同步
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	cudaEventSynchronize(stopEvent);
</span></span><span style="display:flex;"><span>		cudaEventElapsedTime(&amp;ms, startEvent, stopEvent);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//打印计算信息
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	printf(<span style="color:#cd5555">&#34;%25s%25s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, <span style="color:#cd5555">&#34;Routine&#34;</span>, <span style="color:#cd5555">&#34;Bandwidth (GB/s)&#34;</span>);
</span></span><span style="display:flex;"><span>  	printf(<span style="color:#cd5555">&#34;%20.2f</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, <span style="color:#b452cd">2</span> * MX * MY * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>) * <span style="color:#b452cd">1e-6</span> * <span style="color:#b452cd">100</span> / ms);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    cudaMemcpy(H_odata, D_odata, size, cudaMemcpyDeviceToHost);
</span></span><span style="display:flex;"><span>    cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>    check(res, H_odata) ? printf(<span style="color:#cd5555">&#34;ok&#34;</span>) : printf(<span style="color:#cd5555">&#34;error&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaFreeHost(H_idata);
</span></span><span style="display:flex;"><span>    cudaFreeHost(H_odata);
</span></span><span style="display:flex;"><span>    cudaFree(D_idata);
</span></span><span style="display:flex;"><span>    cudaFree(D_odata);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>得到的带宽（global memory）计算出来为90GB/s左右。</p>
<p>接下来，我们要使用<code>shared memory</code>来优化：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">95
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">/* CUDA程序:矩阵转置实现 */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#include</span> <span style="color:#1e889b">&lt;stdio.h&gt;</span><span style="color:#1e889b">
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span><span style="color:#1e889b">#define TILE_DIM 32 </span><span style="color:#228b22">//假设每次能操纵的矩阵小块的宽和高为32
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#1e889b">#define BLOCK_SIZE 8 
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#define MX 2048
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b">#define MY 2048
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">transpose2</span>(<span style="color:#00688b;font-weight:bold">float</span>* outputdata, <span style="color:#00688b;font-weight:bold">float</span>* inputdata) {
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 一个block内部的share memory有32个存储块
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    __shared__ <span style="color:#00688b;font-weight:bold">float</span> title[TILE_DIM][TILE_DIM];
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> x = blockIdx.x * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> y = blockIdx.y * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">int</span> w = gridDim.x * TILE_DIM;
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">if</span> (x &gt;= MX || y &gt;= MY) <span style="color:#8b008b;font-weight:bold">return</span>; 
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; TILE_DIM; i += BLOCK_SIZE) {
</span></span><span style="display:flex;"><span>        title[threadIdx.y + i][threadIdx.x] = inputdata[(y + i) * w + x];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    __syncthreads();
</span></span><span style="display:flex;"><span>    x = blockIdx.y * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>    y = blockIdx.x * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; TILE_DIM; i += BLOCK_SIZE) {
</span></span><span style="display:flex;"><span>        outputdata[(y + i) * w + x] = title[threadIdx.x][threadIdx.y + i];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">bool</span> <span style="color:#008b45">check</span>(<span style="color:#00688b;font-weight:bold">float</span> *c_cpu, <span style="color:#00688b;font-weight:bold">float</span> *c_gpu) {
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> r = <span style="color:#b452cd">0</span>; r &lt; MX; r++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> c = <span style="color:#b452cd">0</span>; c &lt; MY; c++) {
</span></span><span style="display:flex;"><span>            <span style="color:#8b008b;font-weight:bold">if</span> (c_cpu[r * MX + c] != c_gpu[r * MY + c]) {
</span></span><span style="display:flex;"><span>                <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">false</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> <span style="color:#658b00">true</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>    size_t size = MX * MY * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">float</span> *H_idata, *H_odata, *D_idata, *D_odata, *res;
</span></span><span style="display:flex;"><span>    <span style="color:#00688b;font-weight:bold">float</span> ms; <span style="color:#228b22">//用于记录程序计算使用的时间
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaMallocHost(&amp;H_idata, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;H_odata, size);
</span></span><span style="display:flex;"><span>    cudaMallocHost(&amp;res, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;D_idata, size);
</span></span><span style="display:flex;"><span>    cudaMalloc(&amp;D_odata, size);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dim3 threads(TILE_DIM, BLOCK_SIZE, <span style="color:#b452cd">1</span>); <span style="color:#228b22">// 给定线程数为TILE_DIM * BLOCK_SIZE 
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    dim3 blocks((MX + TILE_DIM - <span style="color:#b452cd">1</span>) / threads.x, (MY + TILE_DIM - <span style="color:#b452cd">1</span>) / threads.y, <span style="color:#b452cd">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; MX; i++) {
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> j = <span style="color:#b452cd">0</span>; j &lt; MY; j++) {
</span></span><span style="display:flex;"><span>            H_idata[i * MY + j] = i * MY + j;
</span></span><span style="display:flex;"><span>            res[i * MY + j] = j * MY + i;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    cudaEvent_t startEvent, stopEvent;
</span></span><span style="display:flex;"><span>    cudaEventCreate(&amp;startEvent);
</span></span><span style="display:flex;"><span>    cudaEventCreate(&amp;stopEvent);
</span></span><span style="display:flex;"><span>    cudaEventRecord(startEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    cudaMemcpy(D_idata, H_idata, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>    cudaMemcpy(D_odata, H_odata, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">// 开始计时
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaEventRecord(startEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; <span style="color:#b452cd">100</span>; i++) {
</span></span><span style="display:flex;"><span>        transpose2&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(D_odata, D_idata);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">// 停止计时
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaEventRecord(stopEvent, <span style="color:#b452cd">0</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">// 异步操作等待同步
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    cudaEventSynchronize(stopEvent);
</span></span><span style="display:flex;"><span>    cudaEventElapsedTime(&amp;ms, startEvent, stopEvent);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#228b22">//打印计算信息
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>    printf(<span style="color:#cd5555">&#34;%25s%25s</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, <span style="color:#cd5555">&#34;Routine&#34;</span>, <span style="color:#cd5555">&#34;Bandwidth (GB/s)&#34;</span>);
</span></span><span style="display:flex;"><span>    printf(<span style="color:#cd5555">&#34;%25s&#34;</span>, <span style="color:#cd5555">&#34;native transpose&#34;</span>);
</span></span><span style="display:flex;"><span>    printf(<span style="color:#cd5555">&#34;%20.2f</span><span style="color:#cd5555">\n</span><span style="color:#cd5555">&#34;</span>, <span style="color:#b452cd">2</span> * MX * MY * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>) * <span style="color:#b452cd">1e-6</span> * <span style="color:#b452cd">100</span> / ms);
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    cudaMemcpy(H_odata, D_odata, size, cudaMemcpyDeviceToHost);
</span></span><span style="display:flex;"><span>    cudaDeviceSynchronize();
</span></span><span style="display:flex;"><span>    check(res, H_odata) ? printf(<span style="color:#cd5555">&#34;ok&#34;</span>) : printf(<span style="color:#cd5555">&#34;error&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cudaFreeHost(H_idata);
</span></span><span style="display:flex;"><span>    cudaFreeHost(H_odata);
</span></span><span style="display:flex;"><span>    cudaFree(D_idata);
</span></span><span style="display:flex;"><span>    cudaFree(D_odata);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>带宽（shared memory）来到了250GB/s左右。</p>
<blockquote>
<p>优化分析</p>
</blockquote>
<ul>
<li>
<p>在这个优化后的CUDA程序中，使用了GPU的共享内存来实现矩阵转置操作。共享内存是每个block共享的内存空间，在block内的线程可以高效地进行数据交换和共享，从而提高并行计算效率。优化后的transpose2函数中，首先定义了一个大小为TILE_DIM x TILE_DIM的共享内存数组<code>title</code>，它用于暂存每个线程所需要的数据块。然后，将输入矩阵中的数据加载到共享内存中，其中每个线程负责加载一个数据块。接着，使用<code>__syncthreads()</code>进行同步，保证所有线程都已经加载完毕，然后再将共享内存中的数据写回到输出矩阵中，实现矩阵转置操作。这种优化的思路是将数据块加载到共享内存中，以减少对全局内存的访问次数，从而提高访存效率。由于共享内存的访问速度相比全局内存更快，且共享内存是block级别的，因此可以在一个block内高效地进行数据交换和共享，从而减少数据冗余和重复计算。</p>
</li>
<li>
<p>1.在优化后的transpose2函数中，交换坐标是为了实现矩阵转置的正确性。由于共享内存中的数据是以“行优先”方式存储的，而输出矩阵需要以“列优先”方式存储，因此在将共享内存中的数据写回到输出矩阵时，需要进行坐标的交换。具体来说，原始的输入矩阵在全局内存中是按照行优先的方式存储的，即以连续的行数据存储。而共享内存<code>title</code>中加载的数据也是以行优先的方式存储的，因为每个线程在加载数据时是按照每一行的数据块来加载的。在共享内存中，<code>title[threadIdx.y][threadIdx.x]</code>保存的就是<code>inputdata[(y + threadIdx.y) * w + x + threadIdx.x]</code>的值，其中<code>threadIdx.y</code>表示行索引偏移，<code>threadIdx.x</code>表示列索引偏移。但是，输出矩阵需要以列优先的方式存储，即以连续的列数据存储。因此，我们在写回输出矩阵时需要将共享内存中的行数据按列的方式重新排列。为了实现这个转置过程，我们交换了<code>x</code>和<code>y</code>的值，并且在写回输出矩阵时，通过<code>outputdata[(y + i) * w + x]</code>将共享内存中的行数据转置为输出矩阵的列数据。</p>
</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img71.jpg" alt=""></p>
<ul>
<li>整个过程可以用如下伪代码表示：</li>
</ul>
<pre tabindex="0"><code>for each block in grid:
    load data from global memory to shared memory (row-major order)
    synchronize threads in the block
    transpose data in shared memory (row-major to column-major)
    write data back from shared memory to global memory (column-major order)
</code></pre><p>这样，通过对共享内存中的数据进行转置，就能够实现矩阵的正确转置操作。<strong>这种方式减少了全局内存的访问次数，并且通过共享内存的高速缓存和块内线程的并行计算，提高了整体矩阵转置的性能。</strong></p>
<blockquote>
<p>存储块冲突（bank confilict）</p>
</blockquote>
<p>共享内存一共有32个存储块，且内存读写可以同时运行。当并行线程尝试访问同一存储块内的内存时，我们将这种情况称为<strong>存储块冲突</strong>，该冲突将导致操作的顺序化。</p>
<p>使用Padding避免存储体冲突，见下图：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img72.jpg" alt=""></p>
<p>——&gt;</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img73.jpg" alt="">
原来假设为4个bank，现在填充数组的时候多填充一位，但由于bank是按顺序读取，那么棕色的部分就会占位，但不会产生作用。所以Bank读取时不会产生冲突。</p>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2023-08-01</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://caixiongjiang.github.io/blog/2023/%E5%AE%9E%E4%B9%A0/%E4%BA%9A%E4%BF%A1%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/">
			下回<br>亚信算法实习笔记
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2023/hpc/%E4%B8%AD%E7%A7%91%E5%A4%A7cuda%E6%95%99%E7%A8%8B/">
			上回<br>中科大CUDA教程
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
