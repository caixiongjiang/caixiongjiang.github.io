<!DOCTYPE html>
<html><head>
<title>中科大CUDA教程</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="CUDA硬件和逻辑设计，以及部分CUDA编程和优化">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="中科大CUDA教程" />
<meta property="og:description" content="CUDA硬件和逻辑设计，以及部分CUDA编程和优化" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2023/hpc/%E4%B8%AD%E7%A7%91%E5%A4%A7cuda%E6%95%99%E7%A8%8B/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2023-07-19T18:18:05+08:00" />
<meta property="article:modified_time" content="2023-08-08T09:19:06+08:00" />
<meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2023/hpc/cuda%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" /><meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/" />











<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="https://jarson-cai.gitee.io/jarson-cai-blog">
    MiFeng
</a>
<br>

<a href="nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e4%b8%ad%e7%a7%91%e5%a4%a7cuda%e7%bc%96%e7%a8%8b" onclick="onNavClick(`#中科大cuda编程-nav`)" id="中科大cuda编程-nav">
									中科大CUDA编程
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cpu%e4%bd%93%e7%b3%bb%e6%9e%b6%e6%9e%84%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#cpu体系架构概述-nav`)" id="cpu体系架构概述-nav">
									CPU体系架构概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%8e%b0%e4%bb%a3cpu%e6%9e%b6%e6%9e%84%e5%92%8c%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96" onclick="onNavClick(`#现代cpu架构和性能优化-nav`)" id="现代cpu架构和性能优化-nav">
									现代CPU架构和性能优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e5%99%a8%e6%9e%b6%e6%9e%84%e5%b1%82%e6%ac%a1" onclick="onNavClick(`#存储器架构层次-nav`)" id="存储器架构层次-nav">
									存储器架构/层次
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%90%91%e9%87%8f%e8%bf%90%e7%ae%97" onclick="onNavClick(`#向量运算-nav`)" id="向量运算-nav">
									向量运算
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e7%ba%a7%e7%9a%84%e5%b9%b6%e8%a1%8c" onclick="onNavClick(`#线程级的并行-nav`)" id="线程级的并行-nav">
									线程级的并行
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cpu%e7%9a%84%e7%93%b6%e9%a2%88" onclick="onNavClick(`#cpu的瓶颈-nav`)" id="cpu的瓶颈-nav">
									CPU的瓶颈
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#并行程序设计概述-nav`)" id="并行程序设计概述-nav">
									并行程序设计概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e6%a8%a1%e5%bc%8f" onclick="onNavClick(`#并行计算模式-nav`)" id="并行计算模式-nav">
									并行计算模式
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e5%99%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#存储器架构-nav`)" id="存储器架构-nav">
									存储器架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#并行编程模型-nav`)" id="并行编程模型-nav">
									并行编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e5%bc%80%e5%8f%91%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e5%92%8c%e5%b7%a5%e5%85%b7%e9%85%8d%e7%bd%ae" onclick="onNavClick(`#cuda开发环境搭建和工具配置-nav`)" id="cuda开发环境搭建和工具配置-nav">
									CUDA开发环境搭建和工具配置
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e4%bd%93%e7%b3%bb%e6%9e%b6%e6%9e%84%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#gpu体系架构概述-nav`)" id="gpu体系架构概述-nav">
									GPU体系架构概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#gpu%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#gpu架构-nav`)" id="gpu架构-nav">
									GPU架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e7%9a%84%e5%ad%98%e5%82%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#gpu的存储架构-nav`)" id="gpu的存储架构-nav">
									GPU的存储架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cudagpu%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#cudagpu编程模型-nav`)" id="cudagpu编程模型-nav">
									CUDA/GPU编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cpu%e5%92%8cgpu%e4%ba%92%e5%8a%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#cpu和gpu互动模型-nav`)" id="cpu和gpu互动模型-nav">
									CPU和GPU互动模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e7%9a%84%e7%ba%bf%e7%a8%8b%e7%bb%84%e7%bb%87%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#gpu的线程组织模型-nav`)" id="gpu的线程组织模型-nav">
									GPU的线程组织模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#gpu存储模型-nav`)" id="gpu存储模型-nav">
									GPU存储模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#编程模型-nav`)" id="编程模型-nav">
									编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b1" onclick="onNavClick(`#cuda编程1-nav`)" id="cuda编程1-nav">
									CUDA编程（1）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cuda%e6%9c%af%e8%af%ad" onclick="onNavClick(`#cuda术语-nav`)" id="cuda术语-nav">
									CUDA术语
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e7%9a%84%e5%b1%82%e6%ac%a1" onclick="onNavClick(`#线程的层次-nav`)" id="线程的层次-nav">
									线程的层次
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e5%b1%82%e6%ac%a1%e7%bb%93%e5%90%88gpu%e5%ad%98%e5%82%a8%e5%b1%82%e6%ac%a1%e5%8a%a0%e6%b7%b1%e5%af%b9%e4%bb%a3%e7%a0%81%e6%93%8d%e4%bd%9c%e7%9a%84%e7%a1%ac%e4%bb%b6%e7%90%86%e8%a7%a3" onclick="onNavClick(`#线程层次结合gpu存储层次加深对代码操作的硬件理解-nav`)" id="线程层次结合gpu存储层次加深对代码操作的硬件理解-nav">
									线程层次结合gpu存储层次加深对代码操作的硬件理解
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e5%86%85%e5%ad%98%e4%bc%a0%e8%be%93" onclick="onNavClick(`#cuda内存传输-nav`)" id="cuda内存传输-nav">
									CUDA内存传输
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e7%9b%b8%e4%b9%98" onclick="onNavClick(`#矩阵相乘-nav`)" id="矩阵相乘-nav">
									矩阵相乘
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b2" onclick="onNavClick(`#cuda编程2-nav`)" id="cuda编程2-nav">
									CUDA编程（2）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%86%85%e7%bd%ae%e7%b1%bb%e5%9e%8b%e5%92%8c%e5%87%bd%e6%95%b0" onclick="onNavClick(`#内置类型和函数-nav`)" id="内置类型和函数-nav">
									内置类型和函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e5%90%8c%e6%ad%a5" onclick="onNavClick(`#线程同步-nav`)" id="线程同步-nav">
									线程同步
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e8%b0%83%e5%ba%a6" onclick="onNavClick(`#线程调度-nav`)" id="线程调度-nav">
									线程调度
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#存储模型-nav`)" id="存储模型-nav">
									存储模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b3" onclick="onNavClick(`#cuda编程3-nav`)" id="cuda编程3-nav">
									CUDA编程（3）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95%e9%87%8d%e5%88%86%e6%9e%90" onclick="onNavClick(`#矩阵乘法重分析-nav`)" id="矩阵乘法重分析-nav">
									矩阵乘法重分析
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%8e%9f%e5%ad%90%e5%87%bd%e6%95%b0" onclick="onNavClick(`#原子函数-nav`)" id="原子函数-nav">
									原子函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%a8%8b%e5%ba%8f%e5%9f%ba%e6%9c%ac%e4%bc%98%e5%8c%96" onclick="onNavClick(`#cuda程序基本优化-nav`)" id="cuda程序基本优化-nav">
									CUDA程序基本优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#parallel-reduction%e5%b9%b6%e8%a1%8c%e8%a7%84%e7%ba%a6" onclick="onNavClick(`#parallel-reduction并行规约-nav`)" id="parallel-reduction并行规约-nav">
									Parallel Reduction：并行规约
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#warp%e5%88%86%e5%89%b2" onclick="onNavClick(`#warp分割-nav`)" id="warp分割-nav">
									Warp分割
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%a8%8b%e5%ba%8f%e6%b7%b1%e5%85%a5%e4%bc%98%e5%8c%96" onclick="onNavClick(`#cuda程序深入优化-nav`)" id="cuda程序深入优化-nav">
									CUDA程序深入优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e8%ae%bf%e5%ad%98%e9%80%a0%e6%88%90%e7%9a%84%e5%bb%b6%e8%bf%9f" onclick="onNavClick(`#访存造成的延迟-nav`)" id="访存造成的延迟-nav">
									访存造成的延迟
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#memory-coalescing%e8%ae%bf%e5%ad%98%e5%90%88%e5%b9%b6" onclick="onNavClick(`#memory-coalescing访存合并-nav`)" id="memory-coalescing访存合并-nav">
									Memory Coalescing：访存合并
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bank%e5%86%b2%e7%aa%81" onclick="onNavClick(`#bank冲突-nav`)" id="bank冲突-nav">
									Bank冲突
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e7%9a%84texture%e7%ba%b9%e7%90%86" onclick="onNavClick(`#cuda的texture纹理-nav`)" id="cuda的texture纹理-nav">
									CUDA的Texture纹理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#sm%e8%b5%84%e6%ba%90%e5%8a%a8%e6%80%81%e5%88%86%e5%89%b2" onclick="onNavClick(`#sm资源动态分割-nav`)" id="sm资源动态分割-nav">
									SM资源动态分割
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%95%b0%e6%8d%ae%e9%a2%84%e8%af%bb" onclick="onNavClick(`#数据预读-nav`)" id="数据预读-nav">
									数据预读
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%8c%87%e4%bb%a4%e6%b7%b7%e5%90%88" onclick="onNavClick(`#指令混合-nav`)" id="指令混合-nav">
									指令混合
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%be%aa%e7%8e%af%e5%b1%95%e5%bc%80" onclick="onNavClick(`#循环展开-nav`)" id="循环展开-nav">
									循环展开
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e4%b8%ad%e7%a7%91%e5%a4%a7cuda%e7%bc%96%e7%a8%8b" onclick="onNavClick(`#中科大cuda编程-nav`)" id="中科大cuda编程-nav">
									中科大CUDA编程
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cpu%e4%bd%93%e7%b3%bb%e6%9e%b6%e6%9e%84%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#cpu体系架构概述-nav`)" id="cpu体系架构概述-nav">
									CPU体系架构概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%8e%b0%e4%bb%a3cpu%e6%9e%b6%e6%9e%84%e5%92%8c%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96" onclick="onNavClick(`#现代cpu架构和性能优化-nav`)" id="现代cpu架构和性能优化-nav">
									现代CPU架构和性能优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e5%99%a8%e6%9e%b6%e6%9e%84%e5%b1%82%e6%ac%a1" onclick="onNavClick(`#存储器架构层次-nav`)" id="存储器架构层次-nav">
									存储器架构/层次
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%90%91%e9%87%8f%e8%bf%90%e7%ae%97" onclick="onNavClick(`#向量运算-nav`)" id="向量运算-nav">
									向量运算
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e7%ba%a7%e7%9a%84%e5%b9%b6%e8%a1%8c" onclick="onNavClick(`#线程级的并行-nav`)" id="线程级的并行-nav">
									线程级的并行
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cpu%e7%9a%84%e7%93%b6%e9%a2%88" onclick="onNavClick(`#cpu的瓶颈-nav`)" id="cpu的瓶颈-nav">
									CPU的瓶颈
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#并行程序设计概述-nav`)" id="并行程序设计概述-nav">
									并行程序设计概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e6%a8%a1%e5%bc%8f" onclick="onNavClick(`#并行计算模式-nav`)" id="并行计算模式-nav">
									并行计算模式
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e5%99%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#存储器架构-nav`)" id="存储器架构-nav">
									存储器架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%b9%b6%e8%a1%8c%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#并行编程模型-nav`)" id="并行编程模型-nav">
									并行编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e5%bc%80%e5%8f%91%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e5%92%8c%e5%b7%a5%e5%85%b7%e9%85%8d%e7%bd%ae" onclick="onNavClick(`#cuda开发环境搭建和工具配置-nav`)" id="cuda开发环境搭建和工具配置-nav">
									CUDA开发环境搭建和工具配置
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e4%bd%93%e7%b3%bb%e6%9e%b6%e6%9e%84%e6%a6%82%e8%bf%b0" onclick="onNavClick(`#gpu体系架构概述-nav`)" id="gpu体系架构概述-nav">
									GPU体系架构概述
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#gpu%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#gpu架构-nav`)" id="gpu架构-nav">
									GPU架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e7%9a%84%e5%ad%98%e5%82%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#gpu的存储架构-nav`)" id="gpu的存储架构-nav">
									GPU的存储架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cudagpu%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#cudagpu编程模型-nav`)" id="cudagpu编程模型-nav">
									CUDA/GPU编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cpu%e5%92%8cgpu%e4%ba%92%e5%8a%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#cpu和gpu互动模型-nav`)" id="cpu和gpu互动模型-nav">
									CPU和GPU互动模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e7%9a%84%e7%ba%bf%e7%a8%8b%e7%bb%84%e7%bb%87%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#gpu的线程组织模型-nav`)" id="gpu的线程组织模型-nav">
									GPU的线程组织模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpu%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#gpu存储模型-nav`)" id="gpu存储模型-nav">
									GPU存储模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#编程模型-nav`)" id="编程模型-nav">
									编程模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b1" onclick="onNavClick(`#cuda编程1-nav`)" id="cuda编程1-nav">
									CUDA编程（1）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cuda%e6%9c%af%e8%af%ad" onclick="onNavClick(`#cuda术语-nav`)" id="cuda术语-nav">
									CUDA术语
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e7%9a%84%e5%b1%82%e6%ac%a1" onclick="onNavClick(`#线程的层次-nav`)" id="线程的层次-nav">
									线程的层次
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e5%b1%82%e6%ac%a1%e7%bb%93%e5%90%88gpu%e5%ad%98%e5%82%a8%e5%b1%82%e6%ac%a1%e5%8a%a0%e6%b7%b1%e5%af%b9%e4%bb%a3%e7%a0%81%e6%93%8d%e4%bd%9c%e7%9a%84%e7%a1%ac%e4%bb%b6%e7%90%86%e8%a7%a3" onclick="onNavClick(`#线程层次结合gpu存储层次加深对代码操作的硬件理解-nav`)" id="线程层次结合gpu存储层次加深对代码操作的硬件理解-nav">
									线程层次结合gpu存储层次加深对代码操作的硬件理解
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e5%86%85%e5%ad%98%e4%bc%a0%e8%be%93" onclick="onNavClick(`#cuda内存传输-nav`)" id="cuda内存传输-nav">
									CUDA内存传输
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e7%9b%b8%e4%b9%98" onclick="onNavClick(`#矩阵相乘-nav`)" id="矩阵相乘-nav">
									矩阵相乘
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b2" onclick="onNavClick(`#cuda编程2-nav`)" id="cuda编程2-nav">
									CUDA编程（2）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%86%85%e7%bd%ae%e7%b1%bb%e5%9e%8b%e5%92%8c%e5%87%bd%e6%95%b0" onclick="onNavClick(`#内置类型和函数-nav`)" id="内置类型和函数-nav">
									内置类型和函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e5%90%8c%e6%ad%a5" onclick="onNavClick(`#线程同步-nav`)" id="线程同步-nav">
									线程同步
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%ba%bf%e7%a8%8b%e8%b0%83%e5%ba%a6" onclick="onNavClick(`#线程调度-nav`)" id="线程调度-nav">
									线程调度
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9e%8b" onclick="onNavClick(`#存储模型-nav`)" id="存储模型-nav">
									存储模型
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%bc%96%e7%a8%8b3" onclick="onNavClick(`#cuda编程3-nav`)" id="cuda编程3-nav">
									CUDA编程（3）
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95%e9%87%8d%e5%88%86%e6%9e%90" onclick="onNavClick(`#矩阵乘法重分析-nav`)" id="矩阵乘法重分析-nav">
									矩阵乘法重分析
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%8e%9f%e5%ad%90%e5%87%bd%e6%95%b0" onclick="onNavClick(`#原子函数-nav`)" id="原子函数-nav">
									原子函数
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%a8%8b%e5%ba%8f%e5%9f%ba%e6%9c%ac%e4%bc%98%e5%8c%96" onclick="onNavClick(`#cuda程序基本优化-nav`)" id="cuda程序基本优化-nav">
									CUDA程序基本优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#parallel-reduction%e5%b9%b6%e8%a1%8c%e8%a7%84%e7%ba%a6" onclick="onNavClick(`#parallel-reduction并行规约-nav`)" id="parallel-reduction并行规约-nav">
									Parallel Reduction：并行规约
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#warp%e5%88%86%e5%89%b2" onclick="onNavClick(`#warp分割-nav`)" id="warp分割-nav">
									Warp分割
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cuda%e7%a8%8b%e5%ba%8f%e6%b7%b1%e5%85%a5%e4%bc%98%e5%8c%96" onclick="onNavClick(`#cuda程序深入优化-nav`)" id="cuda程序深入优化-nav">
									CUDA程序深入优化
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e8%ae%bf%e5%ad%98%e9%80%a0%e6%88%90%e7%9a%84%e5%bb%b6%e8%bf%9f" onclick="onNavClick(`#访存造成的延迟-nav`)" id="访存造成的延迟-nav">
									访存造成的延迟
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#memory-coalescing%e8%ae%bf%e5%ad%98%e5%90%88%e5%b9%b6" onclick="onNavClick(`#memory-coalescing访存合并-nav`)" id="memory-coalescing访存合并-nav">
									Memory Coalescing：访存合并
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bank%e5%86%b2%e7%aa%81" onclick="onNavClick(`#bank冲突-nav`)" id="bank冲突-nav">
									Bank冲突
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cuda%e7%9a%84texture%e7%ba%b9%e7%90%86" onclick="onNavClick(`#cuda的texture纹理-nav`)" id="cuda的texture纹理-nav">
									CUDA的Texture纹理
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#sm%e8%b5%84%e6%ba%90%e5%8a%a8%e6%80%81%e5%88%86%e5%89%b2" onclick="onNavClick(`#sm资源动态分割-nav`)" id="sm资源动态分割-nav">
									SM资源动态分割
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%95%b0%e6%8d%ae%e9%a2%84%e8%af%bb" onclick="onNavClick(`#数据预读-nav`)" id="数据预读-nav">
									数据预读
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%8c%87%e4%bb%a4%e6%b7%b7%e5%90%88" onclick="onNavClick(`#指令混合-nav`)" id="指令混合-nav">
									指令混合
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%be%aa%e7%8e%af%e5%b1%95%e5%bc%80" onclick="onNavClick(`#循环展开-nav`)" id="循环展开-nav">
									循环展开
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/CUDA_title.jpg')"
                    
                
            >
                <div class="post-title">
                    中科大CUDA教程
                    
                    <div class="post-subtitle">
                        CUDA硬件和逻辑设计，以及部分CUDA编程和优化
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2023-07-19 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[HPC]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/cuda%E7%BC%96%E7%A8%8B">CUDA编程</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            55 min
                            
                            32 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="中科大cuda编程">中科大CUDA编程</h2>
<p>参考资料：</p>
<ul>
<li>CUDA C Programming Guide，中文翻译见<a href="https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese">here</a></li>
<li>CUDA C++ Best Practice Guide</li>
</ul>
<h3 id="cpu体系架构概述">CPU体系架构概述</h3>
<h4 id="现代cpu架构和性能优化">现代CPU架构和性能优化</h4>
<p>CPU是执行指令和处理数据的器件，能完成基本的逻辑和算术指令。</p>
<blockquote>
<p>指令</p>
</blockquote>
<p>Example：</p>
<p>算术：add r3,r4 -&gt; r4</p>
<p>访存：load [r4] -&gt; r7</p>
<p>控制：jz end</p>
<p>对于一个编译好的程序，最优化目标：
$$
\frac{cycle}{instruction}\times \frac{seconds}{cycle}
$$
总结来说，CPI（每条指令的时钟数）&amp; 时钟周期，注意这两个指标并不独立。</p>
<blockquote>
<p>摩尔定律</p>
</blockquote>
<p>芯片的集成密度每两年翻一番，成本下降一半。</p>
<blockquote>
<p>CPU的处理流程</p>
</blockquote>
<p>取址 -&gt; 解码 -&gt; 执行 -&gt; 访存 -&gt; 写回</p>
<blockquote>
<p>流水线</p>
</blockquote>
<p>使用一个洗衣服的例子，单件衣服总时间 = wash（30min）+ dry（40min）+ fold（20min）</p>
<p>那么洗4件衣服需要的总时间 = 30 + 40 + 40 + 40 + 40 + 20 = 210min</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img6.jpg" alt=""></p>
<ul>
<li>流水线使用的是指令级的并行，可以有效地减少时钟周期</li>
<li>增加了延迟和芯片面积（需要更多的存储）</li>
<li>带来了一些问题：具有依赖关系的指令处理，分支如何处理</li>
</ul>
<blockquote>
<p>旁路（Bypassing）</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img38.jpg" alt=""></p>
<p>这里的两条指令具有依赖性，按照原来的方式，需要先计算R7的结果，再进行写回，访寸取到R7的结果。有了旁路这一功能，便可以跳过这个阶段，直接取到R7的结果。</p>
<blockquote>
<p>流水线的停滞</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img39.jpg" alt=""></p>
<p>如果前面的<code>load[R3]</code>没有做完，流水线便会停滞。</p>
<blockquote>
<p>分支</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img40.jpg" alt=""></p>
<p>判断是否做循环<code>jeq loop</code>，我们并不知道是否要执行这个循环，计算机会通过分支预测等工作来进行处理。</p>
<p>具体的分支预测基于过去的分支记录，现代计算机的预测器准确率大于90%。同样它同样会增加芯片面积，增加延迟（预测的开销）。</p>
<blockquote>
<p>分支断定</p>
</blockquote>
<p>与分支预测不相同的是，它不再使用分支预测器，而是将所有分支都做一遍。</p>
<p>好处：不需要复杂的预测器，减少了芯片面积，减少了错误预测，在GPU中使用了分支断定。</p>
<blockquote>
<p>增加CPU一个时钟周期能处理的指令数（IPC）</p>
</blockquote>
<p>超标量——增加流水线的宽度，一个时钟周期处理多条指令。（超标量流水线将每个阶段细分为更小的微操作，并在多个功能单元上同时执行这些微操作。这样，多条指令可以在同一时钟周期内同时执行，从而提高处理器的吞吐量。）</p>
<p><strong>这需要更多的寄存器和存储器带宽。</strong></p>
<blockquote>
<p>指令调度</p>
</blockquote>
<p>考虑以下指令：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">xor</span> <span style="color:#8b008b;font-weight:bold">r1</span>,<span style="color:#8b008b;font-weight:bold">r2</span> -&gt; <span style="color:#8b008b;font-weight:bold">r3</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">add</span> <span style="color:#8b008b;font-weight:bold">r3</span>,<span style="color:#8b008b;font-weight:bold">r4</span> -&gt; <span style="color:#8b008b;font-weight:bold">r4</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">sub</span> <span style="color:#8b008b;font-weight:bold">r5</span>,<span style="color:#8b008b;font-weight:bold">r3</span> -&gt; <span style="color:#8b008b;font-weight:bold">r3</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">addi</span> <span style="color:#8b008b;font-weight:bold">r3</span>,<span style="color:#8b008b;font-weight:bold">1</span> -&gt; <span style="color:#8b008b;font-weight:bold">r1</span> //<span style="color:#8b008b;font-weight:bold">addi代表减法</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>xor</code>和<code>add</code>是相互依赖的（读后写）</li>
<li><code>sub</code>和<code>addi</code>相互依赖（读后写）</li>
<li><code>xor</code>和<code>sub</code>不依赖（写后写）</li>
</ul>
<p>为了让程序运行地更快，可以使用替换寄存器的方法：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">xor</span> <span style="color:#8b008b;font-weight:bold">p1</span>,<span style="color:#8b008b;font-weight:bold">p2</span> -&gt; <span style="color:#8b008b;font-weight:bold">p3</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">add</span> <span style="color:#8b008b;font-weight:bold">p6</span>,<span style="color:#8b008b;font-weight:bold">p4</span> -&gt; <span style="color:#8b008b;font-weight:bold">p7</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">sub</span> <span style="color:#8b008b;font-weight:bold">p5</span>,<span style="color:#8b008b;font-weight:bold">p2</span> -&gt; <span style="color:#8b008b;font-weight:bold">p8</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">addi</span> <span style="color:#8b008b;font-weight:bold">p8</span>,<span style="color:#8b008b;font-weight:bold">1</span> -&gt; <span style="color:#8b008b;font-weight:bold">p9</span> //<span style="color:#8b008b;font-weight:bold">addi代表减法</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><em>这样我们的<code>xor</code>和<code>sub</code>就可以并行执行了。</em></p>
<blockquote>
<p>乱序执行</p>
</blockquote>
<p>将所有的指令重排，使其顺序更合理。</p>
<ul>
<li>重排缓冲区</li>
<li>发射队列/调度器</li>
</ul>
<h4 id="存储器架构层次">存储器架构/层次</h4>
<p><strong>存储器越大越慢。</strong></p>
<blockquote>
<p>缓存</p>
</blockquote>
<p>利用时间临近性和空间临近性，可以使我们的处理变得更快。计算机一般有3级缓存，缓存的大小越来越大。</p>
<h4 id="向量运算">向量运算</h4>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i++) {
</span></span><span style="display:flex;"><span>  	A[i] = B[i] + C[i];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以使用<code>单指令多数据(SIMD)</code>进行加速。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; N; i += <span style="color:#b452cd">4</span>) {
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//并行同时计算	
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	A[i] = B[i] + C[i];
</span></span><span style="display:flex;"><span>  	A[i + <span style="color:#b452cd">1</span>] = B[i + <span style="color:#b452cd">1</span>] + C[i + <span style="color:#b452cd">1</span>];
</span></span><span style="display:flex;"><span>  	A[i + <span style="color:#b452cd">2</span>] = B[i + <span style="color:#b452cd">2</span>] + C[i + <span style="color:#b452cd">2</span>];
</span></span><span style="display:flex;"><span>  	A[i + <span style="color:#b452cd">3</span>] = B[i + <span style="color:#b452cd">3</span>] + C[i + <span style="color:#b452cd">3</span>];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>x86的向量运算</p>
</blockquote>
<ul>
<li>SSE：4宽度浮点和整数指令</li>
<li>AVX：8宽度浮点和整数指令</li>
</ul>
<h4 id="线程级的并行">线程级的并行</h4>
<p>线程的组成：私有的寄存器、程序计数器、栈等。</p>
<p><strong>程序员可以创建和线程，OS和程序员都可以对线程进行调度。</strong></p>
<h4 id="cpu的瓶颈">CPU的瓶颈</h4>
<p>因为功耗墙的存在，处理器的单核性能的提升会越来越少，所以需要多核来支撑。</p>
<blockquote>
<p>新摩尔定律</p>
</blockquote>
<ul>
<li>处理器越来越胖，核越来越多</li>
<li>单核的性能不会大幅提升</li>
</ul>
<p>由此也带来了另外一堵墙，叫<code>存储器墙</code>，处理器的存储器带宽无法满足处理能力的提升。</p>
<h3 id="并行程序设计概述">并行程序设计概述</h3>
<h4 id="并行计算模式">并行计算模式</h4>
<p>并行计算是同时应用多个计算资源解决一个计算问题：</p>
<ul>
<li>涉及多个计算资源或处理器</li>
<li>问题被分解为多个离散的部分，可以同时处理（并行）</li>
<li>每个部分可以由一系列指令完成</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img41.jpg" alt=""></p>
<blockquote>
<p>Flynn矩阵</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">SISD</th>
<th style="text-align:center">SIMD</th>
<th style="text-align:center">MISD</th>
<th style="text-align:center">MIMD</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">单指令单数据</td>
<td style="text-align:center">单指令多数据</td>
<td style="text-align:center">多指令单数据</td>
<td style="text-align:center">多指令多数据</td>
</tr>
</tbody>
</table>
<p><em>在并行计算中，SIMD是一种很常见的方式。</em></p>
<blockquote>
<p>常见名词</p>
</blockquote>
<ul>
<li>Task：任务</li>
<li>Parallel Task：并行任务，该任务可以由多个并行计算的方式解决的<strong>单个任务</strong>。</li>
<li>Serial Execution：串行执行</li>
<li>Parallel Execution：并行执行</li>
<li>Shared Memory：共享存储</li>
<li>Distributed Memory：分布式存储</li>
<li>Communications：通信</li>
<li>Synchronization：同步</li>
<li>Granularity：粒度</li>
<li>Observed Speedup：加速比，对比Baseline，并行计算能获得的性能提升。</li>
<li>Parallel Overhead：并行开销</li>
<li>Scalability：可扩展性</li>
</ul>
<h4 id="存储器架构">存储器架构</h4>
<ul>
<li>共享存储</li>
<li>分布式存储</li>
<li>分布式共享存储</li>
</ul>
<h4 id="并行编程模型">并行编程模型</h4>
<ul>
<li>共享存储模型</li>
<li>线程模型</li>
<li>消息传递模型</li>
<li>数据并行模型</li>
</ul>
<p>具体实例：<code>OpenMP</code>，<code>MPI</code>，<code>Single Program Multiple Data(SPMD)</code>，<code>Multiple Program Multiple Data(MPMD)</code>。</p>
<blockquote>
<p>Amadahl&rsquo;s Law</p>
</blockquote>
<p>Amadahl&rsquo;s Law的程序可能的加速比取决于可以被并行化的部分。
$$
\text{speedup} = \frac{1}{1-p}\
p代表可以被并行化的部分\
\text{speedup} = \frac{1}{\frac{P}{N} + S}\
P代表并行部分，N代表处理器数，S代表串行部分。
$$</p>
<h3 id="cuda开发环境搭建和工具配置">CUDA开发环境搭建和工具配置</h3>
<p>由于该教程是14年的教程，环境配置和如今已经完全不同，这部分将会在我的<a href="https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/">博客</a>上呈现。</p>
<h3 id="gpu体系架构概述">GPU体系架构概述</h3>
<h4 id="gpu架构">GPU架构</h4>
<p>GPU是一个异构的多处理器芯片，为图形图像处理进行优化。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img52.jpg" alt=""></p>
<p><code>Shader core</code>代表渲染器的核心，其组成是一个基本的ALU计算单元。</p>
<p>将GPU的执行单元拎出来，其结构如下：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img53.jpg" alt=""></p>
<p>从上到下分别是<code>地址译码单元</code>、<code>计算核心</code>、<code>执行上下文</code>。</p>
<p>现代的GPU中的ALU都共享指令集，那么为了提高效率，我们一般就通过增大ALU和SIMD来增进并行性，方便向量化的操作。</p>
<p>GTX480的单个架构的SM（流多处理器），一个流多处理器包含32个CUDA核心（CUDA核心本质为一个ALU）：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img54.jpg" alt=""></p>
<p>整个GTX480显卡可以同时承载23000个<code>CUDA片元</code>（也叫CUDA线程）。</p>
<h4 id="gpu的存储架构">GPU的存储架构</h4>
<blockquote>
<p>CPU存储架构</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img55.jpg" alt=""></p>
<blockquote>
<p>GPU的存储架构</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img56.jpg" alt=""></p>
<p>GPU的存储是交给了专门的较大的存储，<code>显存</code>，带宽可以达到150GB/s。<code>访存的带宽资源</code>是非常宝贵的资源！</p>
<blockquote>
<p>看一个带宽测试的例子</p>
</blockquote>
<p>$$
A、B、C为三个矩阵。\
计算 D = A\times B + C
$$</p>
<p>上述计算需要5个步骤：</p>
<p>1.Load input A[i]</p>
<p>2.Load input B[i]</p>
<p>3.Load input C[i]</p>
<p>4.计算A[i] * B[i] + C[i]</p>
<p>5.存储结果到D [i]中</p>
<p>如果这时候的矩阵是非常大的矩阵，那么上述几个步骤，最大的开销则发生在前3步，那么计算的效率是非常低的，这里的瓶颈是带宽。</p>
<p>现代的GPU通过缓存来缓解带宽受限的情况：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img57.jpg" alt=""></p>
<p>总结一下GPU是异构、众核的处理器，针对吞吐优化。</p>
<blockquote>
<p>高效的GPU任务具备的条件</p>
</blockquote>
<ul>
<li>具有成千上万的独立工作
<ul>
<li>尽量利用大量的ALU计算单元</li>
<li>大量的片元（CUDA thread）切换掩藏延迟</li>
</ul>
</li>
<li>可以共享指令流
<ul>
<li>适用于SIMD处理</li>
</ul>
</li>
<li>最好是计算密集的任务
<ul>
<li>通信和计算开销比例合适</li>
<li>不要受制于访存带宽</li>
</ul>
</li>
</ul>
<h3 id="cudagpu编程模型">CUDA/GPU编程模型</h3>
<h4 id="cpu和gpu互动模型">CPU和GPU互动模型</h4>
<blockquote>
<p>cpu和gpu的交互</p>
</blockquote>
<ul>
<li>cpu和gpu有各自的物理内存空间</li>
<li>它们之间通过PCIE总线相连（8G/s～16G/s）</li>
<li>交互的开销较大</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img59.jpg" alt=""></p>
<blockquote>
<p>gpu的存储架构</p>
</blockquote>
<p>![](/Users/caixiongjiang/Library/Application Support/typora-user-images/image-20230721093954435.png)</p>
<blockquote>
<p>访存速度的高低</p>
</blockquote>
<p>从高到低，DRAM代表物理位置在显存中：</p>
<ul>
<li>Register（寄存器）- 延迟约为1个时钟周期</li>
<li>Shared Memory（共享存储）-  延迟约为1个时钟周期</li>
<li>Local Memory（DRAM）- 在每一个私有的线程装配的一个memory，如果寄存器放不下则装入这里，（在物理上放在显存中）速度相对较慢。</li>
<li>Global Memory（DRAM）- 真正的显存，速度相对较慢</li>
<li>Constant Memory（DRAM）- 相对Global和Local更慢</li>
<li>Texture Memory（DRAM）- 相对Global和Local更慢</li>
<li>Instruction Memory（invisible， DRAM）</li>
</ul>
<h4 id="gpu的线程组织模型">GPU的线程组织模型</h4>
<p>GPU的线程模型主要就是<code>网格</code>、<code>块</code>、<code>线程</code>，如下图：</p>
<p>![](/Users/caixiongjiang/Library/Application Support/typora-user-images/image-20230721100425159.png)</p>
<p><em>注意上述示意图为软件逻辑上的组织，并不代表硬件层次。</em></p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img60.jpg" alt=""></p>
<p>WARP代表线程束，是一些线程的组成，一般由32个连续的线程组成。</p>
<p><strong>一个Kernel（通常是在GPU上执行的单个程序）具有大量的线程，这些线程被划分为多个线程块（Blocks），一个Block内部共享<code>Shared Memory</code>，这些Block可以进行同步。</strong></p>
<p><strong>线程和线程块具有唯一的标识。</strong></p>
<h4 id="gpu存储模型">GPU存储模型</h4>
<blockquote>
<p>gpu内存和线程的关系</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img61.jpg" alt=""></p>
<ul>
<li>每个线程有一个私有的<code>Local Memory</code></li>
<li>每个Block有多个线程，它们共享<code>Shared Memory</code></li>
<li>整个设备拥有一个<code>Global Memory</code></li>
<li>主机端的存储器可以跟不同的设备进行交互</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img62.jpg" alt=""></p>
<p>上图代表了GPU端Block内部的访问流程。</p>
<h4 id="编程模型">编程模型</h4>
<p>常规的GPU用于处理图形图像，操作于像素，每个像素的操作都类似，可以应用SIMD（单指令多数据）。</p>
<p>SIMD可以认为是数据并行的分割：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img63.jpg" alt=""></p>
<p>在GPU中，它被称为是SIMT：</p>
<p><strong>通过大量的线程模型获得高度并行，线程切换获得延迟掩藏，多个线程执行相同的指令流，GPU上大量线程承载和调度。</strong></p>
<blockquote>
<p>CUDA编程模式：Extended C</p>
</blockquote>
<ul>
<li>修饰词：global，device，shared，local，constant</li>
<li>关键词：threadIdx，blockIdx</li>
<li>Intrinsics：__syncthreads</li>
<li>运行期API：Memory，symbol，execution，management</li>
<li>函数调用：例子<code>convolve&lt;&lt;&lt;100, 10&gt;&gt;&gt; (参数)</code></li>
</ul>
<blockquote>
<p>CUDA函数声明</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">执行位置</th>
<th style="text-align:center">调用位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>__device__ float DeviceFunc()</td>
<td style="text-align:center">Device</td>
<td style="text-align:center">Device</td>
</tr>
<tr>
<td>__global__ void kernelFunc()</td>
<td style="text-align:center">Device</td>
<td style="text-align:center">Host</td>
</tr>
<tr>
<td>__host__ float HostFunc()</td>
<td style="text-align:center">Host</td>
<td style="text-align:center">Host</td>
</tr>
</tbody>
</table>
<p>几个需要理解的点：</p>
<ul>
<li>入口函数，CPU上调用，GPU上执行</li>
<li>必须返回void</li>
<li>__device__ 和__host__可以同时使用</li>
</ul>
<h3 id="cuda编程1">CUDA编程（1）</h3>
<h4 id="cuda术语">CUDA术语</h4>
<ul>
<li>Host：主机端，通常指cpu</li>
<li>Device：设备端，通常指gpu</li>
<li>Host和Device有各自的存储器</li>
<li>Kernel：数据并行处理函数，也就是所谓的<code>核函数</code>，类似于OpenGL的<code>shader</code></li>
<li>Grid：一维或多维线程块</li>
<li>Block：一组线程</li>
</ul>
<p><strong>一个Grid的的每个Block的线程数都是一样的，Block内部的每个线程可以进行同步，并访问共享存储器。</strong></p>
<h4 id="线程的层次">线程的层次</h4>
<p>一个Block可以是一维，二维，甚至是三维的。（例如，索引数组、矩阵、体）</p>
<ul>
<li>一维Block：Thread ID == Thread Index</li>
<li>二维Block：（Dx，Dy）</li>
</ul>
<p>Thread ID of index(x, y) == x + y Dx</p>
<ul>
<li>三维Block：（Dx，Dy，Dz）</li>
</ul>
<p>Thread ID of index(x, y, z) == x + y Dx + z Dx Dy</p>
<p>看一个代码的例子：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatAdd</span>(<span style="color:#00688b;font-weight:bold">float</span> A[N][N], <span style="color:#00688b;font-weight:bold">float</span> B[N][N],
</span></span><span style="display:flex;"><span>                       <span style="color:#00688b;font-weight:bold">float</span> C[N][N]) 
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> i = threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> j = threadIdx.y;
</span></span><span style="display:flex;"><span>  	C[i][j] = A[i][j] + B[i][j];
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> numBlocks = <span style="color:#b452cd">1</span>;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 对于dim3的类型，如果第三个参数不传，默认为1，这样就变成了一个二维的Block
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	dim3 threadsPerBlock(N, N);
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//第一个参数代表1个 Thread Block，第二个参数代表一个2D的Block（相当于排列的时候变成了行和列）
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>一个线程块里的线程位于相同的处理器核，共享所在核的存储器。</strong></p>
<ul>
<li>块索引：blockIdx</li>
<li>块的线程数：blockDim（一维，二维，三维）</li>
</ul>
<p>使用多个Block进行矩阵的Add：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatAdd</span>(<span style="color:#00688b;font-weight:bold">float</span> A[N][N], <span style="color:#00688b;font-weight:bold">float</span> B[N][N],
</span></span><span style="display:flex;"><span>                       <span style="color:#00688b;font-weight:bold">float</span> C[N][N]) 
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>		<span style="color:#00688b;font-weight:bold">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">if</span> (i &lt; N &amp;&amp; j &lt;&lt; N) {
</span></span><span style="display:flex;"><span>      	C[i][j] = A[i][j] + B[i][j];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> <span style="color:#008b45">main</span>() {
</span></span><span style="display:flex;"><span>  	dim3 threadsPerBlock(<span style="color:#b452cd">16</span>, <span style="color:#b452cd">16</span>);
</span></span><span style="display:flex;"><span>  	dim3 numBlocks(N / threadsPerBlock.x , N / threadsPerBlock.y);
</span></span><span style="display:flex;"><span>  	MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="线程层次结合gpu存储层次加深对代码操作的硬件理解">线程层次结合gpu存储层次加深对代码操作的硬件理解</h4>
<ul>
<li>Device Code：</li>
</ul>
<p>&ndash; 读写每个线程的的寄存器</p>
<p>&ndash; 读写每个线程的local memory</p>
<p>&ndash; 读写每个线程块的shared memory（线程块内线程共享）</p>
<p>&ndash; 读写每个grid的global memory（不同线程块的所有线程共享）</p>
<p>&ndash; 只读每个grid的constant memory（每个grid的步态变化的独立空间）</p>
<ul>
<li>Host Code：</li>
</ul>
<p>&ndash; 主机端只能读写global和constant memory，global memory代表全局的存储器，constant memory代表常量的存储器。</p>
<h4 id="cuda内存传输">CUDA内存传输</h4>
<ul>
<li>cudaMalloc()：在设备端分配global memory</li>
<li>cudaFree()：释放存储空间</li>
</ul>
<p>分配的代码示例：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">float</span> *Md;
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> size = Widch * Width * <span style="color:#8b008b;font-weight:bold">sizeof</span>(<span style="color:#00688b;font-weight:bold">float</span>);
</span></span><span style="display:flex;"><span><span style="color:#228b22">//当前指针是指向设备上的存储空间
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>cudaMalloc((<span style="color:#00688b;font-weight:bold">void</span>**)&amp;Md, size);
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>cudaFree(Md);
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>cudaMemcpy()：内存传输，Host-&gt;Host, Host-&gt;Devicel, Device-&gt;Device, Device-&gt;Host</li>
</ul>
<p>示例程序：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">// Md和Pd都是在device端的地址
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>cudaMemcpy(P, Pd, size, cudaMemcpyDeviceToHost);
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="矩阵相乘">矩阵相乘</h4>
<ul>
<li>CPU实现：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatrixMultOnHost</span>(<span style="color:#00688b;font-weight:bold">float</span> *M, <span style="color:#00688b;font-weight:bold">float</span>* N, flaot *P, <span style="color:#00688b;font-weight:bold">int</span> width) {
</span></span><span style="display:flex;"><span>  <span style="color:#228b22">//i, j分别代表行和列，k代表当前进行计算的第一个矩阵行和第二个矩阵列的位置	
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  <span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> i = <span style="color:#b452cd">0</span>; i &lt; width; i++) {
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> j = <span style="color:#b452cd">0</span>; j &lt; width; j++) {
</span></span><span style="display:flex;"><span>          	<span style="color:#00688b;font-weight:bold">float</span> sum = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>          	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; width; ++k) {
</span></span><span style="display:flex;"><span>              	<span style="color:#00688b;font-weight:bold">float</span> a = M[i * width + k];
</span></span><span style="display:flex;"><span>              	<span style="color:#00688b;font-weight:bold">float</span> b = N[k * width + j];
</span></span><span style="display:flex;"><span>              	sum += a * b;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>          	P[i * width + j] = sum;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>CUDA算法框架，三步走：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">1</span><span style="color:#008b45;font-weight:bold">.分配我们的内存</span><span style="color:#a61717;background-color:#e3d2d2">（</span><span style="color:#8b008b;font-weight:bold">输入的变量和输出的结果等</span><span style="color:#a61717;background-color:#e3d2d2">），</span><span style="color:#8b008b;font-weight:bold">并进行数据传输</span><span style="color:#a61717;background-color:#e3d2d2">（</span><span style="color:#8b008b;font-weight:bold">Host和Device之间</span><span style="color:#a61717;background-color:#e3d2d2">）</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">2</span><span style="color:#008b45;font-weight:bold">.在GPU上进行计算</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">3</span><span style="color:#008b45;font-weight:bold">.进行数据传输</span><span style="color:#a61717;background-color:#e3d2d2">（</span><span style="color:#8b008b;font-weight:bold">结果</span><span style="color:#a61717;background-color:#e3d2d2">），</span><span style="color:#8b008b;font-weight:bold">并释放相应的内存</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>GPU的矩阵相乘的Kernel函数：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatrixMulKernel</span>(<span style="color:#00688b;font-weight:bold">float</span> *Md, <span style="color:#00688b;font-weight:bold">float</span> *Nd, <span style="color:#00688b;font-weight:bold">float</span> *Pd, <span style="color:#00688b;font-weight:bold">int</span> Width) {
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//2D threads
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> tx = threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> ty = threadIdx.y;
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//每一个kernel线程计算一个输出
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">float</span> Pvalue = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; Width; ++k) {
</span></span><span style="display:flex;"><span>      	<span style="color:#00688b;font-weight:bold">float</span> Md_element = Md[tx * Width + k];
</span></span><span style="display:flex;"><span>      	<span style="color:#00688b;font-weight:bold">float</span> Nd_element = Nd[k * Width + ty];
</span></span><span style="display:flex;"><span>      	Pvalue += Md_element + Nd_element;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//写入结果矩阵
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	P[tx * Width + ty] = Pvalue;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>上述矩阵相乘的样例特点：</p>
<p>1.每个线程计算结果矩阵<code>Pd</code>的一个元素。</p>
<p>2.每个线程需要读入矩阵<code>Md</code>的一行，读入矩阵<code>Nd</code>的一列，并为每对元素执行一次乘法和加法。（访存的次数和计算的次数基本接近1:1）</p>
<p>3.矩阵的长度受限于一个线程块允许的线程数目。</p>
<blockquote>
<p>思考：在算法实现中最主要的性能问题是什么？</p>
</blockquote>
<p>主要的性能问题其实存在于访问存储的开销，所以算法的速度主要取决于访存的带宽（从Global Memory读数据的速度）。</p>
<h3 id="cuda编程2">CUDA编程（2）</h3>
<h4 id="内置类型和函数">内置类型和函数</h4>
<ul>
<li>__global__：主机上调用，设备上执行。返回类型必须是<code>void</code>。</li>
<li>__device__：在设备上调用，在设备上执行。</li>
<li>__host__：在主机上调用，在主机上执行。</li>
</ul>
<blockquote>
<p>Global和device函数</p>
</blockquote>
<ol>
<li>
<p>尽量少用递归</p>
</li>
<li>
<p>不要使用静态变量</p>
</li>
<li>
<p>少用malloc</p>
</li>
<li>
<p>小心通过指针实现的函数调用</p>
</li>
</ol>
<blockquote>
<p>CUDA内置的向量的数据类型</p>
</blockquote>
<ul>
<li>Example：</li>
</ul>
<ol>
<li>char[1~4]，uchar[1~4]</li>
<li>short[1~4]，ushort[1~4]</li>
<li>int[1~4]，uint[1~4]</li>
<li>long[1~4]，ulong[1~4]</li>
<li>longlong[1~4]，ulonglong[1~4]</li>
<li>float[1~4]</li>
<li>double1，double2</li>
</ol>
<ul>
<li>同时适用于host和device的代码，通过函数<code>make_&lt;type name&gt;构造</code>:</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>int2 i2 = make_int2(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>); 
</span></span><span style="display:flex;"><span>float4 f4 = make_float4(<span style="color:#b452cd">1.0f</span>, <span style="color:#b452cd">2.0f</span>, <span style="color:#b452cd">3.0f</span>, <span style="color:#b452cd">4.0f</span>);
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>通过<code>.x</code>，<code>.y</code>，<code>.z</code>和<code>.w</code>来访问：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>int2 i2 = make_int2(<span style="color:#b452cd">1</span>, <span style="color:#b452cd">2</span>);
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> x = i2.x;
</span></span><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">int</span> y = i2.y;
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>常用的数学函数</p>
</blockquote>
<ul>
<li>开根号函数：<code>sqrt</code>、<code>rsqrt</code></li>
<li>指数函数：<code>Exp</code>、<code>log</code></li>
<li>三角函数：<code>sin</code>、<code>cos</code>、<code>tan</code>、<code>sincos</code></li>
<li>进/舍位函数：<code>trunc</code>，<code>ceil</code>，<code>floor</code></li>
</ul>
<p><strong>cuda中还提供了一些内建的数学函数，比上面这些函数速度更快，但精度要低一些，适合于那种对精度要求不高，但运算速度要求比较高的场合</strong>，这些函数都以双下划线<code>__</code>开头：<code>__expf</code>、<code>__logf</code>、<code>__sinf</code>、<code>__powf</code>等</p>
<h4 id="线程同步">线程同步</h4>
<blockquote>
<p>块内线程可以同步</p>
</blockquote>
<ul>
<li>调用<code>__syncthreads</code>创建一个barrier栅栏</li>
<li>每个线程在调用点等待块内线程执行到这个地方，然后所有线程继续执行后续指令：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>Mds[i] = Md[j];
</span></span><span style="display:flex;"><span>__syncthreads();
</span></span><span style="display:flex;"><span>func(Mds[i], Mds[i + <span style="color:#b452cd">1</span>]);
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>线程同步带来的问题</p>
</blockquote>
<p>线程同步会带来部分线程的暂停，线程同步可能还会带来更严重的问题,死锁：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">//这里的部分线程执行的时候会在上面那个分支等待，而部分线程在下面等待，永远无法同步，造成死锁
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#8b008b;font-weight:bold">if</span> (someFunc()) {
</span></span><span style="display:flex;"><span>  	__syncthreads();
</span></span><span style="display:flex;"><span>} <span style="color:#8b008b;font-weight:bold">else</span> {
</span></span><span style="display:flex;"><span>  	__syncthreads();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="线程调度">线程调度</h4>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img74.jpg" alt=""></p>
<p>左边是一个的流多处理器（SM）的物理结构，右边为其逻辑结构。</p>
<p>一个绿色的小块为一个流处理器（SP），在这个GPU（古老）中，8个SP组成一个SM。</p>
<blockquote>
<p>Warp：块（Block）内的一组线程</p>
</blockquote>
<ul>
<li>一个Warp有32个线程。</li>
<li>运行于同一个SM，是线程调度的基本单位。</li>
<li>threadIdx值连续。</li>
<li>硬件上保证了一个Warp内的线程是<strong>天然同步</strong>的。</li>
</ul>
<p>一个例子：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scss" data-lang="scss"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">一个SM上</span><span style="color:#a61717;background-color:#e3d2d2">，</span><span style="color:#8b008b;font-weight:bold">有3个Block</span><span style="color:#a61717;background-color:#e3d2d2">，</span><span style="color:#8b008b;font-weight:bold">每一个Block被切分成了若干个warp</span><span style="color:#a61717;background-color:#e3d2d2">：</span><span style="color:#8b008b;font-weight:bold">这时执行程序会根据warp为单位执行上下文切换等操作并进行调度</span><span style="color:#a61717;background-color:#e3d2d2">。</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>在一个硬件上，warp的调度是0开销的！原因是一个warp需要的资源（上下文）在硬件结构上是不变的，只需要进行warp的切换。使用现实生活举例就是一个饭桌是固定的，只需要切换吃饭的那一伙人就OK。</strong></p>
</li>
<li>
<p>在一个SM上，任一时刻只有一个warp在执行</p>
</li>
</ul>
<blockquote>
<p>如果一个warp内的线程沿着不同的分支执行会有什么后果？</p>
</blockquote>
<p>这种情况为<code>divergent warp</code>，在不同的执行分支下，所有的warp的执行顺序是统一的，比如先执行if里面的内容，再执行else的内容。</p>
<blockquote>
<p>假设一个SM中只有8个SP，那么如何给线程分配SP？</p>
</blockquote>
<p>按照构想，其实也就是轮流使用的过程：warp内的32个线程按照8个线程一批的形式轮流使用SP。</p>
<h4 id="存储模型">存储模型</h4>
<blockquote>
<p>寄存器</p>
</blockquote>
<p>每个SM内部的寄存器对线程来说是竞争模型。</p>
<p>假设一个SM内部有8000个寄存器，768个线程，那么每个线程能分配到10个寄存器。超出限制后线程数将因为block的减少而减少。</p>
<pre tabindex="0"><code>Example：每个线程用到了11个寄存器，并且每个block含256个线程，那么一个SM可以驻扎多少个线程，一个SM可以驻扎多少个warp？warp数变少了意味着什么？
</code></pre><p>768/256 = 3， 原本可以分配3个block，但是由于寄存器数量不够用，最多只能分配给512个线程。
那么线程数就会减少到512个，属于2个block，一个SM只能有512/32 = 16个。warp数量的减少意味着效率的降低，剩余的寄存器也会闲置。</p>
<blockquote>
<p>局部存储器（Local Memory）</p>
</blockquote>
<p>**局部存储器是存储于global memory（显存），作用域是每个thread，是线程私有的空间。**一般用于存储自动变量数组，通过常量索引访问，速度较慢。</p>
<blockquote>
<p>共享存储器（Shared Memory）</p>
</blockquote>
<p>其存储层次和cache是同一等级的，用户可进行编程，速度较快。</p>
<blockquote>
<p>全局存储器（Global Memory）</p>
</blockquote>
<p>全局存储器其实就是显存，长延时，可读写。如果是随机访问会非常影响性能，Host主机端可以读写。</p>
<blockquote>
<p>常量存储器（Constant Memory）</p>
</blockquote>
<p>短延时，高带宽，当所有线程访问同一位置时只读。存储于global memory但是有缓存，Host主机端可以读写，经常用于存储常量。</p>
<p>那么如何去声明这些变量呢？</p>
<table>
<thead>
<tr>
<th>变量声明</th>
<th>存储器</th>
<th>作用域</th>
<th>生命期</th>
</tr>
</thead>
<tbody>
<tr>
<td>必须是单独的自动变量</td>
<td>register</td>
<td>thread</td>
<td>kernel</td>
</tr>
<tr>
<td>自动变量数组</td>
<td>local</td>
<td>thread</td>
<td>kernel</td>
</tr>
<tr>
<td>__shared__ int sharedVar;</td>
<td>shared</td>
<td>block</td>
<td>kernel</td>
</tr>
<tr>
<td>__device__ int globalVar;</td>
<td>global</td>
<td>grid</td>
<td>application</td>
</tr>
<tr>
<td>__constant__ int constantVar;</td>
<td>constant</td>
<td>grid</td>
<td>application</td>
</tr>
</tbody>
</table>
<blockquote>
<p>变量的访问</p>
</blockquote>
<ul>
<li>
<p>global和constant变量：</p>
<ul>
<li>
<p>Host可以通过以下函数访问：</p>
<p><code>cudaGetSymbolAddress()</code>：找到要访问变量的地址</p>
<p><code>cudaGetSymbolSize()</code>：得到访问变量的大小</p>
<p><code>cudaMemcpyToSymbol()</code>：将数据从Host内存复制到Device内存中的一个常量符号（Symbol）位置。</p>
<p><code>cudaMemcpyFromSymbol()</code>：将数据从Device内存中的一个常量符号位置复制回到Host内存中</p>
</li>
<li>
<p>Constans变量必须在函数外声明</p>
</li>
</ul>
</li>
</ul>
<h3 id="cuda编程3">CUDA编程（3）</h3>
<h4 id="矩阵乘法重分析">矩阵乘法重分析</h4>
<p>为了去除长度的限制，一般优化的做法就是将Pd矩阵拆成tile小块，把一个tile布置到一个block上，并通过<code>threadIdx</code>和<code>blockIdx</code>索引。</p>
<p>修改后的代码如下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatrixMulKernel</span>(<span style="color:#00688b;font-weight:bold">float</span> *Md, <span style="color:#00688b;font-weight:bold">float</span> *Nd, <span style="color:#00688b;font-weight:bold">float</span> *Pd, <span style="color:#00688b;font-weight:bold">int</span> width) {
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 注意这里的行和列与CUDA中的相反的，不相反也没有关系
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>		<span style="color:#00688b;font-weight:bold">int</span> Row = blockIdx.y * blockDim.y + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> Col = blockIdx.x * blockDim.x + threadIdx.x;
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">float</span> Pvalue = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; Width; ++k) {
</span></span><span style="display:flex;"><span>      	Pvalue += Md[Row * Width + k] * Nd[k * Width + Col];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	Pd[Row * Width + Col] = Pvalue;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>CUDA中的索引和矩阵索引是如何做的？</p>
</blockquote>
<p>对于CUDA的global memory来说，没有二维数组的功能，所以行优先与列优先是无所谓。<strong>所以在GPU的Global级别编程里没有交换循环顺序带来性能提升的说法。但是在CUDA的shared memory中，默认是按照行优先来计算的。所以变换成列优先会有很大的性能提升。</strong></p>
<blockquote>
<p>对于矩阵相乘时，Global memory的访问开销占大部分的时间，如何减少访问带来的消耗？</p>
</blockquote>
<p>其实我们在做矩阵乘法的时候，有很多重复的读取：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img75.jpg" alt=""></p>
<p><em>在两个位置进行计算的时候，读取的是同一列的数据，多了很多重复读取。</em></p>
<ul>
<li>解决方法是每个输入元素被Width个线程读取，使用shared memory来减少global memory带宽需求：</li>
</ul>
<p>将Kernel函数拆分成多个阶段，每个阶段使用Md矩阵和Nd矩阵的子集累加Pd矩阵，这样每个阶段都有很好的数据局部性。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img76.jpg" alt=""></p>
<p><em>但由于shared memory的大小是有限的，我们将条块读取也需要分批读取。</em></p>
<p>代码如下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">MatrixMulKernel</span>(<span style="color:#00688b;font-weight:bold">float</span> *Md, <span style="color:#00688b;font-weight:bold">float</span> *Nd, <span style="color:#00688b;font-weight:bold">float</span> *Pd, <span style="color:#00688b;font-weight:bold">int</span> width)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 定义Shared memory存储Md和Nd的子集
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	__shared__ <span style="color:#00688b;font-weight:bold">float</span> Mds[TILE_WIDTH][TILE_WIDTH];
</span></span><span style="display:flex;"><span>  	__shared__ <span style="color:#00688b;font-weight:bold">float</span> Nds[TILE_WIDTH][TILE_WIDTH];
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> bx = blockIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> by = blockIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> tx = threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> ty = threadIdx.y;
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> Row = by * TILE_WIDTH + ty;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> Col = bx * TILE_WIDTH + bx;
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">float</span> Pvalue = <span style="color:#b452cd">0</span>;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 将整个矩阵的运算分成Width / TILE_WIDTH 个阶段进行 
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> m = <span style="color:#b452cd">0</span>; m &lt; Width / TILE_WIDTH; ++m) {
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 从Md和Nd中各取一个元素存入shared memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	<span style="color:#228b22">// 从二维的角度来说为Md[Row][m * TILE_WIDTH + tx]，取第一个矩阵小块的行
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	<span style="color:#228b22">// 从二维的角度来说为Nd[m * TILE_WIDTH + ty][Col]，取第二个矩阵小块的列
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	Mds[ty][tx] = Md[Row * Width + (m * TILE_WIDTH + tx)];
</span></span><span style="display:flex;"><span>      	Nds[ty][tx] = Nd[Col + (m * TILE_WIDTH + ty) * Width];
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 等待所有block内的线程同步后才能进行乘累加
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	__synchthreads();
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 每一个TILE_WIDTH子集做乘累加
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; TILE_WIDTH; ++k) {
</span></span><span style="display:flex;"><span>          	Pvalue += Mds[ty][k] + Nds[k][tx];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 防止上次的乘累加还没有完成，下一次从Global -&gt; shared过程的元素对乘累加的结果造成影响
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	__synchthreads();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  	Pd[Row * Width + Col] = Pvalue;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>上述程序整体的流程：</p>
<ol>
<li>计算结果矩阵Pd中元素的row和col来确定要取Md的哪一行，哪一列。</li>
<li>根据行列将其分为一个个小块，分别把小块放入Shared Memory</li>
<li>在Shared Memory进行计算</li>
<li>这里的同步体现在每一个小块上的读取是可以并行的，为O(1)。而且可以有效减少对global memory的访问次数</li>
</ol>
<blockquote>
<p>那么如何选取TILE_WIDTH的数值</p>
</blockquote>
<p>一个块内的线程数是有上限的，TILE_WIDTH的数目不要大于BLock内部的线程数，同时Shared Memory大小是有极限的。更大的TILE_WIDTH将导致更少的Block数。</p>
<p>原理如图所示：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img77.jpg" alt=""></p>
<h4 id="原子函数">原子函数</h4>
<p>CUDA中的原子操作本质上是让线程在某个内存单元完成读-修改-写的过程中不被其他线程打扰，它是一个独占的过程。</p>
<p>举个例子来说：我有很多线程，每个线程计算出了一个结果, 我需要把所有的结果加在一起，就必须使用原子操作，不然就会发生错误。因为可能会发生一个线程正在读，另一个线程正在写的过程。所以就需要一个原子加的操作过程，如下图：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img78.jpg" alt=""></p>
<ul>
<li>算术运算：<code>atomicAdd()</code>,<code>atomicSub()</code>,<code>atomicExch()</code>,<code>atomicExch()</code>,<code>atomicMin()</code>,<code>atomicMax()</code>,<code>atomicDec()</code>,<code>atomicCAS()</code></li>
<li>位运算：<code>atomicAnd()</code>,<code>atomicOr</code>,<code>atomicXor()</code></li>
</ul>
<p>这些原子函数具体的作用可以参考<a href="https://zhuanlan.zhihu.com/p/552049508">CUDA原子操作详解及其适用场景 - 知乎 (zhihu.com)</a>
原子操作是比较耗时的，需要进入一个排队机制，尽量少用。</p>
<h3 id="cuda程序基本优化">CUDA程序基本优化</h3>
<p><code>有效的数据并行算法</code> + <code>针对GPU架构特性的优化</code> = <code>最优性能</code></p>
<h4 id="parallel-reduction并行规约">Parallel Reduction：并行规约</h4>
<p>下面是一个并行规约的过程：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img79.jpg" alt=""></p>
<p><em>也就是每两个数进行一次合并！</em></p>
<p>GPU程序如下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">parallel_reduction</span>() {
</span></span><span style="display:flex;"><span>  	__shared__ <span style="color:#00688b;font-weight:bold">float</span> *partialSum;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// Load into shared memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> t = threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> stride = <span style="color:#b452cd">1</span>; stride &lt; blockDim.x; stride *= <span style="color:#b452cd">2</span>) {
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 同步是为了每一层的规约做完了之后才能做下一层
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	__syncthreads();
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">if</span> (t % (<span style="color:#b452cd">2</span> * stride) == <span style="color:#b452cd">0</span>) {
</span></span><span style="display:flex;"><span>          	partialSum[t] += partialSum[t + stride];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>以8个数为例，每次我们启动8个线程读取，在做加法时，实际上工作的线程只有4个线程，由于同步的需求，多余的线程就闲置了。</p>
<p>也就是说n个元素实际上只需要n/2个线程，也就是说每轮所需要的线程数都减半！</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img80.jpg" alt=""></p>
<p>按照上图的方式，我们可以通过改变索引来实现这个需求，那么我们stride的顺序从<code>1，2，4</code>变为了<code>4，2，1</code>：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">parallel_reduction</span>() {
</span></span><span style="display:flex;"><span>  	__shared__ <span style="color:#00688b;font-weight:bold">float</span> *partialSum;
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// Load into shared memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> t = threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> stride = blockDim.x / <span style="color:#b452cd">2</span>; stride &gt; <span style="color:#b452cd">0</span>; stride /= <span style="color:#b452cd">2</span>) {
</span></span><span style="display:flex;"><span>      	<span style="color:#228b22">// 同步是为了每一层的规约做完了之后才能做下一层
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>      	__syncthreads();
</span></span><span style="display:flex;"><span>      	<span style="color:#8b008b;font-weight:bold">if</span> (t &lt; stride) {
</span></span><span style="display:flex;"><span>          	partialSum[t] += partialSum[t + stride];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>![](/Users/caixiongjiang/Library/Application Support/typora-user-images/image-20230805171617104.png)</p>
<p><strong>因为线程进行计算的方式进行了改变，因为warp是线程调度的基本单位，这样的排列方式可以让更多闲置的线程可以提前释放资源。</strong></p>
<h4 id="warp分割">Warp分割</h4>
<blockquote>
<p>线程块内如何划分warp</p>
</blockquote>
<p>通晓warp分割有助于减少分支发散，让warp尽早完工。</p>
<ul>
<li>Block被划分为以32个连续的线程组叫一个warp</li>
<li>warp是最基本的调度单位</li>
<li>warp一直执行相同的指令</li>
<li>每个线程只能执行自己的代码路径</li>
<li>设备切换没有时间代价</li>
</ul>
<h3 id="cuda程序深入优化">CUDA程序深入优化</h3>
<h4 id="访存造成的延迟">访存造成的延迟</h4>
<blockquote>
<p>CPU-GPU数据传输最小化</p>
</blockquote>
<ul>
<li><code>Host &lt;--&gt; Device</code>的数据传输带宽远低于global momory</li>
<li>减少这种传输的方法：
<ul>
<li>1.中间数据直接在GPU分配，操作，释放</li>
<li>2.部分代码在GPU内部重复计算的开销可能比总线（pcie）传输的开销更大</li>
<li>3.如果将CPU代码移植到GPU，但是这个中间传输的过程还在，可能无法提升性能（此时中间传输的开销大于GPU计算的开销）</li>
</ul>
</li>
<li>组团传输
<ul>
<li>大块传输的性能好于小块</li>
</ul>
</li>
<li>内存传输与计算时间重叠
<ul>
<li>双缓存解决</li>
</ul>
</li>
</ul>
<h4 id="memory-coalescing访存合并">Memory Coalescing：访存合并</h4>
<p><strong>这被认为是最重要的影响因子！</strong></p>
<p>GPU的<code>Global memory</code>的带宽虽然很高，但是延时是很高的。</p>
<blockquote>
<p>带宽和延时的理解：</p>
<p>带宽可以比喻为高速公路上的宽度，允许多少数据同时经过；延时可以比喻为在高速公路上开车的速度。</p>
</blockquote>
<p><strong>问题</strong>：给定一个矩阵用<code>行优先</code>的方式存储于<code>global memory</code>，对一个thread来说比较适合的访存模式是什么？</p>
<p>如果满足访问存储合并条件（相邻的线程访问相邻的内存），一个warp的线程访问Global memory的32、64或128位宽数据，结果只需要1或者2次传输。</p>
<p>**Shared Memory **:</p>
<ul>
<li>比global memory快上百倍</li>
<li>可以通过缓存数据减少global memory的访存次数</li>
<li>线程可以通过shared memory协作</li>
<li>用来避免不满足合并条件的访存：
<ul>
<li>读入shared memory重排顺序，从而支持合并寻址。</li>
</ul>
</li>
</ul>
<blockquote>
<p>Shared Memory架构</p>
</blockquote>
<ul>
<li>很多线程访问存储器
<ul>
<li>因此存储器被划分为banks</li>
<li>连续的32-bit访存被分配到连续的banks</li>
</ul>
</li>
<li>每个bank每个周期可以响应一个地址
<ul>
<li>如果有多个bank的话可以同时响应更多的地址申请</li>
</ul>
</li>
<li>对同一个bank进行多个并发访存将导致<strong>bank冲突</strong>
<ul>
<li>冲突的访存必须串行执行</li>
</ul>
</li>
</ul>
<h4 id="bank冲突">Bank冲突</h4>
<p>下面两种是不会发生bank冲突的内存访问方式：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img87.jpg" alt=""></p>
<p>下面两种是容易发生bank冲突的内存访问方式：</p>
<p>![](/Users/caixiongjiang/Library/Application Support/typora-user-images/image-20230811150006601.png)</p>
<p>一般来说，多少路的bank冲突就会导致多少倍的性能下降。</p>
<ul>
<li>通常来说，没有bank冲突shared memory和registers一样快。</li>
<li>warp_serialize profiler分析器的可以反映冲突</li>
<li>快速情况：
<ul>
<li>half-warp内所有线程访问不同的banks，没有冲突</li>
<li>half-warp内所有线程读取<strong>同一地址</strong>，没有冲突（广播）</li>
</ul>
</li>
<li>慢速情况：
<ul>
<li>Bank Conflict：half-warp内多个线程访问<strong>同一个bank</strong></li>
<li>访存必须串行化</li>
<li>代价 = 多个线程同时访问同一个bank的线程数的最大值</li>
</ul>
</li>
</ul>
<blockquote>
<p>举例：Transpose 矩阵转置</p>
</blockquote>
<ul>
<li>每个线程块在矩阵的一个warp上操作</li>
<li>原始版本存在对global memory按步长访问的情况</li>
</ul>
<p>原始矩阵转置：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">transposeNaive</span>(<span style="color:#00688b;font-weight:bold">float</span> *odata, <span style="color:#00688b;font-weight:bold">float</span> *idata, <span style="color:#00688b;font-weight:bold">int</span> width, <span style="color:#00688b;font-weight:bold">int</span> height)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> xIndex = blockIdx.x * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> yIndex = blockIdx.y * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> index_in = xIndex + width * yIndex; <span style="color:#228b22">// [xIndex, yIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> index_out = yIndex + width * xIndex; <span style="color:#228b22">// [yIndex, xIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>
</span></span><span style="display:flex;"><span>  	odata[index_out] = idata[index_in];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>通过shared memory实现合并</p>
<ul>
<li>先将warp的多列元素存入shared memory，再以连续化的数据写入global memory</li>
<li>需要同步__syncthreads()，因为线程需要用到其他线程存储到<code>shared memory</code>的数据。</li>
</ul>
<p>代码如下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c++" data-lang="c++"><span style="display:flex;"><span>__global__ <span style="color:#00688b;font-weight:bold">void</span> <span style="color:#008b45">transposeCoalesced</span>(<span style="color:#00688b;font-weight:bold">float</span> *odata, <span style="color:#00688b;font-weight:bold">float</span> *idata, <span style="color:#00688b;font-weight:bold">int</span> width, <span style="color:#00688b;font-weight:bold">int</span> height)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	__shared__ <span style="color:#00688b;font-weight:bold">float</span> tile[TILE_DIM][TILE_DIM];
</span></span><span style="display:flex;"><span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 计算原矩阵的坐标 
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#00688b;font-weight:bold">int</span> xIndex = blockIdx.x * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> yIndex = blockIdx.y * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> index_in = xIndex * width + yIndex; <span style="color:#228b22">// 行元素：[xIndex, yIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 计算转置矩阵的坐标	
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	xIndex = blockIdx.y * TILE_DIM + threadIdx.y;
</span></span><span style="display:flex;"><span>  	yIndex = blockIdx.x * TILE_DIM + threadIdx.x;
</span></span><span style="display:flex;"><span>  	<span style="color:#00688b;font-weight:bold">int</span> index_out = xIndex + yIndex * height; <span style="color:#228b22">// 列元素：[xIndex, yIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">//读入shared memory [y, x] = [xIndex, yIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	tile[threadIdx.y][threadIdx.x] = idata[index_in];
</span></span><span style="display:flex;"><span>  	__syncthreads(); <span style="color:#228b22">// 同步
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// [yIndex, xIndex] = [x, y]:[xIndex, yIndex]
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	odata[index_out] = tile[threadIdx.x][threadIdx.y];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>现在还存在一个问题：</p>
<ul>
<li>warp内的16$\times$16个floats存在于shared memory：
<ul>
<li>列中的数据存于相同的bank</li>
<li>读入warp &ndash; 列数据存在16路的bank conflict</li>
</ul>
</li>
<li>解决方案 &ndash; 填充shared memory数组
<ul>
<li><code>__shared__ float tile[TILE_DIM][TILE_DIM + 1]</code></li>
<li>反对角线上的数据存于相同的bank</li>
</ul>
</li>
</ul>
<p>使用Padding避免存储体冲突（填充数组），见下图：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img88.jpg" alt=""></p>
<p>原来假设为4个bank，现在填充数组的时候多填充一位，但由于bank是按顺序读取，那么棕色的部分就会占位，但不会产生作用。所以Bank读取时不会产生冲突。</p>
<h4 id="cuda的texture纹理">CUDA的Texture纹理</h4>
<p>Texture是读入数据的一个对象。</p>
<p>优点：</p>
<ul>
<li>数据被缓存：特别适用于无法合并访存的场合</li>
<li>支持过滤：线性、双线性、三线性 插值</li>
<li>Wrap模式（针对越界寻址）：裁剪到边缘或重复</li>
<li>一维、二维、三维寻址：以整数或归一化小数做为坐标</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img89.jpg" alt=""></p>
<p>Texture代码请查看《CUDA c program》</p>
<blockquote>
<p>GPU硬件在数据的并行计算问题上，怎样可以达到很好的性能？</p>
</blockquote>
<ul>
<li>有效利用并行性</li>
<li>尽可能合并内存访问</li>
<li>利用shared memory</li>
<li>开发其他可存储空间（Texture、Constant）</li>
<li>减少bank冲突</li>
</ul>
<h4 id="sm资源动态分割">SM资源动态分割</h4>
<p>SM资源分配使用木桶原理。谁的资源先达到瓶颈则减少该部分资源的分配。</p>
<p>例子：</p>
<p>假设我们有768个线程（3个block），每个线程用10个寄存器。然而寄存器的大小最多只支持10个寄存器，如果此时每个线程分配11个寄存器，那么可使用的寄存器数量不够，则会自动减少block数量，变为512个线程（2个block），每个线程使用的11个寄存器，剩余的线程就会变为空闲状态。</p>
<h4 id="数据预读">数据预读</h4>
<p>在一次global memory读操作和实际用到这个数据的语句中间，插入独立于以上数据的指令，可以隐藏访问延迟(并行)。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#00688b;font-weight:bold">float</span> m = Md[i]; <span style="color:#228b22">//Read global memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#00688b;font-weight:bold">float</span> f = a * b  + c * d; <span style="color:#228b22">//执行指令，不依赖读内存的操作。该语句可以被隐藏延迟。
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#00688b;font-weight:bold">float</span> f2 = m * f;
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>引入预读操作的瓦片化matrix multiply</p>
</blockquote>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#228b22">// Load first tile into registers
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span><span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#228b22">/*...*/</span>)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// 将寄存器的内容读取到shared memory
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	__syncthreads();
</span></span><span style="display:flex;"><span>  	<span style="color:#228b22">// Load下一个tile到寄存器
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	<span style="color:#228b22">// 执行乘累加操作
</span></span></span><span style="display:flex;"><span><span style="color:#228b22"></span>  	__syncthreads();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="指令混合">指令混合</h4>
<p>计算密集型任务很容易受限于带宽，典型的情况就是在存储器和执行配置优化完成后，考虑指令优化。</p>
<p>比如：</p>
<p>除以2^n，采用<code>&gt;&gt;n</code></p>
<p>以2^n求模，采用<code>&amp;(2^n - 1)</code></p>
<p>避免double到float的类型自动转换</p>
<h4 id="循环展开">循环展开</h4>
<p>example:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; BLOCK_SIZE; ++k) 
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	Pvalue += Ms[ty][k] * Ns[k][tx];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>虽然这条语句只是单纯的循环计算，但是系统需要做很多额外的操作。</p>
<p>改成：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>Pvalue += Ms[ty][<span style="color:#b452cd">0</span>] * Ns[<span style="color:#b452cd">0</span>][tx] + 
</span></span><span style="display:flex;"><span>  				Ms[ty][<span style="color:#b452cd">1</span>] * Ns[<span style="color:#b452cd">1</span>][tx] + 
</span></span><span style="display:flex;"><span>  				...
</span></span><span style="display:flex;"><span>  				Ms[ty][<span style="color:#b452cd">15</span>] * Ns[<span style="color:#b452cd">15</span>][tx]; <span style="color:#228b22">// BLOCK_SIZE = 16
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>去掉循环的好处：不再有循环计数器更新，不再有分支，常量索引（不再有地址运算）。</p>
<p>编译自动实现：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#1e889b">#pragma unroll BLOCK_SIZE
</span></span></span><span style="display:flex;"><span><span style="color:#1e889b"></span><span style="color:#8b008b;font-weight:bold">for</span> (<span style="color:#00688b;font-weight:bold">int</span> k = <span style="color:#b452cd">0</span>; k &lt; BLOCK_SIZE; ++k) 
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  	Pvalue += Ms[ty][k] * Ns[k][tx];
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></td></tr></table>
</div>
</div><p>缺点：可扩展性不强</p>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2023-08-08</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://caixiongjiang.github.io/blog/2023/hpc/cuda%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/">
			下回<br>CUDA编程实战
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/">
			上回<br>Ubuntu CUDA编程环境配置
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
