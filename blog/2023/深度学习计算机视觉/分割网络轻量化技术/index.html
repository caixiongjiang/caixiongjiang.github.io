<!DOCTYPE html>
<html><head>
<title>分割网络模型轻量化技术</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="分割网络的参数量往往比分类和检测网络大得多，为了让分割网络在实际中应用，需要对复杂的网络模型进行压缩量化。">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="分割网络模型轻量化技术" />
<meta property="og:description" content="分割网络的参数量往往比分类和检测网络大得多，为了让分割网络在实际中应用，需要对复杂的网络模型进行压缩量化。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E8%BD%BB%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2023-03-20T18:18:05+08:00" />
<meta property="article:modified_time" content="2023-03-21T09:19:06+08:00" />












<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="https://jarson-cai.gitee.io/jarson-cai-blog">
    MiFeng
</a>
<br>

<a href="nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b%e9%87%8f%e5%8c%96%e6%8a%80%e6%9c%af" onclick="onNavClick(`#分割模型量化技术-nav`)" id="分割模型量化技术-nav">
									分割模型量化技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%8f%90%e9%ab%98%e7%bd%91%e7%bb%9c%e6%8e%a8%e7%90%86%e6%95%88%e7%8e%87%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%8a%80%e6%9c%af" onclick="onNavClick(`#提高网络推理效率的基本技术-nav`)" id="提高网络推理效率的基本技术-nav">
									提高网络推理效率的基本技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e9%87%87%e6%a0%b7%e6%8a%80%e6%9c%af" onclick="onNavClick(`#采样技术-nav`)" id="采样技术-nav">
									采样技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%ab%98%e6%95%88%e5%8d%b7%e7%a7%af%e6%8a%80%e6%9c%af" onclick="onNavClick(`#高效卷积技术-nav`)" id="高效卷积技术-nav">
									高效卷积技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e8%b7%b3%e8%bf%87%e8%bf%9e%e6%8e%a5" onclick="onNavClick(`#残差连接跳过连接-nav`)" id="残差连接跳过连接-nav">
									残差连接/跳过连接
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%bd%bb%e9%87%8f%e5%8c%96%e9%aa%a8%e5%b9%b2%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#轻量化骨干网络-nav`)" id="轻量化骨干网络-nav">
									轻量化骨干网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e8%bd%bb%e9%87%8f%e5%8c%96%e5%ae%9e%e6%97%b6%e5%88%86%e5%89%b2%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#轻量化实时分割网络-nav`)" id="轻量化实时分割网络-nav">
									轻量化实时分割网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%bc%96%e7%a0%81%e5%99%a8%e5%92%8c%e8%a7%a3%e7%a0%81%e5%99%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#编码器和解码器架构-nav`)" id="编码器和解码器架构-nav">
									编码器和解码器架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e5%88%86%e6%94%af%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#多分支架构-nav`)" id="多分支架构-nav">
									多分支架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%85%83%e5%ad%a6%e4%b9%a0%e6%8a%80%e6%9c%af" onclick="onNavClick(`#元学习技术-nav`)" id="元学习技术-nav">
									“元学习”技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bf%ab%e9%80%9f%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" onclick="onNavClick(`#快速注意力机制-nav`)" id="快速注意力机制-nav">
									快速注意力机制
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f" onclick="onNavClick(`#知识蒸馏-nav`)" id="知识蒸馏-nav">
									知识蒸馏
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e5%93%8d%e5%ba%94%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于响应的知识-nav`)" id="基于响应的知识-nav">
									基于响应的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e7%89%b9%e5%be%81%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于特征的知识-nav`)" id="基于特征的知识-nav">
									基于特征的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e5%85%b3%e7%b3%bb%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于关系的知识-nav`)" id="基于关系的知识-nav">
									基于关系的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%92%b8%e9%a6%8f%e6%96%b9%e6%b3%95" onclick="onNavClick(`#蒸馏方法-nav`)" id="蒸馏方法-nav">
									蒸馏方法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb" onclick="onNavClick(`#知识蒸馏论文解读-nav`)" id="知识蒸馏论文解读-nav">
									知识蒸馏论文解读
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%88%86%e5%89%b2%e6%a8%a1%e5%9e%8b%e9%87%8f%e5%8c%96%e6%8a%80%e6%9c%af" onclick="onNavClick(`#分割模型量化技术-nav`)" id="分割模型量化技术-nav">
									分割模型量化技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e6%8f%90%e9%ab%98%e7%bd%91%e7%bb%9c%e6%8e%a8%e7%90%86%e6%95%88%e7%8e%87%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%8a%80%e6%9c%af" onclick="onNavClick(`#提高网络推理效率的基本技术-nav`)" id="提高网络推理效率的基本技术-nav">
									提高网络推理效率的基本技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e9%87%87%e6%a0%b7%e6%8a%80%e6%9c%af" onclick="onNavClick(`#采样技术-nav`)" id="采样技术-nav">
									采样技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e9%ab%98%e6%95%88%e5%8d%b7%e7%a7%af%e6%8a%80%e6%9c%af" onclick="onNavClick(`#高效卷积技术-nav`)" id="高效卷积技术-nav">
									高效卷积技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e8%b7%b3%e8%bf%87%e8%bf%9e%e6%8e%a5" onclick="onNavClick(`#残差连接跳过连接-nav`)" id="残差连接跳过连接-nav">
									残差连接/跳过连接
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%bd%bb%e9%87%8f%e5%8c%96%e9%aa%a8%e5%b9%b2%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#轻量化骨干网络-nav`)" id="轻量化骨干网络-nav">
									轻量化骨干网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e8%bd%bb%e9%87%8f%e5%8c%96%e5%ae%9e%e6%97%b6%e5%88%86%e5%89%b2%e7%bd%91%e7%bb%9c" onclick="onNavClick(`#轻量化实时分割网络-nav`)" id="轻量化实时分割网络-nav">
									轻量化实时分割网络
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e7%bc%96%e7%a0%81%e5%99%a8%e5%92%8c%e8%a7%a3%e7%a0%81%e5%99%a8%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#编码器和解码器架构-nav`)" id="编码器和解码器架构-nav">
									编码器和解码器架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%9a%e5%88%86%e6%94%af%e6%9e%b6%e6%9e%84" onclick="onNavClick(`#多分支架构-nav`)" id="多分支架构-nav">
									多分支架构
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%85%83%e5%ad%a6%e4%b9%a0%e6%8a%80%e6%9c%af" onclick="onNavClick(`#元学习技术-nav`)" id="元学习技术-nav">
									“元学习”技术
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%bf%ab%e9%80%9f%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6" onclick="onNavClick(`#快速注意力机制-nav`)" id="快速注意力机制-nav">
									快速注意力机制
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f" onclick="onNavClick(`#知识蒸馏-nav`)" id="知识蒸馏-nav">
									知识蒸馏
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e5%93%8d%e5%ba%94%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于响应的知识-nav`)" id="基于响应的知识-nav">
									基于响应的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e7%89%b9%e5%be%81%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于特征的知识-nav`)" id="基于特征的知识-nav">
									基于特征的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%9f%ba%e4%ba%8e%e5%85%b3%e7%b3%bb%e7%9a%84%e7%9f%a5%e8%af%86" onclick="onNavClick(`#基于关系的知识-nav`)" id="基于关系的知识-nav">
									基于关系的知识
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e8%92%b8%e9%a6%8f%e6%96%b9%e6%b3%95" onclick="onNavClick(`#蒸馏方法-nav`)" id="蒸馏方法-nav">
									蒸馏方法
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e7%9f%a5%e8%af%86%e8%92%b8%e9%a6%8f%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb" onclick="onNavClick(`#知识蒸馏论文解读-nav`)" id="知识蒸馏论文解读-nav">
									知识蒸馏论文解读
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img_title.jpg')"
                    
                
            >
                <div class="post-title">
                    分割网络模型轻量化技术
                    
                    <div class="post-subtitle">
                        分割网络的参数量往往比分类和检测网络大得多，为了让分割网络在实际中应用，需要对复杂的网络模型进行压缩量化。
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2023-03-20 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[深度学习]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/deep_learning">Deep_learning</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            35 min
                            
                            30 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="分割模型量化技术">分割模型量化技术</h2>
<p><strong>本文主要介绍的内容如下：</strong></p>
<blockquote>
<ul>
<li>提高网络推理效率的基本技术</li>
<li>轻量化实时分割网络常用的架构</li>
<li>知识蒸馏</li>
</ul>
</blockquote>
<p><strong>文中涉及的部分代码全部使用<code>Pytorch框架</code>实现。</strong></p>
<p><strong>本文的大部分内容来自于综述文章</strong>（<a href="https://arxiv.org/pdf/2206.08605.pdf">On Efficient Real-Time Semantic Segmentation: A Survey</a>）</p>
<h3 id="提高网络推理效率的基本技术">提高网络推理效率的基本技术</h3>
<p>本节将从以下几个方面来介绍：</p>
<blockquote>
<ul>
<li>采样技术</li>
<li>高效卷积技术</li>
<li>残差连接/跳过连接</li>
<li>轻量化骨干网络</li>
</ul>
</blockquote>
<h4 id="采样技术">采样技术</h4>
<p>采样技术是减少推理延迟最常用的手段，采样分为上采样和下采样。</p>
<p>下采样可以用来降低图像的分辨率，在大型网络中广泛使用，来增加深层卷积核的接受场。通常在网络早期对图像进行下采样可以显著减少网络的推理延迟，在深层网络进行下采样也可以更好地提取高分辨率的细节。</p>
<p>常用的下采样方式有两种，一是使用<code>最大池化层</code>，二是使用<code>步进卷积</code>：</p>
<ul>
<li>最大池化将图像分为若干个池化子区域，在每个区域中取最大的像素值。</li>
<li>步进卷积则通过调整步幅大小来调整图片的大小：
根据输入图像的大小$W\times W$，卷积核的大小$F\times F$，步长$S$，填充的数量$P$来计算输出图像的大小</li>
</ul>
<p>$$W_{out} = \lvert\frac{W - F + 2P}{S}\rvert+1$$</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">nn</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 最大池化层(以下采样2倍为例)</span>
</span></span><span style="display:flex;"><span>maxpooling = nn.MaxPool2d(kernel_size=<span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 步进卷积（以3*3卷积下采样2倍为例）</span>
</span></span><span style="display:flex;"><span>conv_downsample = nn.Conv2d(in_channels, out_channels, kernel_size=<span style="color:#b452cd">3</span>, stride=<span style="color:#b452cd">2</span>, padding=<span style="color:#b452cd">0</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>上采样的主要目的是为了重建输入分辨率的图像，上采样的方法主要有三种：</p>
<ul>
<li>最近邻插值</li>
<li>双线性插值</li>
<li>转置卷积</li>
</ul>
<p>从上到下计算代价越来越贵，采样效果也越来越好。</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">nn</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 最近邻插值（上采样两倍）  </span>
</span></span><span style="display:flex;"><span>upsample1 = nn.Upsample(scale_factor=<span style="color:#b452cd">2</span>, mode=<span style="color:#cd5555">&#39;nearest&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 双线性插值</span>
</span></span><span style="display:flex;"><span>upsample2 = nn.Upsample(scale_factor=<span style="color:#b452cd">2</span>, mode=<span style="color:#cd5555">&#39;bilinear&#39;</span>, align_corners=<span style="color:#8b008b;font-weight:bold">True</span>) <span style="color:#228b22"># align_corners=True表示保持边缘对齐</span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 转置卷积</span>
</span></span><span style="display:flex;"><span>conv_transpose = nn.ConvTranspose2d(in_channels=<span style="color:#b452cd">3</span>, out_channels=<span style="color:#b452cd">3</span>, 
</span></span><span style="display:flex;"><span>kernel_size=<span style="color:#b452cd">4</span>, stride=<span style="color:#b452cd">2</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">False</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="高效卷积技术">高效卷积技术</h4>
<p>高效卷积技术通常是标准卷积的变体，使得在相同参数量的情况下计算量更小，卷积网络中通常使用的高效卷积有5种：</p>
<ul>
<li>深度可分离卷积</li>
<li>分组卷积</li>
<li>非对称卷积</li>
<li>瓶颈块</li>
<li>空洞/扩张卷积</li>
</ul>
<p><code>深度可分离卷积</code>是由<code>深度卷积</code>和<code>逐点卷积</code>组合而成，逐点卷积也叫$1\times 1$卷积。我们可以使用标准卷积做一个对比来理解。</p>
<blockquote>
<p>标准$3\times 3$卷积</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img73.jpg" alt=""></p>
<blockquote>
<p>深度可分离卷积 = 深度卷积 + $1\times 1$卷积</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img74.jpg" alt=""></p>
<p>分组卷积的原理是将输入和输出通道拆分为g组，输出滤波器仅应用于属于相应组的输入通道，参数量和操作都减少了g倍。分组卷积的一个缺点是组与组之前缺陷信息共享，CVPR 2018 paper（<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.pdf">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a>）通过通道洗牌操作解决了这个问题。</p>
<blockquote>
<p>分组卷积</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img75.jpg" alt=""></p>
<p><code>非对称卷积</code>或叫<code>分解卷积</code>，将$k\times k$卷积重构为$k\times 1$和$1\times k$卷积。</p>
<blockquote>
<p>非对称卷积</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img76.jpg" alt=""></p>
<p><code>瓶颈块</code>最初来自于CVPR 2016 paper（<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">Deep Residual Learning for Image Recognition</a>），在模块的输入使用$1\times 1$卷积来减少特征映射通道的数量，中间使用大尺寸的卷积和大量的特征通道进行计算，在模块的输出又使用$1\times 1$卷积来减少特通道的数量。</p>
<blockquote>
<p>瓶颈块</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img77.jpg" alt=""></p>
<p><code>扩张卷积</code>最初来自于CVPR 2015 paper（<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Papandreou_Modeling_Local_and_2015_CVPR_paper.pdf">Modeling Local and Global Deformations in Deep Learning: Epitomic Convolution</a>），其通过在更大的输入窗口上稀疏应用权重内核，在不增加内核大小的情况下启用更大的接收场，其使用膨胀率d决定稀疏应用的程度。</p>
<blockquote>
<p>扩张卷积</p>
</blockquote>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img78.jpg" alt=""></p>
<p>下表展示了它们的计算量：</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img79.jpg" alt=""></p>
<p>实现代码如下：</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">nn</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">torch.nn.functional</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">F</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">_DSConv</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Depthwise Separable Convolutions
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    深度可分离卷积 = 深度卷积 + 1*1（逐点）卷积
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, dw_channels, out_channels, stride=<span style="color:#b452cd">1</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(_DSConv, self).__init__()
</span></span><span style="display:flex;"><span>        self.conv = nn.Sequential(
</span></span><span style="display:flex;"><span>            nn.Conv2d(dw_channels, dw_channels, <span style="color:#b452cd">3</span>, stride, <span style="color:#b452cd">1</span>, groups=dw_channels, bias=<span style="color:#8b008b;font-weight:bold">False</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(dw_channels),
</span></span><span style="display:flex;"><span>            nn.ReLU(<span style="color:#8b008b;font-weight:bold">True</span>),
</span></span><span style="display:flex;"><span>            nn.Conv2d(dw_channels, out_channels, <span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">False</span>),
</span></span><span style="display:flex;"><span>            nn.BatchNorm2d(out_channels),
</span></span><span style="display:flex;"><span>            nn.ReLU(<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> self.conv(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">GroupConv2d</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Grouped Convolutions
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_channels, out_channels, kernel_size, groups=<span style="color:#b452cd">1</span>, stride=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">True</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(GroupConv2d, self).__init__()
</span></span><span style="display:flex;"><span>        self.groups = groups
</span></span><span style="display:flex;"><span>        self.convs = nn.ModuleList()
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(groups):
</span></span><span style="display:flex;"><span>            self.convs.append(nn.Conv2d(in_channels//groups, out_channels//groups, kernel_size, stride=stride, padding=padding, bias=bias))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 分组</span>
</span></span><span style="display:flex;"><span>        x = torch.split(x, x.size(<span style="color:#b452cd">1</span>)//self.groups, dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 分别卷积</span>
</span></span><span style="display:flex;"><span>        x = [conv(item) <span style="color:#8b008b;font-weight:bold">for</span> conv, item <span style="color:#8b008b">in</span> <span style="color:#658b00">zip</span>(self.convs, x)]
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># 合并输出</span>
</span></span><span style="display:flex;"><span>        x = torch.cat(x, dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">AsymmetricConv2d</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Asymmetric Convolutions
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_channels, out_channels, kernel_size, padding=<span style="color:#b452cd">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(AsymmetricConv2d, self).__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#228b22"># Define the asymmetric kernel</span>
</span></span><span style="display:flex;"><span>        self.padding = padding
</span></span><span style="display:flex;"><span>        self.kernel_size = kernel_size
</span></span><span style="display:flex;"><span>        self.left_kernel_size = (kernel_size, <span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        self.right_kernel_size = (<span style="color:#b452cd">1</span>, kernel_size)
</span></span><span style="display:flex;"><span>        self.conv_left = nn.Conv2d(in_channels, out_channels, self.left_kernel_size, padding=(padding, padding//<span style="color:#b452cd">2</span>))
</span></span><span style="display:flex;"><span>        self.conv_right = nn.Conv2d(in_channels, out_channels, self.right_kernel_size, padding=(padding//<span style="color:#b452cd">2</span>, padding))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        left = self.conv_left(x)
</span></span><span style="display:flex;"><span>        right = self.conv_right(left)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> right
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">BottleneckBlock</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Bottleneck: contain BN and ReLU
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_channels, out_channels, stride=<span style="color:#b452cd">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(BottleneckBlock, self).__init__()
</span></span><span style="display:flex;"><span>        self.conv1 = nn.Conv2d(in_channels, out_channels*<span style="color:#b452cd">2</span>, kernel_size=<span style="color:#b452cd">1</span>, stride=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>        self.bn1 = nn.BatchNorm2d(out_channels*<span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>        self.conv2 = nn.Conv2d(out_channels*<span style="color:#b452cd">2</span>, out_channels*<span style="color:#b452cd">2</span>, kernel_size=<span style="color:#b452cd">3</span>, stride=stride, padding=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>        self.bn2 = nn.BatchNorm2d(out_channels*<span style="color:#b452cd">2</span>)
</span></span><span style="display:flex;"><span>        self.conv3 = nn.Conv2d(out_channels*<span style="color:#b452cd">2</span>, out_channels, kernel_size=<span style="color:#b452cd">1</span>, stride=<span style="color:#b452cd">1</span>, bias=<span style="color:#8b008b;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>        self.bn3 = nn.BatchNorm2d(out_channels)
</span></span><span style="display:flex;"><span>        self.relu = nn.ReLU(inplace=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        out = self.conv1(x)
</span></span><span style="display:flex;"><span>        out = self.bn1(out)
</span></span><span style="display:flex;"><span>        out = self.relu(out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        out = self.conv2(out)
</span></span><span style="display:flex;"><span>        out = self.bn2(out)
</span></span><span style="display:flex;"><span>        out = self.relu(out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        out = self.conv3(out)
</span></span><span style="display:flex;"><span>        out = self.bn3(out)
</span></span><span style="display:flex;"><span>        out = self.relu(out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">DilatedConv</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    Dilated Convolutions
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, in_channels, out_channels, kernel_size, stride=<span style="color:#b452cd">1</span>, padding=<span style="color:#b452cd">0</span>, dilation=<span style="color:#b452cd">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(DilatedConv, self).__init__()
</span></span><span style="display:flex;"><span>        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        out = self.conv(x)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> out
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="残差连接跳过连接">残差连接/跳过连接</h4>
<p>剩余连接和跳过连接允许网络中的数据绕过某些操作，有多种用途。第一种就是改善反向传播期间的梯度流，最典型的是在CVPR 2016 paper（<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">Deep Residual Learning for Image Recognition</a>）提出的残差瓶颈块，使网络的结构能够更深而提高性能；第二种就是对分割网络早期特征的重用，最典型的是在MICCAI 2015 paper（<a href="https://arxiv.org/pdf/1505.04597.pdf%EF%BC%89">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>）提出的skip connection，将早期提取的特征用于上采样阶段的图像重建。</p>
<h4 id="轻量化骨干网络">轻量化骨干网络</h4>
<p>随着CNN的发展，网络的深度越来越大，参数量越来越大，但这在实际的应用中是不现实的。骨干网络是由分类网络去掉分类头实现的，一般用于对大型数据的预训练（ImageNet-1k），本地的分割网络则载入预训练得到的参数，用于加速网络的训练和解决分割数据集不足问题的瓶颈。</p>
<p>常用的CNN轻量化骨干网络有<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf"><code>ResNet系列</code></a>，<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.pdf"><code>Shufflenet系列</code></a>，<code>Mobilenet系列</code>（<a href="https://arxiv.org/pdf/1704.04861.pdf%EF%BC%89">V1</a>,<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf">V2</a>），<a href="http://proceedings.mlr.press/v97/tan19a/tan19a.pdf"><code>EfficientNet系列</code></a>。</p>
<p>但随着近年来transformer的出现，超大型网络超过了传统的CNN网络，同样的也生出了较为轻量的transformer轻量化骨干网络。</p>
<ul>
<li>
<p>CVPR 2022 paper（<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.pdf">MetaFormer is Actually What You Need for Vision</a>）：提出了Poolformer的结构，只使用了池化和通道MLP，抛弃了大型transformer网络中的自注意力结构，一共提供了5个不同大小的骨干网络（<code>S12</code>，<code>S24</code>，<code>S36</code>，<code>M36</code>，<code>M48</code>），注意的是S系列在不同stage输出的通道数都为[64, 128, 320, 512]， M系列在不同stage输出的通道数都为[96, 192, 384, 768]，不同的每个stage的block数量。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img80.jpg" alt=""></p>
</li>
<li>
<p>NeurIPS 2022 paper（<a href="https://arxiv.org/pdf/2206.01191.pdf">EfﬁcientFormer: Vision Transformers at MobileNet Speed</a>）：提出了EfficientFormer的结构，在网络的早期（前2.5个stage）使用了池化和逐点卷积，在网络后期（后1.5个stage）使用传统的自注意力Transformer Block，一共提供了三个不同大小的骨干网络（<code>L1</code>，<code>L2</code>，<code>L3</code>），这里的三个版本在不同的stage的通道数和block数量都不同。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img81.jpg" alt="">
实现了在延迟比较低的情况下，依旧具有较高的分类性能，并且在下游检测任务（COCO2017）和分割任务（ADE20K）上也超过了PoolFormer！
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img82.jpg" alt="">
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img83.jpg" alt=""></p>
</li>
<li>
<p>arxiv preprint 2022年底（估计2023年被某个顶会录用） paper（<a href="https://arxiv.org/pdf/2212.08059.pdf">Rethinking Vision Transformers for MobileNet Size and Speed</a>）同年，该作者又对自己的网络进行了改进提出了EfficientFormerV2，以更小的计算代价达到了先前的分类性能，提供了4个版本（<code>S0</code>，<code>S1</code>，<code>S2</code>，<code>L</code>）。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img84.jpg" alt="">
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img85.jpg" alt=""></p>
</li>
</ul>
<h3 id="轻量化实时分割网络">轻量化实时分割网络</h3>
<p>轻量化分割网络主要有四种架构：</p>
<blockquote>
<ul>
<li>编码器和解码器架构</li>
<li>多分支架构</li>
<li>元学习</li>
<li>快速注意力机制</li>
</ul>
</blockquote>
<h4 id="编码器和解码器架构">编码器和解码器架构</h4>
<ul>
<li>
<p>ECCV 2018 paper（<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Sachin_Mehta_ESPNet_Efficient_Spatial_ECCV_2018_paper.pdf">ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation</a>）：ESPNet提出了高效的金字塔模块，使用$1\times 1$卷积来减少输入维度，然后使用具有不同膨胀率的并行卷积来增加接收场。为了避免因不同膨胀率而导致的网格工件，输出按层次求和，结果串联，最后通过剩余连接添加到输入中。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img86.jpg" alt="">
ESPNet整体结构如下，其整体结构与UNet相似。在网络的早期使用极少滤波器的卷积层下采样，并使用相同尺寸的图像进行拼接，然后通过skip connection来重建分辨率。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img87.jpg" alt=""></p>
</li>
<li>
<p>VCIP 2017 paper（<a href="https://arxiv.org/pdf/1707.03718.pdf%5D">LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation</a>）：LinkNet同样使用标准的编码器和解码器架构，不过参数量相较UNet少了很多，以ResNet-18作为骨干网络。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img98.jpg" alt=""></p>
</li>
<li>
<p>CVPR 2019 paper（<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Orsic_In_Defense_of_Pre-Trained_ImageNet_Architectures_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.pdf">In Defense of Pre-trained ImageNet Architectures for Real-time Semantic Segmentation of Road-driving Images</a>）：首先改文章结合UNet和PSPNet的结构，再通过选取较为轻量的骨干网络以及简化上采样的步骤，组合出了一个基础模型SwiftNetRN-18。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img99.jpg" alt="">
为了增加接收场，该作者取消了金字塔的模块并使用班分辨率的特征提取达到了比金字塔池化模块更好的效果。并证明了小模型在数据量足够的情况下，从头开始训练也能达到预训练的效果。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img100.jpg" alt=""></p>
</li>
<li>
<p>arxiv 2019 paper（<a href="https://arxiv.org/pdf/1902.04502.pdf">Fast-SCNN: Fast Semantic Segmentation Network</a>）：Fast-SCNN网络结构结合了双分支网络和多分辨率输入的两种网络的特点，在特征提取的中间阶段分为两个分支，这样双分支共享特征提取前期的权重。一个分支提取局部信息，另一个分支提取全局特征，最后直接进行双线性插值恢复输入分辨率。注意在特征提取前期使用普通卷积，在通道数较多时使用深度可分离卷积和瓶颈块来减少计算量。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img88.jpg" alt=""></p>
</li>
</ul>
<h4 id="多分支架构">多分支架构</h4>
<ul>
<li>
<p>ECCV 2018 paper（<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdf">ICNet for Real-Time Semantic Segmentation on High-Resolution Images</a>）：ICNet首先通过低分辨率图像首先通过完整的语义感知网络，以获得粗略的预测地图。然后提出了级联特征融合单元和级联标签引导策略，以整合中高分辨率特征，从而逐步细化粗糙的语义图。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img89.jpg" alt="">
从图中可以看出，在图像较小时采用多次卷积并使用较大的深度，大尺寸的图像则则将卷积的stage减少，使用低分辨率监督的结果放入更高的分辨率进行fusion。</p>
</li>
<li>
<p>arxiv 2018 paper（<a href="https://arxiv.org/pdf/1805.04554.pdf">Contextnet: Exploring context and detail for semantic segmentation in real-time</a>）：其提出的ContextNet以两个分支结合为基础，一个分支输入全分辨率，提取空间特征，另一个分支为小分辨率的输入，提取局部特征。其中使用的瓶颈块和深度可分离卷积结构与Fast-SCNN类似，Fast—SCNN也是改进自此网络，将低分辨率的输入直接变为特征提取的低分辨率特征，这样既可以重用特征提取参数，又可以更好提取语义信息。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img106.jpg" alt=""></p>
</li>
</ul>
<h4 id="元学习技术">“元学习”技术</h4>
<p>“元学习”并不是一个专有名词，这里用来泛指所学函数直接影响手头任务所用架构的技术。实时语义分割领域的大多数元学习示例都属于神经架构搜索（NAS）的范畴，这是一种自动化设计神经网络架构过程的方法。</p>
<ul>
<li>arxiv 2020 paper（<a href="https://arxiv.org/pdf/1912.10917.pdf">Fasterseg: Searching for faster real-time semantic segmentation</a>）：FasterSeg使用基于强化学习的神经搜索架构(NAS)，在保持下采样8倍的主干不变的同时，对网络的其余结构进行自动搜索，生成FastSeg模型。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img90.jpg" alt="">
通过最后的网络搜索，形成了一个多分支结合的网络，并且在网络的后期使用了大量的缩放卷积。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img91.jpg" alt=""></li>
</ul>
<h4 id="快速注意力机制">快速注意力机制</h4>
<ul>
<li>IEEE Robotics and Automation Letters（二区） 2021 paper（<a href="https://ieeexplore.ieee.org/ielaam/7083369/9223766/9265219-aam.pdf">Real-time Semantic Segmentation with Fast Attention</a>）：FANet的网络是基于编码器和解码器架构的，其结构相似于UNet，它在skip connection之前加入了一个快速注意力机制，极少量地增加计算量。它使用了ResNet-18和ResNet-34的骨干网络创立了两个版本FANet-18和FANet-34两个版本。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img92.jpg" alt=""></li>
</ul>
<h3 id="知识蒸馏">知识蒸馏</h3>
<p><strong>本节内容主要介绍知识蒸馏的类型，原理，方式，最后会介绍一两种具体的蒸馏方法。</strong></p>
<p><strong>本节内容大部分基于来自于综述文章</strong>（<a href="https://arxiv.org/pdf/2006.05525.pdf">Knowledge Distillation: A Survey</a>）</p>
<p>知识蒸馏最重要的就是知识，这里的知识其实就是数据的目标分布。早期的知识蒸馏技术里，student学习的是teacher的logits（对于分类任务而言，一般将进softmax之前的scores叫做logits，softmax输出的概率分布叫soft labels，当然了，后者也有叫logits的）。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img101.jpg" alt="">
后来为了改善知识蒸馏的效果，各路大佬开始花式开发各种特征用于学习，整体大致可以分为三类，<code>基于响应的知识</code>（response-based knowledge）, <code>基于特征的知识</code>（feature-based knowledge）和<code>基于关系的蒸馏</code>（relation-based knowledge）。</p>
<h4 id="基于响应的知识">基于响应的知识</h4>
<p>响应一般是指教师模型的最后一层的响应，其主要思想是让学生模仿老师的预测。分类任务里最常用的基于响应的知识就是软标签，即softmax输出的概率分布，一般使用<code>KL发散</code>作为损失函数，公式如下：
$$p(z_i, T) = \frac{\text{exp}(z_i/T)}{\sum_{j}\text{exp}(z_j/T)}$$
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img102.jpg" alt=""></p>
<h4 id="基于特征的知识">基于特征的知识</h4>
<p>基于特征的知识其实就是中间层的输出，自从2015年的Fitnets之后，出现了很多花式利用各种中间层特征进行蒸馏的研究。这里重点提一下中间层匹配涉及到的一个层间匹配问题，对于离线蒸馏而言，student可能层数会小一些，如何将teacher的层与student的层进行对应或匹配就是个关键问题。大多数情况下，层间匹配只能靠经验或者实验。另外，中间层的特征维度可能会不匹配，需要根据情况进行投影或者说变换。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img103.jpg" alt=""></p>
<h4 id="基于关系的知识">基于关系的知识</h4>
<p>这种知识一般是指的是图形知识，它表示在任意两个特征图之间的数据内关系，通常使用特征图之间的相似度计算来衡量。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img104.jpg" alt=""></p>
<h4 id="蒸馏方法">蒸馏方法</h4>
<p>知识蒸馏的方法可以分为离线蒸馏，在线蒸馏和自蒸馏三种。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img105.jpg" alt=""></p>
<ul>
<li>
<p>离线蒸馏：从图中可以看出，离线蒸馏的第一步就是选取一个性能表现较好的模型在数据集上预训练。第二步将训练好之后的权值在学生训练阶段载入，并锁定参数，只在特征输出和结果输出上让学生模型学习其数据分布，学生模型出了学习标签提供的数据分布还要学习老师模型处理数据的方法。需要注意的是在学生模型训练的时候，教师模型必须使用验证模式并锁定特征输出部分的权值，防止蒸馏损失函数对教师模型的反向传播。**如果学生模型既要使用骨干网络预训练，又要使用知识蒸馏（特别是特征蒸馏），需要先锁住预训练权重锁住训练一会儿再解开，防止早期过多损失的反向传播破坏了预训练的效果。**由于离线蒸馏比较容易实现，大多数蒸馏都采用这种方式。</p>
</li>
<li>
<p>在线蒸馏：顾名思义，就是学生和老师同时开始从头训练，也可以有额外骨干网络预训练的帮助。但是这种训练方式会带来很多的问题，比如模型大小不一，学生和老师的训练速度不同。又比如学生和老师的模型同时载入，还需要计算特征图之间的关系损失，这会使GPU的内存负担变得非常大。还有可能存在的问题是学生网络和教师网络结构差距较大，学生学习了教师早期的知识，并陷入了一个局部分布变得难以训练。由于这种方式训练难度较大，所以相关的工作比较少。</p>
</li>
<li>
<p>自蒸馏：自蒸馏就是自己又是老师又是学生，这就比较励志了😄。常见的方式就是网络的低层学习高层，后期学习前期等。相当于一个人经历了许多，改掉了以前自己的坏毛病亦或是一个人在后期发现了早期经历了却没有悟出的道理！（自己瞎扯，🐶保命）</p>
</li>
</ul>
<h4 id="知识蒸馏论文解读">知识蒸馏论文解读</h4>
<ul>
<li>
<p>CVPR 2019 paper（<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Knowledge_Adaptation_for_Efficient_Semantic_Segmentation_CVPR_2019_paper.pdf">Knowledge Adaptation for Efficient Semantic Segmentation</a>）：该文提出了一种知识适应的方法，教师网络和学生网络是独立的，蒸馏的位置在两个网络的输出位置。第一步，教师网络通过自动编码器将知识压缩为紧凑的格式来让学生学习。第二步，学生网络通过<code>Feature Adapter</code>来捕获教师网络的远程依赖关系。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img93.jpg" alt=""></p>
</li>
<li>
<p>CVPR 2019 paper（<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Heo_A_Comprehensive_Overhaul_of_Feature_Distillation_ICCV_2019_paper.pdf">A Comprehensive Overhaul of Feature Distillation</a>）：该文使用的是知识蒸馏中的特征蒸馏方法。首先介绍了特征蒸馏的一般范式：根据不同的特征蒸馏方法，改变教师变换T，学生变换S，教师与学生的距离d。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img94.jpg" alt="">
该文设计了与其他论文的不同的教师变换，学生变换，距离函数，以及改变了蒸馏特征的位置。</p>
<ul>
<li>
<p>教师变换：Margin ReLU
$$\sigma_m(x) = \text{max}(x, m)$$
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img95.jpg" alt=""></p>
</li>
<li>
<p>学生变换：$1\times 1$卷积</p>
</li>
<li>
<p>蒸馏的损失函数：将老师与学生的距离作为损失函数，并将<code>partial L2</code>距离函数对教师转换和学生转换做蒸馏。
$$L_{distill}=d_p(\sigma_{m_c}(F_t),r(F_s))$$
$$d_p(T,S)=\sum_i^{W HC}\left{\begin{matrix}0,\quad \text{if}\quad S_i\leqslant T_i \leqslant 0\(T_i-S_i)^2\quad \text{otherwise}\end{matrix}\right.$$</p>
</li>
<li>
<p>特征蒸馏的具体位置：该文认为如果在卷积后面跟着的BN和ReLU之后做特征蒸馏，会损失部分从老师的特征分布带过来的信息。所以他们将进行蒸馏的位置改变到了每个stage的末尾卷积后和ReLU激活函数前。因为使用离线蒸馏，教师模型的参数是最优目标分布，参数是不动的，且载入GPU时使用验证模式，所以Batch Normalization可以忽略。</p>
</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img96.jpg" alt=""></p>
</li>
<li>
<p>CVPR 2019 paper（<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.pdf">Structured Knowledge Distillation for Semantic Segmentation</a>）：本文专门针对语义分割网络提出了解决方案，结合特征蒸馏，输出像素蒸馏，对抗性学习蒸馏组成了一个结构化蒸馏的方法。
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img97.jpg" alt=""></p>
<ul>
<li>基于关系的特征蒸馏：该文章提出了一种计算特征图相似度的<code>Pair-wise loss</code>，首先通过池化来控制特征图输出的大小，然后计算特征图之间的相似度来计算损失。
$$l_{pa}(S)=\frac{1}{(W^{&rsquo;}\times H^{&rsquo;})^2}\sum_{i\varepsilon R}\sum_{j\varepsilon R}(a_{ij}^s-a_{ij}^t)^2$$
其中$a_{ij}$代表两个像素之间的相似性，
$$a_{ij}=f_i^{\top}f_j/(|f_i |_2|f_j |_2 )$$
实现代码如下：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">similarity</span>(feat):
</span></span><span style="display:flex;"><span>feat = feat.float()
</span></span><span style="display:flex;"><span>tmp = L2(feat).detach()
</span></span><span style="display:flex;"><span>feat = feat/tmp
</span></span><span style="display:flex;"><span>feat = feat.reshape(feat.shape[<span style="color:#b452cd">0</span>],feat.shape[<span style="color:#b452cd">1</span>],-<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">return</span> torch.einsum(<span style="color:#cd5555">&#39;icm,icn-&gt;imn&#39;</span>, [feat, feat])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">sim_dis_compute</span>(f_S, f_T):
</span></span><span style="display:flex;"><span>    sim_err = ((similarity(f_T) - similarity(f_S))**<span style="color:#b452cd">2</span>)/((f_T.shape[-<span style="color:#b452cd">1</span>]*f_T.shape[-<span style="color:#b452cd">2</span>])**<span style="color:#b452cd">2</span>)/f_T.shape[<span style="color:#b452cd">0</span>]
</span></span><span style="display:flex;"><span>    sim_dis = sim_err.sum()
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">return</span> sim_dis
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># pairwise feature loss</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">CriterionPairWiseforWholeFeatAfterPool</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, scale, feat_ind):
</span></span><span style="display:flex;"><span>        <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        inter pair-wise loss from inter feature maps
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        scale 代表最大池化层的子区域占原特征图大小的比例。
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        比如2*2的子区域，特诊图大小为56*56，scale就应该等于28/56。
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(CriterionPairWiseforWholeFeatAfterPool, self).__init__()
</span></span><span style="display:flex;"><span>        self.criterion = sim_dis_compute
</span></span><span style="display:flex;"><span>        self.feat_ind = feat_ind
</span></span><span style="display:flex;"><span>        self.scale = scale
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, preds_S, preds_T):
</span></span><span style="display:flex;"><span>        feat_S = preds_S[self.feat_ind]
</span></span><span style="display:flex;"><span>        feat_T = preds_T[self.feat_ind]
</span></span><span style="display:flex;"><span>        feat_T.detach()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        total_w, total_h = feat_T.shape[<span style="color:#b452cd">2</span>], feat_T.shape[<span style="color:#b452cd">3</span>]
</span></span><span style="display:flex;"><span>        patch_w, patch_h = <span style="color:#658b00">int</span>(total_w*self.scale), <span style="color:#658b00">int</span>(total_h*self.scale)
</span></span><span style="display:flex;"><span>        maxpool = nn.MaxPool2d(kernel_size=(patch_w, patch_h), stride=(patch_w, patch_h), padding=<span style="color:#b452cd">0</span>, ceil_mode=<span style="color:#8b008b;font-weight:bold">True</span>) <span style="color:#228b22"># change</span>
</span></span><span style="display:flex;"><span>        loss = self.criterion(maxpool(feat_S), maxpool(feat_T))
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> loss
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>输出像素蒸馏：<code>Pixel-wise Loss</code>借鉴了图像分类任务中使用的软标签的方法，使用教师模型产生的类改成来作为训练学生模型的软目标。
$$l_{pi}(S) = \frac{1}{W^{&rsquo;}\times H^{&rsquo;}}\sum_{i\varepsilon R}\text{KL}(q_i^s|q_i^t)$$
其中$\text{KL}$代表两个概率之间的Kullback-Leibler发散。代码如下：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#228b22"># Pixel loss</span>
</span></span><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">class</span> <span style="color:#008b45;font-weight:bold">CriterionPixelWise</span>(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    reduce参数是计算CE loss每个mini batch的和平均
</span></span></span><span style="display:flex;"><span><span style="color:#cd5555">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> __init__(self, ignore_index=<span style="color:#b452cd">255</span>, use_weight=<span style="color:#8b008b;font-weight:bold">True</span>, reduce=<span style="color:#8b008b;font-weight:bold">True</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#658b00">super</span>(CriterionPixelWise, self).__init__()
</span></span><span style="display:flex;"><span>        self.ignore_index = ignore_index
</span></span><span style="display:flex;"><span>        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=ignore_index, reduce=reduce)
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">if</span> <span style="color:#8b008b">not</span> reduce:
</span></span><span style="display:flex;"><span>            <span style="color:#658b00">print</span>(<span style="color:#cd5555">&#34;disabled the reduce.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">forward</span>(self, preds_S, preds_T):
</span></span><span style="display:flex;"><span>        preds_T.detach()
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">assert</span> preds_S.shape == preds_T.shape,<span style="color:#cd5555">&#39;the output dim of teacher and student differ&#39;</span>
</span></span><span style="display:flex;"><span>        N,C,W,H = preds_S.shape
</span></span><span style="display:flex;"><span>        softmax_pred_T = F.softmax(preds_T.permute(<span style="color:#b452cd">0</span>,<span style="color:#b452cd">2</span>,<span style="color:#b452cd">3</span>,<span style="color:#b452cd">1</span>).contiguous().view(-<span style="color:#b452cd">1</span>,C), dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        logsoftmax = nn.LogSoftmax(dim=<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>        loss = (torch.sum( - softmax_pred_T * logsoftmax(preds_S.permute(<span style="color:#b452cd">0</span>,<span style="color:#b452cd">2</span>,<span style="color:#b452cd">3</span>,<span style="color:#b452cd">1</span>).contiguous().view(-<span style="color:#b452cd">1</span>,C))))/W/H
</span></span><span style="display:flex;"><span>        <span style="color:#8b008b;font-weight:bold">return</span> loss
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对抗性学习蒸馏：<code>Holistic distillation</code>采用条件生成对抗学习来制定整体蒸馏问题。紧凑型网被视为以输入RGB图像I为条件的生成器，而预测的分割图$Q^s$被视为假样本。我们预计$Q^s$与$Q^t$相似，$Q^t$是教师预测的分割图，并尽可能被视为真实样本。<code>Wasserstein distance</code>用于评估真实分布和假分布之间的差异，写成如下:
$$l_{ho}(S,D) = E_{Q^s\sim p_s(Q^s)}[D(Q^s|I)] - E_{Q^t\sim p_t(Q^t)}[D(Q^t|I)]$$
其中$E$是期望运算符，$D$是嵌入网络，作为GAN中的鉴别器，将Q和I一起投影成整体嵌入分数。梯度惩罚满足了利普希茨的要求。</li>
</ul>
</li>
</ul>
<p>所以<strong>结构化蒸馏的损失函数</strong>为：
$$l(S,D) = l_{mc}(S) + \lambda_1(l_{pi}(S) + l_{pa}(S)) - \lambda_2l_{ho}(S,D)$$
其中$pi$代表输出像素损失，$pa$代表成对特征相似度损失，$ho$代表对抗性学习蒸馏损失。总体的训练被分为两步：</p>
<blockquote>
<p>1.训练GAN鉴别器，训练鉴别器等同于最小化$ho$损失，为学生网络的假样本提供低嵌入分数。</p>
</blockquote>
<blockquote>
<p>2.训练紧凑分割网络，最大限度减少与与紧凑分割网络相关的多类交叉熵损失和蒸馏损失。</p>
</blockquote>
<ul>
<li>arxiv 2022 paper（<a href="https://arxiv.org/pdf/2207.05256.pdf">Normalized Feature Distillation for Semantic Segmentation</a>）：该文通过对先前特征蒸馏的方法进行思考，认为虽然对学生和老师的特征不进行转换不能使学生的特征分布与老师相似(下图的b中的Navie代表与没有进行转换的蒸馏中学生模型的特征分布和老师模型特征的CKA相似性)，但认为注意力图，格拉米矩阵和成对相似性等转换方法都是知识损失的，所以他们提出了一种简单的归一化特征蒸馏，具体的特征损失函数如下：
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img107.jpg" alt="">
$$L_{nfd} = D(Norm(F_t), Norm(F_s))$$
其中$Norm$代表归一化，$D$代表$L_2$距离：
$$\hat{F} = \frac{1}{\sigma}(F-u)$$
$u$和$\sigma$分别代表特征的均值和标准差。</li>
</ul>
<p>最后它的总损失表达式如下：
$$L = L_{gt} + \lambda_1L_{kd} + \lambda_2L_{nfd}$$
其中$\lambda_1$设为10和$\lambda_2$设为0.7。</p>
<p>最后在实验结果和消融实验部分，蒸馏的提升到了之前没有的高度，也证明了在（W，H）维度进行归一化蒸馏的效果是最好的。(SKD即是上一篇文章<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.pdf">Structured Knowledge Distillation for Semantic Segmentation</a>)
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img108.jpg" alt="">
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/deep-learning%26computer-vision/img109.jpg" alt=""></p>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2023-03-21</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://caixiongjiang.github.io/blog/2023/%E7%9F%A5%E8%AF%86%E6%9D%82%E8%B0%88/python%E4%B8%AD%E7%9A%84import/">
			下回<br>Python中的import
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/voc%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/">
			上回<br>VOC分割数据集制作
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2023 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
