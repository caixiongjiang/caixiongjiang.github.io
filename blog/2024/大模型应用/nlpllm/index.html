<!DOCTYPE html>
<html><head>
<title>NLP &amp; LLM入门</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="学习大模型的发展历程，主流方法和模型，以及训练方法">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">



<meta property="og:title" content="NLP &amp; LLM入门" />
<meta property="og:description" content="学习大模型的发展历程，主流方法和模型，以及训练方法" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://caixiongjiang.github.io/blog/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/nlpllm/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-01-18T18:18:05+08:00" />
<meta property="article:modified_time" content="2024-01-19T09:19:06+08:00" />
<meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/vllm%E5%B9%B6%E5%8F%91/" /><meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/langchain%E5%85%A5%E9%97%A8/" /><meta property="og:see_also" content="https://caixiongjiang.github.io/blog/2023/llm/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF/" />











<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">
<script src="/vendor/js/vue.min.js" ></script>


  




<link rel="icon" href="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/avater.jfif">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/journal.min.3f72a5fc8f5b5dd732a4b476aced0eece2156958d9d414316494ddb10593ddf7.css" integrity="sha256-P3Kl/I9bXdcypLR2rO0O7OIVaVjZ1BQxZJTdsQWT3fc=" media="screen">



<link rel="stylesheet" href="https://caixiongjiang.github.io/scss/dark-mode.min.c0082f0b082177f6fb3768ff91439a097de49689bd26f4d49f76d94ebb81e02d.css" integrity="sha256-wAgvCwghd/b7N2j/kUOaCX3klom9JvTUn3bZTruB4C0=" media="screen">


<script src="/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>


  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script"
async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style>





  
    <script src="/js/toc.js"></script>
  











<script src="https://cdn.jsdelivr.net/npm/twikoo@1.5.11/dist/twikoo.all.min.js"></script>




</head>
<body>
    	<div id="app"><div ref="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://caixiongjiang.github.io/">
    
        <div class="nav-title">
            🌀Jarson Cai&#39;s Blog
        </div>
        
        <div class="nav-subtitle">
            头脑是日用品，不是装饰品
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
                
            
            
            
            <a class="a-block nav-link-item active" href="/blog">
                文章📖
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                分类📌
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                标签🏷️
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/series">
                系列📚
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/archive">
                归档📃
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                关于👋
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/friends">
                友链🔗
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/index.xml">
                RSS📢
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        
<a href="https://github.com/caixiongjiang">
    GitHub
</a>
<br>

<a href="mailto:nau_cxj@163.com">
    Email
</a>
<br>

<a href="https://leetcode-cn.com/u/cai-xiong-jiang/">
    Leetcode
</a>
<br>

        <hr>
        
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2024 🌀Jarson Cai&#39;s Blog
	
    </div>
    
</div><div ref="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#nlp--llm%e5%85%a5%e9%97%a8" onclick="onNavClick(`#nlp--llm入门-nav`)" id="nlp--llm入门-nav">
									NLP &amp; LLM入门
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#llm%e5%8f%91%e5%b1%95" onclick="onNavClick(`#llm发展-nav`)" id="llm发展-nav">
									LLM发展
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%8f%8c%e5%90%91rnn%e4%b8%ad%e7%9a%84%e6%b3%a8%e6%84%8f%e5%8a%9b" onclick="onNavClick(`#双向rnn中的注意力-nav`)" id="双向rnn中的注意力-nav">
									双向RNN中的注意力
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transformer" onclick="onNavClick(`#transformer-nav`)" id="transformer-nav">
									Transformer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#post-ln-vs-pre-ln-transformer" onclick="onNavClick(`#post-ln-vs-pre-ln-transformer-nav`)" id="post-ln-vs-pre-ln-transformer-nav">
									Post-LN vs Pre-LN Transformer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#nlp%e4%b8%ad%e7%9a%84%e8%ae%ad%e7%bb%83%e8%8c%83%e5%bc%8f" onclick="onNavClick(`#nlp中的训练范式-nav`)" id="nlp中的训练范式-nav">
									NLP中的训练范式
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bert" onclick="onNavClick(`#bert-nav`)" id="bert-nav">
									BERT
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpt-1" onclick="onNavClick(`#gpt-1-nav`)" id="gpt-1-nav">
									GPT-1
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bart" onclick="onNavClick(`#bart-nav`)" id="bart-nav">
									BART
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#llm%e9%80%9a%e7%94%a8%e6%9e%b6%e6%9e%84%e5%88%86%e7%b1%bb" onclick="onNavClick(`#llm通用架构分类-nav`)" id="llm通用架构分类-nav">
									LLM通用架构分类
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e4%b8%bb%e6%b5%81llm" onclick="onNavClick(`#主流llm-nav`)" id="主流llm-nav">
									主流LLM
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#chatglm" onclick="onNavClick(`#chatglm-nav`)" id="chatglm-nav">
									ChatGLM
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#qwen" onclick="onNavClick(`#qwen-nav`)" id="qwen-nav">
									Qwen
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#baichuan" onclick="onNavClick(`#baichuan-nav`)" id="baichuan-nav">
									Baichuan
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#llama" onclick="onNavClick(`#llama-nav`)" id="llama-nav">
									llama
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpt%e7%b3%bb%e5%88%97" onclick="onNavClick(`#gpt系列-nav`)" id="gpt系列-nav">
									GPT系列
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#deepseek" onclick="onNavClick(`#deepseek-nav`)" id="deepseek-nav">
									DeepSeek
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#llm%e8%ae%ad%e7%bb%83" onclick="onNavClick(`#llm训练-nav`)" id="llm训练-nav">
									LLM训练
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#common-nlu%e5%92%8cnlg%e4%bb%bb%e5%8a%a1" onclick="onNavClick(`#common-nlu和nlg任务-nav`)" id="common-nlu和nlg任务-nav">
									Common NLU和NLG任务
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%ba%94%e7%94%a8%e8%ae%ad%e7%bb%83%e9%80%89%e6%8b%a9" onclick="onNavClick(`#大模型应用训练选择-nav`)" id="大模型应用训练选择-nav">
									大模型应用训练选择
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#peft" onclick="onNavClick(`#peft-nav`)" id="peft-nav">
									PEFT
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%a3%80%e7%b4%a2%e5%a2%9e%e5%bc%ba%e7%94%9f%e6%88%90" onclick="onNavClick(`#检索增强生成-nav`)" id="检索增强生成-nav">
									检索增强生成
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#rlhf%e8%ae%ad%e7%bb%83" onclick="onNavClick(`#rlhf训练-nav`)" id="rlhf训练-nav">
									RLHF训练
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a class="pagination-action" v-on:click="toggleDarkMode">
            <i class="material-icons pagination-action-icon" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons pagination-action-icon" v-else="isDarkMode">
                brightness_7
            </i>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" ref="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                    
                
                
                
                <a class="a-block drawer-menu-item active" href="/blog">
                    文章📖
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    分类📌
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    标签🏷️
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/series">
                    系列📚
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/archive">
                    归档📃
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    关于👋
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/friends">
                    友链🔗
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/index.xml">
                    RSS📢
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- 目录 -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#nlp--llm%e5%85%a5%e9%97%a8" onclick="onNavClick(`#nlp--llm入门-nav`)" id="nlp--llm入门-nav">
									NLP &amp; LLM入门
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#llm%e5%8f%91%e5%b1%95" onclick="onNavClick(`#llm发展-nav`)" id="llm发展-nav">
									LLM发展
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#%e5%8f%8c%e5%90%91rnn%e4%b8%ad%e7%9a%84%e6%b3%a8%e6%84%8f%e5%8a%9b" onclick="onNavClick(`#双向rnn中的注意力-nav`)" id="双向rnn中的注意力-nav">
									双向RNN中的注意力
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transformer" onclick="onNavClick(`#transformer-nav`)" id="transformer-nav">
									Transformer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#post-ln-vs-pre-ln-transformer" onclick="onNavClick(`#post-ln-vs-pre-ln-transformer-nav`)" id="post-ln-vs-pre-ln-transformer-nav">
									Post-LN vs Pre-LN Transformer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#nlp%e4%b8%ad%e7%9a%84%e8%ae%ad%e7%bb%83%e8%8c%83%e5%bc%8f" onclick="onNavClick(`#nlp中的训练范式-nav`)" id="nlp中的训练范式-nav">
									NLP中的训练范式
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bert" onclick="onNavClick(`#bert-nav`)" id="bert-nav">
									BERT
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpt-1" onclick="onNavClick(`#gpt-1-nav`)" id="gpt-1-nav">
									GPT-1
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#bart" onclick="onNavClick(`#bart-nav`)" id="bart-nav">
									BART
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#llm%e9%80%9a%e7%94%a8%e6%9e%b6%e6%9e%84%e5%88%86%e7%b1%bb" onclick="onNavClick(`#llm通用架构分类-nav`)" id="llm通用架构分类-nav">
									LLM通用架构分类
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#%e4%b8%bb%e6%b5%81llm" onclick="onNavClick(`#主流llm-nav`)" id="主流llm-nav">
									主流LLM
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#chatglm" onclick="onNavClick(`#chatglm-nav`)" id="chatglm-nav">
									ChatGLM
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#qwen" onclick="onNavClick(`#qwen-nav`)" id="qwen-nav">
									Qwen
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#baichuan" onclick="onNavClick(`#baichuan-nav`)" id="baichuan-nav">
									Baichuan
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#llama" onclick="onNavClick(`#llama-nav`)" id="llama-nav">
									llama
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#gpt%e7%b3%bb%e5%88%97" onclick="onNavClick(`#gpt系列-nav`)" id="gpt系列-nav">
									GPT系列
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#deepseek" onclick="onNavClick(`#deepseek-nav`)" id="deepseek-nav">
									DeepSeek
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#llm%e8%ae%ad%e7%bb%83" onclick="onNavClick(`#llm训练-nav`)" id="llm训练-nav">
									LLM训练
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#common-nlu%e5%92%8cnlg%e4%bb%bb%e5%8a%a1" onclick="onNavClick(`#common-nlu和nlg任务-nav`)" id="common-nlu和nlg任务-nav">
									Common NLU和NLG任务
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%ba%94%e7%94%a8%e8%ae%ad%e7%bb%83%e9%80%89%e6%8b%a9" onclick="onNavClick(`#大模型应用训练选择-nav`)" id="大模型应用训练选择-nav">
									大模型应用训练选择
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#peft" onclick="onNavClick(`#peft-nav`)" id="peft-nav">
									PEFT
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#%e6%a3%80%e7%b4%a2%e5%a2%9e%e5%bc%ba%e7%94%9f%e6%88%90" onclick="onNavClick(`#检索增强生成-nav`)" id="检索增强生成-nav">
									检索增强生成
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#rlhf%e8%ae%ad%e7%bb%83" onclick="onNavClick(`#rlhf训练-nav`)" id="rlhf训练-nav">
									RLHF训练
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav ref="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div ref="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a ref="navTitle" class="navbar-brand" href="https://caixiongjiang.github.io/">
            🌀Jarson Cai&#39;s Blog
        </a>
        
        <button type="button" class="nav-darkmode-toggle" v-on:click="toggleDarkMode">
            <i class="material-icons" v-if="isDarkMode">
                brightness_4
            </i>
            <i class="material-icons" v-else="isDarkMode">
                brightness_7
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" ref="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://caixiongjiang.github.io/">
        <div class="single-column-header-title">🌀Jarson Cai&#39;s Blog</div>
        
        <div class="single-column-header-subtitle">头脑是日用品，不是装饰品</div>
        

    </a>
</div>

            <div id="content">
<div ref="streamContainer" class="stream-container">
    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            
                
            

            <div class="post-head-wrapper"
                
                    
                    
                    style="background-image: url('https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/LLM_title.jpg')"
                    
                
            >
                <div class="post-title">
                    NLP &amp; LLM入门
                    
                    <div class="post-subtitle">
                        学习大模型的发展历程，主流方法和模型，以及训练方法
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2024-01-18 18:18
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/">[大模型]</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/deep_learning">Deep_learning</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            28 min
                            
                            50 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <h2 id="nlp--llm入门">NLP &amp; LLM入门</h2>
<p>对于一个LLM菜鸡来说，从头理解LLM主要架构和任务是很有意义的。</p>
<h3 id="llm发展">LLM发展</h3>
<h4 id="双向rnn中的注意力">双向RNN中的注意力</h4>
<p>论文：<strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/1409.0473.pdf">https://arxiv.org/pdf/1409.0473.pdf</a></p>
<p>该论文引入了循环神经网络（RNN）的注意力机制。传统的 RNN 在处理较长序列时可能会遇到梯度消失或梯度爆炸等问题，导致远程位置的信息难以传递。注意力机制能够通过给予不同位置的输入不同的权重，使模型更好地捕捉到远程位置的信息，从而提高模型处理远程序列的能力。后续Transformer网络的开发也是为了提高网络的远程序列建模能力。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img30.jpg" alt=""></p>
<h4 id="transformer">Transformer</h4>
<p>论文：<strong>Attention Is All You Need</strong></p>
<p>链接：<a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></p>
<p>无论是做NLP还是做CV，这篇论文大家应该都很熟悉。Transformer是一个编码器解码器结构，其引入了位置编码，使得模型能够直接看到全局的信息，更有利于序列的长距离建模。其主要的结构Transformer Block主要由一个多头自注意力和一个前向传播网络（FFN）组成，内部的归一化使用的是Layer Normal，这可以摆脱训练批次对模型训练性能的影响。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img31.jpg" alt=""></p>
<h4 id="post-ln-vs-pre-ln-transformer">Post-LN vs Pre-LN Transformer</h4>
<p>论文：<strong>On Layer Normalization in the Transformer Architecture</strong></p>
<p>链接：<a href="https://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf">https://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf</a></p>
<p>该论文提出Transformer结构中的Layer Normal结构的位置应该放置在多头注意力和FFN之前。该论文表明了Pre-LN的结构比先前的Post-LN效果更佳，解决了梯度问题，许多架构在实践中采用了这一点，但表示它有可能导致崩溃。关于使用Post-LN和Pre-LN的争论目前还在，可以关注后续的发展。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img32.jpg" alt=""></p>
<h4 id="nlp中的训练范式">NLP中的训练范式</h4>
<p>论文：<strong>Universal Language Model Fine-tuning for Text Classification</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/1801.06146.pdf">https://arxiv.org/pdf/1801.06146.pdf</a></p>
<p>预训练微调的范式最早是在CV界广泛应用。早期NLP中的预训练微调的应用不广泛，大部分研究都是从头开始训练的，少数进行的预训练微调的效果并不好，比随机初始化的结果还差，或者需要很多的数据集作为预训练的语料库。该论文根据CV模型和NLP模型不同的架构，设计了三层完全相同的LSTM网络拼接的预训练网络。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img33.jpg" alt=""></p>
<p>上图所示即为该论文提出的语言模型的预训练微调的范式ULMFit，其主要分为三个阶段：</p>
<ol>
<li>在大量文本语料库上训练语言模型</li>
<li>在特定任务数据上微调此预训练的语言模型，使其能适应文本的特定风格和词汇。</li>
<li>对特定任务数据的分类器进行微调，逐步解冻层，避免灾难性遗忘。</li>
</ol>
<p>这个训练范式（在大型语料库上训练语言模型，然后在下游任务上进行微调）是后续基于Transformer的模型和基础模型（如BERT、GPT-2/3/4、RoBERTa等）中使用的中心方法。</p>
<p>然而，在使用Transformer架构时，<strong>逐渐解冻在实践中通常不会例行完成，所有层通常都同时进行微调</strong>。</p>
<h4 id="bert">BERT</h4>
<p>论文：<strong>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a></p>
<p>BERT模型的基础结构采用了原始的Transformer结构，但是在预训练和微调时，BERT都使用了双向Transformer模型。</p>
<p>BERT的训练过程分为两个阶段：</p>
<ol>
<li>模型在大型语料库中对未标记的数据进行训练：（1）Masked Language Model（MLM），BERT可以关注文本左边的上下文和右边的上下文，为了让文本适应这种双向关注，使用完型填空的方式，只预测这些被屏蔽的单词，而不是重建整个输入。 （2）Next Sentence Prediction（NSP），为了训练句子之间的关系，通过上一句的信息来预测下一句。</li>
<li>载入预训练的参数初始化，所有参数使用下游任务有标记的数据进行微调。</li>
</ol>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img34.jpg" alt=""></p>
<h4 id="gpt-1">GPT-1</h4>
<p>论文：<strong>Improving Language Understanding by Generative Pre-Training</strong></p>
<p>链接：<a href="https://www.mikecaptain.com/resources/pdf/GPT-1.pdf">https://www.mikecaptain.com/resources/pdf/GPT-1.pdf</a></p>
<p>先前用于不同的文本任务上需要添加额外的结构，使得模型需要定制化。GPT提出使用遍历式方法，将结构化输入转化为有序序列，这种输入转化避免了跨任务对任务对模型架构的广泛更改。具体不同如何转化看下图中的右边部分。</p>
<p>GPT的训练范式与BERT类似，都是现在大型无标签数据上进行训练后在有标签数据的目标任务上进行微调。只是GPT是一个解码器式的Transformer架构，它的文本建模方式为以上文为基础，去生成下面的文本（token），这表明模型只能关注左侧的信息来生成下文。GPT系列也被证明在文本生成方面的任务更加有效。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img35.jpg" alt=""></p>
<h4 id="bart">BART</h4>
<p>论文：<strong>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/1910.13461.pdf">https://arxiv.org/pdf/1910.13461.pdf</a></p>
<p>如前所述，BERT型编码器风格的LLM通常是预测建模任务的首选，而GPT型解码器风格的LLM更擅长生成文本。为了充分利用这两方面，BART模型结合了编码器和解码器部分。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img36.jpg" alt=""></p>
<h4 id="llm通用架构分类">LLM通用架构分类</h4>
<p>论文：<strong>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2304.13712.pdf">https://arxiv.org/pdf/2304.13712.pdf</a></p>
<p>遵循原始的Transformer架构，大型语言模型研究开始向两个方向分叉：用于文本分类等预测建模任务（NLU）的编码器式（Encoder-style）Transformer和用于翻译、总结和其他形式文本创建等生成建模任务（NLG）的解码器式（Decoder-style）Transformer。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img37.jpg" alt=""></p>
<h3 id="主流llm">主流LLM</h3>
<h4 id="chatglm">ChatGLM</h4>
<p>论文：<strong>GLM: General Language Model Pretraining with Autoregressive Blank Inﬁlling</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2103.10360.pdf">https://arxiv.org/pdf/2103.10360.pdf</a></p>
<p>自动编码模型（例如BERT）、自动回归模型（例如GPT）和编码器-解码器模型（例如T5）。然而，没有一个预训练框架对三个主要类别的所有任务表现最好，包括自然语言理解（NLU）、无条件生成和条件生成。</p>
<p>GLM通过添加2D位置编码和允许任意顺序预测跨度来改进空白填充预训练，从而在NLU任务上比BERT和T5的性能提高。</p>
<ul>
<li>任务1：自动回归空白填充
<ul>
<li>mask的token方面：（1）一个句子随机抽取连续的几个token，使用一个Span盖住，再把Span随机打乱（为了充分捕捉不同Span之前见的依赖关系，使用随机跨度顺序，类似于排列语言模型）</li>
<li>被mask的部分：（1）单向注意力（前面预测后面，带箭头）（2）不参与预测没有被mask的部分。（如下图所示）</li>
<li>没有被mask的部分：双向注意力（前后双向预测，不带箭头）</li>
</ul>
</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img40.jpg" alt=""></p>
<ul>
<li>2D位置编码过程</li>
</ul>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img41.jpg" alt=""></p>
<p>其中(a)为原始序列，被分为A和B两个序列。图(d)中表示了具体的自注意力mask。</p>
<ul>
<li>多任务学习：使用了Document level和Sentence level两个级别进行学习。</li>
</ul>
<p>论文：<strong>Glm-130b: An open bilingual pre-trained model</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2210.02414.pdf">https://arxiv.org/pdf/2210.02414.pdf</a></p>
<p>GLM-130b是对标GPT-3 175B参数规模大小的模型。训练100B左右规模的模型与训练10B规模模型在训练效率、稳定性和收敛性上带来了很多技术和工程上的挑战。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img42.jpg" alt=""></p>
<p>上表是描述两个开源大模型工作和GPT-3以及PaLM使用的架构、语种、数据类型、稳定性策略、量化、推理要求等对比。</p>
<p>可以看到，经过量化到INT4类型后，仅需要4张3090（4$\times$24）或者8张1080Ti（8$\times$12）就可以进行130B模型的推理。</p>
<p>![](/Users/caixiongjiang/Library/Application Support/typora-user-images/image-20240125142645093.png)</p>
<p>大体量LLM的训练，相对于10B规模的训练不同，需要大量的工程优化技术，且参数比较难以训练。控制训练过程中的梯度非常重要，这成为了模型是否训练成功的关键。</p>
<ul>
<li>INT4量化：研究团队根据不同架构模型的权重精度分布来表现量化对性能的影响，可以看到GLM的权重精度分布使得其直接进行量化后few shot性能几乎没有影响。</li>
</ul>
<img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img43.jpg" style="zoom:50%;" />
<h4 id="qwen">Qwen</h4>
<p>论文：<strong>Qwen Technical Report</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2309.16609.pdf">https://arxiv.org/pdf/2309.16609.pdf</a></p>
<h4 id="baichuan">Baichuan</h4>
<p>论文：<strong>Baichuan 2: Open Large-scale Language Models</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2309.10305.pdf">https://arxiv.org/pdf/2309.10305.pdf</a></p>
<h4 id="llama">llama</h4>
<p>论文：<strong>LLaMA: Open and Efficient Foundation Language Models</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2302.13971.pdf">https://arxiv.org/pdf/2302.13971.pdf</a></p>
<h4 id="gpt系列">GPT系列</h4>
<p>论文：<strong>Language Models are Few-Shot Learners</strong></p>
<p>链接：<a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a></p>
<h4 id="deepseek">DeepSeek</h4>
<p>论文：<strong>DeepSeek LLM Scaling Open-Source Language Models with Longtermism</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2401.02954.pdf">https://arxiv.org/pdf/2401.02954.pdf</a></p>
<blockquote>
<p>数据</p>
</blockquote>
<p>为了全面增强数据集的丰富性和多样性，将数据收集的手段的方法分为了三个阶段：数据删除、过滤和重新混合。</p>
<blockquote>
<p>架构</p>
</blockquote>
<p>DeepSeek LLM的微观设计在很大程度上遵循了LLaMA的设计，采用具有RMSNorm功能的Pre-Norm结构，并使用SwiGLU作为前馈网络的激活函数，中间层尺寸为38d模型。它还纳入了旋转嵌入用于位置编码。为了优化推理成本，67B模型使用GroupedQuery Attention，而不是传统的多头注意力。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img44.jpg" alt=""></p>
<p>DeepSeek一共有两个版本的模型，分别是7B和67B。DeepSeek在模型训练上没有使用传统的余弦退火学习策略。而采用了多步学习率下调策略，可以看到下图是他们训练结果的区别。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img45.jpg" alt=""></p>
<h3 id="llm训练">LLM训练</h3>
<h4 id="common-nlu和nlg任务">Common NLU和NLG任务</h4>
<p>NLU (Natural Language Understanding) 和 NLG (Natural Language Generation) 是自然语言处理中常见的任务类型。</p>
<ul>
<li>NLU 任务（自然语言理解）：</li>
</ul>
<ol>
<li>文本分类：将文本分为不同的类别，如情感分类、主题分类等。</li>
<li>命名实体识别（NER）：从文本中识别并标记出命名实体，如人名、地名、组织机构等。</li>
<li>意图识别（Intent Recognition）：从用户输入的文本中识别用户的意图或目的，常用于对话系统中。</li>
<li>语义角色标注（Semantic Role Labeling）：为句子中的每个单词或短语标注其在句子中扮演的语义角色，如施事者、受事者、时间等。</li>
<li>语义解析（Semantic Parsing）：将自然语言转换为结构化的表示形式，如逻辑形式或查询语言，以便进行进一步的处理。</li>
</ol>
<ul>
<li>NLG 任务（自然语言生成）：</li>
</ul>
<ol>
<li>文本生成：根据给定的输入或上下文生成自然语言文本，如自动摘要、机器翻译等。</li>
<li>问答生成（Question Answering Generation）：根据问题生成相应的回答。</li>
<li>对话生成：在对话系统中生成自然语言回复，使其与用户进行交互。</li>
<li>文本摘要生成：从大量文本中生成简洁的概括性摘要。</li>
<li>生成式对话系统：构建能够进行连贯、有逻辑的对话的系统，使其能够与人类进行自然交流。</li>
</ol>
<h4 id="大模型应用训练选择">大模型应用训练选择</h4>
<p>论文：<strong>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2304.13712.pdf">https://arxiv.org/pdf/2304.13712.pdf</a></p>
<p>下图是制作一个大模型应用的选择流程，主要涉及目标任务的难度、类型、以及标签数据是否丰富等。其中<code>LLMs</code>是指使用原生的预训练LLM搭配不同的Prompt来完成任务，而<code>Fine-tuned Models</code>则是LLM模型对目标任务的数据进行参数调整。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img38.jpg" alt=""></p>
<blockquote>
<p>选择LLM模型与微调模型？</p>
</blockquote>
<ul>
<li>在面临非分布数据（如对抗性示例和领域转移）的下游任务中，LLM比微调模型更通用。</li>
<li>在处理有限的注释数据时，LLM比微调模型更可取，当有丰富的注释数据可用时，两者都可以成为合理的选择，具体任务要求。</li>
<li>建议在类似于下游任务的数据字段上选择LLM。</li>
<li>在为下游任务选择LLM时，最好选择在类似数据领域进行预训练的模型。</li>
<li>进行下游任务时需要考虑注释数据的可用性。没有注释时，直接使用预训练的LLM模型；上下文学习： 将一些例子包含在LLM的输入提示中；如果目标任务的数据很丰富，可以考虑微调模型参数或者直接用LLM。</li>
<li>RLHF方法可以显著增强LLM的泛化能力。</li>
<li>在大多数自然语言理解任务中带有丰富的注释数据，并且在测试集中包含很少的分布外示例，则微调模型仍然具有更好的性能。</li>
<li>由于大模型的生成能力和创造力，LLM在大多数生成任务上表现出较强的优势。</li>
<li>LLM擅长要求模型全面了解输入内容和要求，并具有一定的创造能力的任务，比如文本总结，机器翻译，开放式生成。</li>
</ul>
<h4 id="peft">PEFT</h4>
<p>论文：<strong>Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning</strong></p>
<p>链接：<a href="https://arxiv.org/pdf/2303.15647.pdf">https://arxiv.org/pdf/2303.15647.pdf</a></p>
<p>关于<code>PEFT</code>的内容，在大模型高效微调博文中已经仔细分析，这里通过综述论文进行一定的总结。</p>
<p>该论文将所有的论文分为了3种大类方法：</p>
<ul>
<li><strong>Additive methods</strong>：这种方法背后的主要想法是用额外的参数或层增强现有的预训练模型，并仅训练新添加的参数。</li>
<li><strong>Selective methods</strong>: 这种方法主要是通过自由选择网络的一些层进行微调，例如调整偏置（bias）等，以及一些稀疏更新的方法，然而不受限制的非结构化稀疏性在当代硬件上很难得到很好的加速。</li>
<li><strong>Reparametrization-based methods</strong>: 该类别方法使用了低秩矩阵分解的原理，最大限度地减少可训练的参数。</li>
</ul>
<h4 id="检索增强生成">检索增强生成</h4>
<p>论文：<strong>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</strong></p>
<p>链接：<a href="https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf</a></p>
<p>该论文针对序列到序列（seq2seq）模型的”幻觉”问题，提出了一种检索增强生成的问题。</p>
<p>大模型通常在知识密集型任务上低于特定任务架构的性能。该文提出的RAG只要由参数存储器（参数可调整模型）和非参数存储器相结合，如下图所示。其中编码器和检索器组成了非参数存储器，而生成器（后面演变成LLM）充当参数存储器。</p>
<p><img src="https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/LLM/img39.jpg" alt=""></p>
<p>RAG有两种训练范式：</p>
<ul>
<li>RAG-Sequence Model：使用序列级别的检索来增强生成模型。生成模型负责生成目标序列，检索模型负责从候选文档集中选择相关的文档或片段，组合模块将生成模型和检索模型的输出结合起来，以生成最终的结果。</li>
<li>RAG-Token Model：将检索模型的输出直接融入到生成模型中，而不是作为上下文输入。具体而言，RAG-Token Model将检索模型的输出表示为一个可学习的标记嵌入向量，并将其与输入序列的标记嵌入向量进行拼接或加权求和。</li>
</ul>
<p>为了深入理解这种区别，我们将<code>BART</code>模型分别作为分词器和生成器，使用代码来解释这种区别。</p>
<ul>
<li>RAG-Sequence Model：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">transformers</span> <span style="color:#8b008b;font-weight:bold">import</span> RagTokenizer, RagSequenceForGeneration, RagRetriever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义检索器（Retriever）</span>
</span></span><span style="display:flex;"><span>retriever = RagRetriever.from_pretrained(<span style="color:#cd5555">&#39;facebook/dpr-ctx_encoder-single-nq-base&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义生成器（Generator）</span>
</span></span><span style="display:flex;"><span>generator = RagSequenceForGeneration.from_pretrained(<span style="color:#cd5555">&#39;facebook/bart-large&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义分词器（Tokenizer）</span>
</span></span><span style="display:flex;"><span>tokenizer = RagTokenizer.from_pretrained(<span style="color:#cd5555">&#39;facebook/bart-large&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 输入查询</span>
</span></span><span style="display:flex;"><span>query = <span style="color:#cd5555">&#34;What is the capital of France?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 输入候选文档</span>
</span></span><span style="display:flex;"><span>documents = [
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;France is a country located in Western Europe. Its capital is Paris.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;Paris is the capital and most populous city of France.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;The capital city of France is Paris.&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 对查询和候选文档进行编码</span>
</span></span><span style="display:flex;"><span>inputs = tokenizer.prepare_seq2seq_batch(
</span></span><span style="display:flex;"><span>    queries=query,
</span></span><span style="display:flex;"><span>    documents=documents,
</span></span><span style="display:flex;"><span>    return_tensors=<span style="color:#cd5555">&#39;pt&#39;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 检索相关文档</span>
</span></span><span style="display:flex;"><span>retrieved_docs = retriever(inputs[<span style="color:#cd5555">&#39;input_ids&#39;</span>], attention_mask=inputs[<span style="color:#cd5555">&#39;attention_mask&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 将检索到的文档作为上下文输入，生成结果</span>
</span></span><span style="display:flex;"><span>generated = generator.generate(
</span></span><span style="display:flex;"><span>    input_ids=inputs[<span style="color:#cd5555">&#39;input_ids&#39;</span>],
</span></span><span style="display:flex;"><span>    attention_mask=inputs[<span style="color:#cd5555">&#39;attention_mask&#39;</span>],
</span></span><span style="display:flex;"><span>    context_input_ids=retrieved_docs[<span style="color:#cd5555">&#39;context_input_ids&#39;</span>],
</span></span><span style="display:flex;"><span>    context_attention_mask=retrieved_docs[<span style="color:#cd5555">&#39;context_attention_mask&#39;</span>],
</span></span><span style="display:flex;"><span>    max_length=<span style="color:#b452cd">50</span>,
</span></span><span style="display:flex;"><span>    num_return_sequences=<span style="color:#b452cd">1</span>,
</span></span><span style="display:flex;"><span>    num_beams=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>    no_repeat_ngram_size=<span style="color:#b452cd">2</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 解码生成的结果</span>
</span></span><span style="display:flex;"><span>result = tokenizer.batch_decode(generated, skip_special_tokens=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(result)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>RAG-Token Model：</li>
</ul>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b008b;font-weight:bold">from</span> <span style="color:#008b45;text-decoration:underline">transformers</span> <span style="color:#8b008b;font-weight:bold">import</span> RagTokenizer, RagTokenForGeneration, RagRetriever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义检索器（Retriever）</span>
</span></span><span style="display:flex;"><span>retriever = RagRetriever.from_pretrained(<span style="color:#cd5555">&#39;facebook/dpr-ctx_encoder-single-nq-base&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义生成器（Generator）</span>
</span></span><span style="display:flex;"><span>generator = RagTokenForGeneration.from_pretrained(<span style="color:#cd5555">&#39;facebook/bart-large&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 定义分词器（Tokenizer）</span>
</span></span><span style="display:flex;"><span>tokenizer = RagTokenizer.from_pretrained(<span style="color:#cd5555">&#39;facebook/bart-large&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 输入查询</span>
</span></span><span style="display:flex;"><span>query = <span style="color:#cd5555">&#34;What is the capital of France?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 输入候选文档</span>
</span></span><span style="display:flex;"><span>documents = [
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;France is a country located in Western Europe. Its capital is Paris.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;Paris is the capital and most populous city of France.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#cd5555">&#34;The capital city of France is Paris.&#34;</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 对查询和候选文档进行编码</span>
</span></span><span style="display:flex;"><span>inputs = tokenizer.prepare_seq2seq_batch(
</span></span><span style="display:flex;"><span>    queries=query,
</span></span><span style="display:flex;"><span>    documents=documents,
</span></span><span style="display:flex;"><span>    return_tensors=<span style="color:#cd5555">&#39;pt&#39;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 检索相关文档</span>
</span></span><span style="display:flex;"><span>retrieved_docs = retriever(inputs[<span style="color:#cd5555">&#39;input_ids&#39;</span>], attention_mask=inputs[<span style="color:#cd5555">&#39;attention_mask&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 将检索到的文档表示为嵌入向量</span>
</span></span><span style="display:flex;"><span>context_embeddings = retrieved_docs[<span style="color:#cd5555">&#39;retrieved_doc_embeds&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 将检索结果与输入序列的标记嵌入向量进行拼接</span>
</span></span><span style="display:flex;"><span>input_ids = inputs[<span style="color:#cd5555">&#39;input_ids&#39;</span>]
</span></span><span style="display:flex;"><span>attention_mask = inputs[<span style="color:#cd5555">&#39;attention_mask&#39;</span>]
</span></span><span style="display:flex;"><span>expanded_input_ids = torch.cat([input_ids, context_embeddings], dim=-<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>expanded_attention_mask = torch.cat([attention_mask, torch.ones_like(context_embeddings)], dim=-<span style="color:#b452cd">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 生成结果</span>
</span></span><span style="display:flex;"><span>generated = generator.generate(
</span></span><span style="display:flex;"><span>    input_ids=expanded_input_ids,
</span></span><span style="display:flex;"><span>    attention_mask=expanded_attention_mask,
</span></span><span style="display:flex;"><span>    max_length=<span style="color:#b452cd">50</span>,
</span></span><span style="display:flex;"><span>    num_return_sequences=<span style="color:#b452cd">1</span>,
</span></span><span style="display:flex;"><span>    num_beams=<span style="color:#b452cd">4</span>,
</span></span><span style="display:flex;"><span>    no_repeat_ngram_size=<span style="color:#b452cd">2</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#228b22"># 解码生成的结果</span>
</span></span><span style="display:flex;"><span>result = tokenizer.batch_decode(generated, skip_special_tokens=<span style="color:#8b008b;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#658b00">print</span>(result)
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="rlhf训练">RLHF训练</h4>

                    
                    <HR width="100%" id="EOF">
		            <p style="color:#777;">最后修改于 2024-01-19</p>
                    
                    
                    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://image-1252109614.cos.ap-beijing.myqcloud.com/img/20210508215939.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://caixiongjiang.github.io/blog/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/vllm%E5%B9%B6%E5%8F%91/">
			下回<br>vLLM如何提高并发？
                </a>
                
                
                
                <a class="older-posts" href="https://caixiongjiang.github.io/blog/2024/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/langchain%E5%85%A5%E9%97%A8/">
			上回<br>LangChain:LLM应用框架
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                








<div id="tcomment"></div>



            </div>
        </div>
    </div>
</div>

            </div><div id="single-column-footer">
魔改自 <a href="https://github.com/riba2534/hugo-blog">Riba2534</a> by <a href="https://caixiongjiang.github.io">Jarson Cai</a>
<br>

&copy;
	
	2024 🌀Jarson Cai&#39;s Blog
	</div>
            </div>
    <script>
let app;

app = new Vue({
    el: '#app',
    data: {
        scrollY: 0,
        navOpacity: 0,
        isDrawerOpen: false,
        mounted: false,
        isDarkMode: false
    },
    methods: {
            sgn(t, x) {
                let k = 1. / (1. - 2 * t);
                if (x <= t) return 0;
                else if (x >= 1 - t) return 1;
                else {
                    return k * (x - t);
                }
            },
            handleScroll() {
                this.scrollY = window.scrollY;
                this.navOpacity = this.sgn(.0, Math.min(1, Math.max(0, window.scrollY / (this.pageHeadHeight() - this.navBarHeight() * 0.8))));
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;

                if (this.navOpacity >= 1) {
                    navBackground.style.opacity = 1;
                    navTitle.style.opacity = 1;
                } else {
                    navBackground.style.opacity = 0;
                    navTitle.style.opacity = 0;
                }
            },
            handleResize() {
                const {navBar, navBackground, navTitle, extraContainer, streamContainer} = this.$refs;
                extraContainer.style.left = (streamContainer.offsetWidth - extraContainer.offsetWidth) + 'px';
            },
            navBarHeight() {
                return this.$refs.navBar.offsetHeight;
            },
            pageHeadHeight() {
                return this.$refs.pageHead.offsetHeight;
            },
            toggleDrawer() {
                this.isDrawerOpen = !this.isDrawerOpen;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            closeDrawer() {
                this.isDrawerOpen = false;
                document.getElementsByTagName('html')[0].style.overflow = this.isDrawerOpen ? 'hidden' : 'unset';
            },
            toggleDarkMode() {
                this.isDarkMode = !this.isDarkMode;
                if (this.isDarkMode==true){
                    document.cookie = "night=1;path=/";
                    document.body.classList.add("night");
                } else {
                    document.cookie = "night=0;path=/";
                    document.body.classList.remove("night");
                }
            },
            debounce(func, wait, options) {
                let lastArgs,
                    lastThis,
                    maxWait,
                    result,
                    timerId,
                    lastCallTime

                let lastInvokeTime = 0
                let leading = false
                let maxing = false
                let trailing = true

                
                const useRAF = (!wait && wait !== 0 && typeof root.requestAnimationFrame === 'function')

                if (typeof func !== 'function') {
                    throw new TypeError('Expected a function')
                }
                function isObject(value) {
                    const type = typeof value
                    return value != null && (type === 'object' || type === 'function')
                }

                wait = +wait || 0
                if (isObject(options)) {
                    leading = !!options.leading
                    maxing = 'maxWait' in options
                    maxWait = maxing ? Math.max(+options.maxWait || 0, wait) : maxWait
                    trailing = 'trailing' in options ? !!options.trailing : trailing
                }

                function invokeFunc(time) {
                    const args = lastArgs
                    const thisArg = lastThis

                    lastArgs = lastThis = undefined
                    lastInvokeTime = time
                    result = func.apply(thisArg, args)
                    return result
                }

                function startTimer(pendingFunc, wait) {
                    if (useRAF) {
                    root.cancelAnimationFrame(timerId)
                    return root.requestAnimationFrame(pendingFunc)
                    }
                    return setTimeout(pendingFunc, wait)
                }

                function cancelTimer(id) {
                    if (useRAF) {
                    return root.cancelAnimationFrame(id)
                    }
                    clearTimeout(id)
                }

                function leadingEdge(time) {
                    
                    lastInvokeTime = time
                    
                    timerId = startTimer(timerExpired, wait)
                    
                    return leading ? invokeFunc(time) : result
                }

                function remainingWait(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime
                    const timeWaiting = wait - timeSinceLastCall

                    return maxing
                    ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke)
                    : timeWaiting
                }

                function shouldInvoke(time) {
                    const timeSinceLastCall = time - lastCallTime
                    const timeSinceLastInvoke = time - lastInvokeTime

                    
                    
                    
                    return (lastCallTime === undefined || (timeSinceLastCall >= wait) ||
                    (timeSinceLastCall < 0) || (maxing && timeSinceLastInvoke >= maxWait))
                }

                function timerExpired() {
                    const time = Date.now()
                    if (shouldInvoke(time)) {
                    return trailingEdge(time)
                    }
                    
                    timerId = startTimer(timerExpired, remainingWait(time))
                }

                function trailingEdge(time) {
                    timerId = undefined

                    
                    
                    if (trailing && lastArgs) {
                    return invokeFunc(time)
                    }
                    lastArgs = lastThis = undefined
                    return result
                }

                function cancel() {
                    if (timerId !== undefined) {
                    cancelTimer(timerId)
                    }
                    lastInvokeTime = 0
                    lastArgs = lastCallTime = lastThis = timerId = undefined
                }

                function flush() {
                    return timerId === undefined ? result : trailingEdge(Date.now())
                }

                function pending() {
                    return timerId !== undefined
                }

                function debounced(...args) {
                    const time = Date.now()
                    const isInvoking = shouldInvoke(time)

                    lastArgs = args
                    lastThis = this
                    lastCallTime = time

                    if (isInvoking) {
                    if (timerId === undefined) {
                        return leadingEdge(lastCallTime)
                    }
                    if (maxing) {
                        
                        timerId = startTimer(timerExpired, wait)
                        return invokeFunc(lastCallTime)
                    }
                    }
                    if (timerId === undefined) {
                    timerId = startTimer(timerExpired, wait)
                    }
                    return result
                }
                debounced.cancel = cancel
                debounced.flush = flush
                debounced.pending = pending
                return debounced
                }

    },
    created() {
        window.addEventListener('scroll', this.handleScroll);
        window.addEventListener('resize', this.handleResize);
        window._nonDesktop = function () {
            let check = false;
            (function (a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };
        
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1");
        if (night==""){
            if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
                
            }
        }else{
            
            if (night=="1") {
                this.toggleDarkMode();
            }
        }
    },
    mounted() {
        this.handleScroll();
        this.handleResize();
        this.mounted = true;

        
        
        
            twikoo.init({
                envId: "https://twikoo-rho-olive.vercel.app/",
                el: '#tcomment',
                region:  null ,
            });
        

        document.querySelectorAll("table").forEach(function(elem){
            elem.classList.add("table-striped");
            elem.classList.add("table");
            elem.classList.add("table-responsive");
            elem.classList.add("table-hover");
        })

        
        spy();
        window.addEventListener('scroll', this.debounce(spy, 250, { 'maxWait': 250 }), false);
        
        
    },
    destroyed() {
        window.removeEventListener('scroll', this.handleScroll);
        window.removeEventListener('resize', this.handleResize);
    }
});



</script>
    </body>
</html>
