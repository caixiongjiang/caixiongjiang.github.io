<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on 🌀Jarson Cai&#39;s Blog</title>
    <link>https://caixiongjiang.github.io/blog/</link>
    <description>Recent content in Blogs on 🌀Jarson Cai&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 21 Jul 2023 18:18:05 +0800</lastBuildDate><atom:link href="https://caixiongjiang.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>M1 Mac安装LabelImg及使用</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E5%AE%9E%E4%B9%A0/m1-mac-%E5%AE%89%E8%A3%85labelimg/</link>
      <pubDate>Fri, 21 Jul 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E5%AE%9E%E4%B9%A0/m1-mac-%E5%AE%89%E8%A3%85labelimg/</guid>
      <description>LabelImg M1 Mac 安装LabelImg 如果你直接使用命令行安装：
1 $ pip install labelimg 你会发现你的M1笔记本会报错，查了一些资料，找到了解决方法。
总体思路就是使用pyqt6代替pyqt5，从源文件进行安装：
1.找到问题的解决方案：https://github.com/HumanSignal/labelImg/tree/pyside6 2.下载分支文件：必须安装该分支的文件（download zip且解压），不能使用git clone，这样会变成下载主分支。或者可以直接clone分支： 1 $ git clone -b pyside6 https://github.com/HumanSignal/labelImg.git 3.进入文件目录 1 $ cd labelImg-pyside6 建立虚拟环境并进行安装： 1 2 3 4 5 $ conda create -n LabelImg python=3.9 $ conda activate LabelImg $ pip3 install pyside6 lxml $ make pyside6 $ python3 labelImg.py OK!启动成功！
LabelImg导出不同格式的标签文件 </description>
    </item>
    
    <item>
      <title>亚信算法实习笔记</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E5%AE%9E%E4%B9%A0/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B01/</link>
      <pubDate>Fri, 21 Jul 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E5%AE%9E%E4%B9%A0/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B01/</guid>
      <description>亚信图像算法实习笔记 授权书区域识别项目：2023.7.24～2023.8.05 修改Linux服务器文件权限问题 将文件设置为可读写执行权限： 1 $ chmod 777 file 给文件所有者增加写权限： 1 $ chmod u+w file 给文件所有者和同组用户赋予读写权限，其他用户只有读权限： 1 $ chmod 664 file 递归修改目录及其子目录中的文件权限： 1 $ chmod -R 755 directory 显示修改后的权限信息： 1 $ chmod -v 755 file 请注意，修改文件或目录的权限需要有足够的权限进行操作。只有文件或目录的所有者或超级用户(root)才能更改权限。
Docker配置深度学习环境 第一步，安装Docker
检查docker是否安装： 1 $ docker help 如果没有安装docker，则使用官方提供的脚本进行安装： 1 $ curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun Docker镜像加速
在/etc/docker/daemon.json中写入如下内容，如果没有该文件则新建： 1 {&amp;#34;registry-mirrors&amp;#34;:[&amp;#34;https://XXX.mirror.aliyuncs.com/&amp;#34;]} 重启Docker服务： 1 2 $ sudo systemctl daemon-reload $ sudo systemctl restart docker 从Docker Hub下载镜像</description>
    </item>
    
    <item>
      <title>CUDA编程实战</title>
      <link>https://caixiongjiang.github.io/blog/2023/hpc/cuda%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/</link>
      <pubDate>Wed, 19 Jul 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/hpc/cuda%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/</guid>
      <description>CUDA编程实战 Hello GPU 编写第一个gpu程序
一般来说，CUDA程序是.cu结尾的程序！
hello-gpu.cu:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include &amp;lt;stdio.h&amp;gt; void cpu() { printf(&amp;#34;hello cpu\n&amp;#34;); } __global__ void gpu() { printf(&amp;#34;hello gpu\n&amp;#34;); } int main() { cpu(); gpu&amp;lt;&amp;lt;&amp;lt;1, 1&amp;gt;&amp;gt;&amp;gt;(); // 等待cpu和gpu同步 cudaDeviceSynchronize(); } __global__:
__global__关键字代表以下函数将在GPU山运行并全局可调用。 通过我们将在cpu上执行的代码称为主机代码，而在GPU上运行的代码称为设备代码。 注意返回类型为void。使用__global__关键字定义的函数需要返回void类型。 gpu&amp;laquo;&amp;lt;1, 1&amp;raquo;&amp;gt;():
通常，当调用要在GPU上运行的函数时，我们将这种函数称为已启动的核函数。 启动核函数之前必须提供执行的配置，在向核函数传递任何预期参数之前使用&amp;lt;&amp;lt;&amp;lt;...&amp;gt;&amp;gt;&amp;gt;语法完成配置。 程序员可通过执行配置为核函数启动指定线程层次结构，从而定义线程组（也称为线程块）的数量，以及要在每个线程块中执行的线程数量。这里就代表正在使用包含1线程（第二个配置参数）的1线程块（第一个配置参数）启动核函数。 cudaDeviceSynchronize():
与大部分c/c++代码不同，核函数启动方式为异步：CPU代码将继续执行而无需等待核函数完成启动。 调用CUDA运行时提供的函数cudaDeviceSynchronize将导致主机（cpu）代码暂停，直至设备（GPU）代码执行完成，才能在cpu上恢复执行。 使用nvcc编译、链接、执行
1 nvcc -o hello-gpu hello-gpu.cu -run 看到
1 2 hello cpu hello gpu 说明你编译、链接、执行成功。</description>
    </item>
    
    <item>
      <title>中科大CUDA教程</title>
      <link>https://caixiongjiang.github.io/blog/2023/hpc/%E4%B8%AD%E7%A7%91%E5%A4%A7cuda%E6%95%99%E7%A8%8B/</link>
      <pubDate>Wed, 19 Jul 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/hpc/%E4%B8%AD%E7%A7%91%E5%A4%A7cuda%E6%95%99%E7%A8%8B/</guid>
      <description>中科大CUDA编程 参考资料：
CUDA C Programming Guide，中文翻译见here CUDA C++ Best Practice Guide CPU体系架构概述 现代CPU架构和性能优化 CPU是执行指令和处理数据的器件，能完成基本的逻辑和算术指令。
指令
Example：
算术：add r3,r4 -&amp;gt; r4
访存：load [r4] -&amp;gt; r7
控制：jz end
对于一个编译好的程序，最优化目标： $$ \frac{cycle}{instruction}\times \frac{seconds}{cycle} $$ 总结来说，CPI（每条指令的时钟数）&amp;amp; 时钟周期，注意这两个指标并不独立。
摩尔定律
芯片的集成密度每两年翻一番，成本下降一半。
CPU的处理流程
取址 -&amp;gt; 解码 -&amp;gt; 执行 -&amp;gt; 访存 -&amp;gt; 写回
流水线
使用一个洗衣服的例子，单件衣服总时间 = wash（30min）+ dry（40min）+ fold（20min）
那么洗4件衣服需要的总时间 = 30 + 40 + 40 + 40 + 40 + 20 = 210min
流水线使用的是指令级的并行，可以有效地减少时钟周期 增加了延迟和芯片面积（需要更多的存储） 带来了一些问题：具有依赖关系的指令处理，分支如何处理 旁路（Bypassing）</description>
    </item>
    
    <item>
      <title>Ubuntu CUDA编程环境配置</title>
      <link>https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Fri, 14 Jul 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/hpc/ubuntu%E5%AE%89%E8%A3%85cuda%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>Ubuntu下CUDA环境配置 为了学习CUDA编程，我们需要一套Linux下的CUDA编程环境，需要注意的是我们的Linux下需要直通显卡，所以记住不能使用虚拟机！不能使用虚拟机！不能使用虚拟机！
那为了方便学习，又不能完全抛弃Windows，毕竟我还要写毕业论文。那么双系统就是最好的方案了。
Windows &amp;amp; Ubuntu 双系统 首先，Linux发行版的选择，我建议还是用Ubuntu，毕竟群体多，社区才能维护。
双系统安装参考视频
Ubuntu安装显卡驱动、cuda、cudnn 我使用的配置如下：
Ubuntu：20.04 显卡：RTX3060 CUDA版本：11.7 cudnn版本：8.9.0 显卡驱动版本：535 显卡驱动安装 Ubuntu安装显卡驱动，CUDA，cudnnn参考视频
注意，安装完驱动必须重启！
CUDA和cudnn安装 Ubuntu22.04安装CUDA环境参考文章
CUDA工具包安装
首先进入NVIDIA CUDA Toolkit Archive下载你想要的cuda工具版本，需要根据你系统的版本和显卡驱动版本进行选择，只要支持就ok。
在Ubuntu终端输入:
1 $ nvidia-smi 在显示的CUDA版本代表当前驱动支持的最高版本CUDA，我的最高版本为12.2，所以选择安装的CUDA版本需要小于12.2。
我选择了CUDA11.7的版本： 依次输入命令：
1 $ wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda_11.7.0_515.43.04_linux.run 下载完包之后，我们要按照第二条命令装CUDA，但是在安装这个之前，你需要安装一下gcc的环境，不然就会缺少依赖报错：
1 2 3 4 $ sudo apt update $ sudo apt install gcc # 顺便安装一下g++ $ sudo apt install g++ 安装cuda包：
1 $ sudo sh cuda_11.7.0_515.43.04_linux.run 安装过程中间会跳出Abort和continue的选项，不要理会，选择continue。
后续又会跳出接受不接受，选择accept，之后便会跳出需要install的选项，盗用一下别人的截图： 需要注意上述出现的Driver是CUDA11.7配套的驱动，但不一定适合显卡，但只需要我们的Driver版本比它高，都是可以用的。选中Driver，按空格去掉x，然后再选择install。
CUDA环境变量配置
打开终端，输入：
1 $ gedit ~/.</description>
    </item>
    
    <item>
      <title>Jetson Nano算法部署实战</title>
      <link>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/jetson-nano%E7%AE%97%E6%B3%95%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/</link>
      <pubDate>Wed, 31 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/jetson-nano%E7%AE%97%E6%B3%95%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/</guid>
      <description>Jetson Nano算法部署实战 硬件和环境准备 Jetson Nano B01开发板 CSI摄像头模块 Wifi模块 我选择的是亚博智能的wife进阶套餐开发套件，TF卡自带镜像，自带一些所需的Package:
deepstream-app version: 6.0.1 DeepStream SDK: 6.0.1 JetPack: 4.6 Python: 3.6.9 CUDA Driver version: 10.2 CUDA Runtime version: 10.2 TensorRT version: 8.2 cuDNN version: 8.2 ONNXRuntime-gpu: 1.6.0(自行下载) ONNXRuntime-gpu的下载：Jetson Nano为arm64架构，ONNXRuntime-gpu不能直接通过pip下载，需要手动编译。好在官方已经帮我们完成了，需要根据Jetpack版本和Python版本进行选择！ 下载地址
下载完成之后，打开Terminal,进入下载地方的地址，使用pip安装：
1 $ pip3 install https://nvidia.box.com/shared/static/49fzcqa1g4oblwxr3ikmuvhuaprqyxb7.whl 连接工具 我们需要在Jetson Nano内部写代码，需要使用较为方便的编辑器，我这里选择的是vscode远程连接Jetson Nano。
vscode远程配置连接：
首先在vscode中添加扩展Remote - SSH 启动Jetson Nano，并连接wifi，打开Terminal输入ifconfig，将最下方的ip地址记下。 在PC端的Remote - SSH连接到刚刚的IP地址，并输入Jetson Nano账户和密码（亚博智能的为 账户：Jetson 密码：yahboom）需要注意的是PC和Jetson Nano必须连接到同一个wifi。 在vscode端为jetson nano内部配置Python扩展。 文件传输工具，因为我使用的是MAC端，所以我使用Transmit工具，连接方式和vscode连接是一样的。 算法准备 关于算法你需要的文件就只有一个ONNX文件，因为ONNX既包含了模型的权值参数也包含了计算图。我在这里使用的算法是我开发的脐橙缺陷检测分割算法FastSegFormer-P。
ONNX文件导出（需要pth文件）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #--*-- coding:utf-8 --*-- import torch from models.</description>
    </item>
    
    <item>
      <title>NVIDIA官方教程：第一节</title>
      <link>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/tensorrt%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B_1/</link>
      <pubDate>Wed, 17 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/tensorrt%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B_1/</guid>
      <description>TensorRT简介 TensorRT是用于高效实现已经训练好的深度学习模型的推理过程的SDK。 TensorRT内含推理优化器和运行时环境。 TensorRT使Deep Learning模型能以更高的吞吐量和更低的延迟运行。 包含C++和python的API，完全等价可以混用。 一些reference： TensorRT文档:https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html C++ API文档:https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/index.html python API文档:https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/index.html TensorRT下载:https://developer.nvidia.com/nvidia-tensorrt-download 该教程配套代码:https://github.com/NVIDIA/trt-samples-for-hackathon-cn/tree/master/cookbook
TensorRT基本特性 TensorRT的基本流程 示例代码
基本流程：
构建期： 建立Buider（构建引擎器） 创建Network（计算图内容） 生成SerializedNetwork（网络的TRT内部表示） 运行期： 建立Engine和Context Buffer相关准备（Host端 + Device端 + 拷贝操作） 执行推理（Execute） TensorRT工作流 使用框架自带的TRT接口(TF-TRT、Torch-TensorRT) 简单灵活、部署仍然在原框架中，无需书写插件。 使用Parser(TF/Torch/&amp;hellip; -&amp;gt; ONNX -&amp;gt; TensorRT) 流程成熟，ONNX通用性好，方便网络调整，兼顾性能效率 使用TensorRT原生API搭建网络 性能最优，精细网络控制，兼容性最好 使用TensorRT API搭建 下面是一个API完整搭建一个MNIST手写识别模型的示例： 示例代码
由于我没有学过Tensorflow，我也不会使用该框架去实现，未来应该只选择Parser的方式实现，这里只做了解。
基本流程：
1.Tensorflow中创建并训练一个网络 2.提取网络权重，保存为para.npz 3.TensorRT中重建该网络并加载para.npz的权重 4.生成推理引擎 5.用引擎做实际推理 用一张图来表示TensorRT使用的通用流程： 其中黄色部分文字是API创建方式特有的步骤，Parse将用onnx来代替。
构建阶段介绍 Logger日志记录器 1 2 3 # 可选参数：VERBOSE，INFO，WARNING，ERROR，INTERNAL_ERROR， # 产生不同等级的日志 ，由详细到简略。 logger = trt.Logger(trt.Logger.VERBOSE) Builder引擎构建器 1 2 3 4 # 常用成员：Builder.</description>
    </item>
    
    <item>
      <title>服务器深度学习环境</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Wed, 17 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/</guid>
      <description>深度学习环境搭建 租用云GPU服务 这里我使用的是AutoDL，主要是价格比较便宜。
在租用GPU时，要注意所需项目的环境，特别是Pytorch和CUDA版本。服务器可以选择你需要的环境，如果没有你想要的环境，可以只选择Miniconda环境，选择一个使用的Unbantu和Python版本，然后自行下载需要的环境。
vscode连接服务器 打开vscode，下载Remote - SSH插件。 打开最左边的Remote - SSH模块，点击+，添加远程ssh登录指令，并输入AutoDL实例页面的登录指令，并按回车，再次按回车写入配置文件。 点击右下角的connect，然后输入AutoDL示例页面提供的密码，回车，成功连接。 在vscode的插件商店中选择Python,并为服务器端下载插件。 在vscode中按下command+shift+p，输入python，选择Python: Select Interpreter，选择服务器中自动配置好的base环境。如果在配置实例时只选择了Miniconda，可以重新建立一个虚拟环境，安装Pytorch大礼包。 配置服务器免密登录 这里我使用的是Mac操作系统进行配置，Windows具体流程相似。
操作流程：
在本机创建新的ssh key: 1 2 $ cd ~/.ssh $ ssh-keygen -t rsa -C &amp;#34;ssh key的注释&amp;#34; 此时在.ssh目录下就会生成两个文件id_rsa和id_rsa.pub，分别是私钥和公钥。
复制公钥的内容到服务器端/root/.ssh目录下的authorized_keys（有时也是authorized_keys2）: 1 2 $ cat ~/.ssh/id_rsa.pub $ # 然后选中复制，并粘贴到服务器端的目标位置 配置完成之后，本地进入服务器端就不需要一直输ssh密码了。 上传文件 如果我们的文件可以在Github中找到，直接使用Terminal进行克隆： 1 $ git clone 你的repo的https地址 如果文件在本机，可以直接将文件拖拽到vscode目录下，也可以通过实例进入JupyterLab上传文件。 谷歌Colab白嫖GPU资源 首先登录Colab官网，点击新建笔记本，点击代码执行程序，点击下拉列表里的更改运行时类型，选择GPU，保存。然后就可以开心地白嫖了！
修改Linux服务器文件权限问题 将文件设置为可读写执行权限： 1 $ chmod 777 file 给文件所有者增加写权限： 1 $ chmod u+w file 给文件所有者和同组用户赋予读写权限，其他用户只有读权限： 1 $ chmod 664 file 递归修改目录及其子目录中的文件权限： 1 $ chmod -R 755 directory 显示修改后的权限信息： 1 $ chmod -v 755 file 请注意，修改文件或目录的权限需要有足够的权限进行操作。只有文件或目录的所有者或超级用户(root)才能更改权限。</description>
    </item>
    
    <item>
      <title>TensorRT动态Batch和动态宽高的实现</title>
      <link>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/%E5%8A%A8%E6%80%81batch%E5%92%8C%E5%AE%BD%E9%AB%98/</link>
      <pubDate>Tue, 16 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/%E5%8A%A8%E6%80%81batch%E5%92%8C%E5%AE%BD%E9%AB%98/</guid>
      <description>TensorRT之动态Batch和动态宽高 动态Batch 该特性的需求主要源于TensorRT编译时对batch的处理，若静态batch则意味着无论你有多少图，都按照固定大小batch推理。耗时是固定的。
实现动态Batch的注意点：
1.onnx导出模型是，注意view操作不能固定batch维度数值，通常写-1。 2.onnx导出模型是，通常可以指定dynamic_axes（通常用于指定动态维度），实际上不指定也没关系。
动态宽高 该特性需求来自onnx导出时指定的宽高是固定的，TensorRT编译时也需要固定大小引擎，若你想得到另外一个不同大小的TensorRT引擎（一个eng模型只能支持一个输入分辨率）时，就需要动态宽高的存在。而直接使用TensorRT的动态宽高（一个eng模型能支持不同输入分辨率的推理）会带来不必要的复杂度，所以使用中间方案：在编译时修改onnx输入实现相对动态（一个onnx模型，修改参数可以得到不同输入分辨率大小的eng模型），避免重回Pytorch再做导出。
实现动态宽高的注意点：
1.不建议使用dynamic_axes指定Batch以外的维度为动态，这样带来的复杂度太高，并且存在有的layer不支持。 2.如果onnx文件已经导出，但是输入的shape固定了，此时希望修改onnx的输入shape： 步骤一：使用TRT::compile函数的inputsDimsSetup参数重新定义输入的shape。 步骤二：使用TRT::set_layer_hook_reshape钩子动态修改reshape的参数实现适配。
动态Batch demo：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 int max_batch_size = 5; /** 模型编译，onnx到trtmodel **/ TRT::compile( TRT::Model::FP32, max_batch_size, //最大batch size &amp;#34;model_name.onnx&amp;#34;, &amp;#34;model_name.fp32.trtmodel&amp;#34; ); /** 加载编译好的引擎 **/ auto infer = TRT::load_infer(&amp;#34;model_name.fp32.trtmodel&amp;#34;); /** 设置输入的值 **/ /** 修改input的0维度为1，最大可以是5 **/ infer-&amp;gt;input(0)-&amp;gt;resize_single_dim(0, 2); infer-&amp;gt;input(0)-&amp;gt;set_to(1.0f); /** 引擎进行推理 **/ infer-&amp;gt;forward(); /** 取出引擎的输出并打印 **/ auto out = infer-&amp;gt;output(0); INFO(&amp;#34;out.</description>
    </item>
    
    <item>
      <title>TensorRT部署方案介绍</title>
      <link>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/tensorrt%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</link>
      <pubDate>Thu, 11 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/tensorrt%E9%83%A8%E7%BD%B2/tensorrt%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</guid>
      <description>TensorRT部署方案介绍 为每个模型写硬代码（c++） 仓库地址:https://github.com/wang-xinyu/tensorrtx
看图可知，也就是通过c++源代码直接调用TensorRT API，对每个不同的网络模型进行重写，再调用TensorRT Builder生成TensorRT Engine。
原理：
1.使用作者定义的gen_wts.py的存储权重。 2.使用C++硬代码调用TensorRT C++API构建模型，加载gen_wts.py产生的权重组成完整模型。
优点：
1.可以控制每个layer的细节和权重，直接面对TensorRT API。 2.这种方案不存在算子问题，如果存在不支持的算子可以自行增加插件。
缺点：
1.新模型需要对每个layer重写C++代码。 2.过于灵活，需要控制的细节多，技能要求很高。 3.部署时无法查看网络结构进行分析和排查。
为每个算子写Converter 仓库地址:https://github.com/NVIDIA-AI-IOT/torch2trt
原理：
1.作者为每一个算子（比如ReLU，Conv等），为每一个操醉的forward反射到自定义函数 2.通过反射torch的forward操作获取模块的权重，调用Python API接口实现模型
优点：
1.直接集成了Python、Pytorch，可以实现Pytorch模型到TensorRT模型的无缝转换。
缺点：
1.提供了Python的方案并没有提供c++的方案。 2.新的算子需要自己实现converter，需要维护新的算子库 3.直接用Pytorch赚到tensorRT存储的模型是TensorRT模型，如果跨设备必须在设备上安装pytoch，灵活度差，不利于部署。 4.部署时无法查看网络结构进行分析和排查。
基于ONNX路线提供C++和Python的接口 仓库地址:https://github.com/shouxieai/tensorRT_Pro
原理：
通过Pytorch官方和NVIDIA官方对torch-&amp;gt;onnx和onnx-&amp;gt;TRT算子库的支持。
优点：
1.集成工业级推理方案，支持TensorRT从模型导出到应用到项目中的全部工作 2.案例有YoloV5、YoloX、AlphaPose、RetinaFace、DeepSORT等，每个应用均为高性能工业级。 3.具有简单的模型导出方法和onnx问题的解决方案 4.具有简单的模型推理接口，封装tensorRT细节。支持插件。 5.依赖onnx，有两大官方进行维护。
缺点：
onnx存在各种兼容性问题。
如何正确导出onnx（避坑指南） 1.对于任何用到shape、size返回值的参数时，例如tensor.view(tensor.size(0), -1)，避免直接使用tensor.size的返回值，而是加上int转换，tensor.view(int(tensor.size(0)), -1)。（这里的tensor值的是一个具体的张量） 2.对于nn.Upsample或者nn.fucntional.interpolate函数，使用scale_factor指定倍率，而不是使用size参数指定大小。 3.对于reshape、view操作时，-1请指定到batch维度，其他维度计算出来即可。 4.torch.onnx.export指定dynamic_axes参数，并只指定batch维度，不指定其他维度。我们只需要动态batch，相对动态的宽高有其他方案。 这些做法的必要性体现在简化过程的复杂度，去掉gather、shape类的节点。
Example：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import torch import torch.</description>
    </item>
    
    <item>
      <title>推理框架ONNX Runtime</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/onnx%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Wed, 10 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/onnx%E9%83%A8%E7%BD%B2/</guid>
      <description>ONNX ONNX简介 目前我们熟知的Pytorch，Tensorflow和PaddlePaddle等深度学习框架是专门用于深度学习网络的框架。模型训练好之后会导出模型的权值文件，使用Pytorch导出 的文件一般以.pt或者.pth结尾的文件，他们可以在Pytorch框架上进行推理。根据训练和部署分离的原则，如果采用Pytorch框架进行训练，如何使用其他的框架进行 推理。这就需要使用万金油文件格式onnx。
两张图感受onnx的作用
可以看到使用了onnx中间格式后，极大地降低了部署的难度。
ONNX权值文件导出 在Pytorch训练完一个模型后，可以通过onnx将.pth和.pt文件转化为onnx格式。
首先需要先下载对应的Package:Pytorch，ONNX，ONNX Runtime：
1 2 3 4 5 6 # 安装Pytorch !pip3 install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113 # 安装ONNX !pip install onnx -i https://pypi.tuna.tsinghua.edu.cn/simple # 安装ONNX Runtime(cpu) !pip install onnxruntime -i https://pypi.tuna.tsinghua.edu.cn/simple 准备好训练完成的模型权值文件，进行ONNX导出，这里使用分割模型进行演示：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import torch import onnx # 定义要使用的设备 device = torch.</description>
    </item>
    
    <item>
      <title>Python中的import</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E7%9F%A5%E8%AF%86%E6%9D%82%E8%B0%88/python%E4%B8%AD%E7%9A%84import/</link>
      <pubDate>Sat, 06 May 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E7%9F%A5%E8%AF%86%E6%9D%82%E8%B0%88/python%E4%B8%AD%E7%9A%84import/</guid>
      <description>Import的常用方法 最初的项目相关的代码都在Windows系统下运行，写这个也是因为了在Linux系统下运行代码的需求。我们会发现在Pycharm里能运行的代码，在Linux下就会报错，大部分错误都来自import的错误。
场景及使用方法 绝对路径import Note：在Python3的新版本中文件夹下面不需要__init__.py这个文件，也可以视为一个Package，不过也可以用该文件来实现一些额外的功能。
在下面的例子中大写字母开头的英文代表文件夹，小写字母开头的代表文件。
同级目录下的单个脚本引用 目录：
ROOT- example.py- test.py 如果你想要在test.py文件中引用example.py的方法，你可以使用以下的代码：
1 2 3 4 5 6 # 引入example.py中的所有内容作 import test # 引入example.py中的方法 from test import &amp;#39;方法名&amp;#39; # 使用.引入的文件中的类 x = test.Class_A 同级目录下的单个文件夹引用 目录:
ROOT- Package-- example.py- test.py 如果想要在test.py中引入Package整个包，你可以使用如下代码：
1 2 3 4 5 6 7 8 # 引入整个包 import Package # 引入包中的一个文件 import Package.example # 这样import的方式会让Package这个文件夹加入系统的路径 # 将某个文件赋值给某个变量 import Package.example as ep # 这样ep的内容就变成了example这个文件 # 从Package里引入某个文件中的某个方法或者类 from Package.</description>
    </item>
    
    <item>
      <title>分割网络模型量化技术</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Mon, 20 Mar 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF/</guid>
      <description>分割模型量化技术 本文主要介绍的内容如下：
提高网络推理效率的基本技术 轻量化实时分割网络常用的架构 知识蒸馏 文中涉及的部分代码全部使用Pytorch框架实现。
本文的大部分内容来自于综述文章（On Efficient Real-Time Semantic Segmentation: A Survey）
提高网络推理效率的基本技术 本节将从以下几个方面来介绍：
采样技术 高效卷积技术 残差连接/跳过连接 轻量化骨干网络 采样技术 采样技术是减少推理延迟最常用的手段，采样分为上采样和下采样。
下采样可以用来降低图像的分辨率，在大型网络中广泛使用，来增加深层卷积核的接受场。通常在网络早期对图像进行下采样可以显著减少网络的推理延迟，在深层网络进行下采样也可以更好地提取高分辨率的细节。
常用的下采样方式有两种，一是使用最大池化层，二是使用步进卷积：
最大池化将图像分为若干个池化子区域，在每个区域中取最大的像素值。 步进卷积则通过调整步幅大小来调整图片的大小： 根据输入图像的大小$W\times W$，卷积核的大小$F\times F$，步长$S$，填充的数量$P$来计算输出图像的大小 $$W_{out} = \lvert\frac{W - F + 2P}{S}\rvert+1$$
1 2 3 4 5 6 import torch.nn as nn # 最大池化层(以下采样2倍为例) maxpooling = nn.MaxPool2d(kernel_size=2) # 步进卷积（以3*3卷积下采样2倍为例） conv_downsample = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=0) 上采样的主要目的是为了重建输入分辨率的图像，上采样的方法主要有三种：
最近邻插值 双线性插值 转置卷积 从上到下计算代价越来越贵，采样效果也越来越好。
1 2 3 4 5 6 7 8 9 10 import torch import torch.</description>
    </item>
    
    <item>
      <title>VOC分割数据集制作</title>
      <link>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/voc%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/</link>
      <pubDate>Thu, 02 Mar 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/voc%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/</guid>
      <description>VOC格式数据集制作 Labelme安装 一般来说，Labelme标图软件包比较通用，可以直接安装在anaconda的base环境，在Terminal或者anaconda prompt中输入：
1 2 3 4 5 6 7 8 # 注意前面三项安装为labelme的依赖项。 conda install -c conda-forge pyside2 conda install pyqt pip install pyqt5 pip install labelme 如果安装不流畅，或者因为网络原因下载不下来可以换源：
pip换源：加-i https://pypi.tuna.tsinghua.edu.cn/simple, 这里加的清华源 conda焕源： 1 2 3 4 5 6 7 # 加的都是中科大的镜像源 conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.</description>
    </item>
    
    <item>
      <title>有限资源下的预训练方案</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%9C%89%E9%99%90%E8%B5%84%E6%BA%90%E4%B8%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%A1%88/</link>
      <pubDate>Thu, 13 Oct 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%9C%89%E9%99%90%E8%B5%84%E6%BA%90%E4%B8%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%A1%88/</guid>
      <description>其实有一个月没更新了！因为之前做的实验有了一丢丢成果，所以花了半个月时间写了一篇论文，试投了sci 4区的期刊，祝自己好运吧！
然后这是我新研究的方向就是swin transformer系列分割模型，先来做个最基本的工作！
有限资源下的预训练方案 最近在使用swin_Transformer的骨干网络模型做图像分割，但该骨干网络又十分依赖于预训练。
预训练的两种方案 第一种就是直接拿swin_Transformer的图像分类网络在ImageNet_1k和ImageNet_22k的数据集直接的预训练权重，直接载入你的模型和目标数据进行训练。（一般需要先锁权重让剩余的网络参数迭代一下，再解锁进行迭代）
第二种就是拿你组建好的图像分割模型在分割数据集（例如VOC2012BST，或者更大的ADE20k数据集）上进行预训练，然后将得到的权重加载到你的目标数据集上进行迭代。
swin_Transfomer的训练方案 首先先下载swin_Transformer的预训练权重，包括两个input_image_size(224$\times$224,384$\times$384)，4个model_size(Swin_T,Swin_S,Swin_B,Swin_L)都有在ImageNet1k和ImageNet22k的预训练权重。
预训练权重地址(在release的v1.0.0和v1.0.8):https://github.com/SwinTransformer/storage/releases/
首先构建分割网络，swin_TransUnet
Swin_transformer.py(对源码进行微调，加了3个输出特征图):
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 &amp;#34;&amp;#34;&amp;#34; Swin Transformer A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows` - https://arxiv.</description>
    </item>
    
    <item>
      <title>充分利用你的显存，智能调节学习率</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%E4%BD%A0%E7%9A%84%E6%98%BE%E5%AD%98/</link>
      <pubDate>Fri, 09 Sep 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%E4%BD%A0%E7%9A%84%E6%98%BE%E5%AD%98/</guid>
      <description>一些新手比较容易踩的坑 batch_size 大小设置 先讲batch_size的功效：
增大batch_size的大小，可以加快训练速度 增大batch_size的大小，可以使得你使用的batch normalization更稳定，训练效果最好。 副作用：
batch_size越大，需要的显存就越大 相信所有人都经历过cuda out of memory报错，让人很心烦！那原因真的一定是batch_size过大吗？
第一种情况，是在验证的时候，没有加with torch.no_grad()，在验证的时候是不需要梯度反向传播的！ 第二种情况是确实模型太大，超显存了。 相信小伙伴都遇到过第三种情况：你设batch_size为2还报out of memory，任务管理器里明明显示还有很多显存，那就需要注意你的num_worker数量了。 如果你的num_worker比较大的话，cpu多线程读取图片的速度是快于你的GPU速度的，这时候会增加你的显存。这和你的GPU以及CPU的性能都是有关的，需要合理设置！ 学习率设置 学习率设置太大，容易让模型训练不动 batch_size调大之后，学习率是需要相应调大的 调参的时候通常使用大的学习率先开始训练，如果模型收敛不了再调更小 训练的时候一般采用学习率衰减的方法防止过拟合，一般使用step步进或者是模拟余弦退火算法来控制学习率大小。 </description>
    </item>
    
    <item>
      <title>图像分割之迁移学习</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 02 Sep 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</guid>
      <description>Unet，Attention_Unet网络修改之替换主干网络 对于算力有限的机器来说，从零开始训练实际效果并不好。使用迁移学习的预训练权重对于缺少参数调优的机器的炼丹人是非常重要的！
为了使用预训练权重，就需要将特征提取网络替换成知名的主干网络，比如VGG，Resnet，mobilenet等
Unet的修改——特征提取网络替换成VGG Unet论文地址：https://arxiv.org/abs/1505.04597
为了使替换主干网络后，保持维度匹配，需要对网络结构进行修改。所以我重构了网络结构图：
代码如下：
vgg.py:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 import torch.</description>
    </item>
    
    <item>
      <title>图像分割的边角料</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E8%BE%B9%E8%A7%92%E6%96%99%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Sun, 21 Aug 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E8%BE%B9%E8%A7%92%E6%96%99%E7%9F%A5%E8%AF%86/</guid>
      <description>图像分割中的上采样方法 反最大池化的方法 在下采样中，我们通常采用最大池化的方法来进行。那么对应在上采样中，反最大池化的方法其实就是记住最大池化时得到像素在原图中的位置，将其他位置填充为0。如图所示：
最早的SegNet所使用的上采样就是这种方式！
转置卷积 第二种方法就是转置卷积,这种方法和前面的反最大池化方法的最大区别就是转置卷积的参数是可以用于学习训练的，它不是一个固定的策略！
这个图可能看的不是很准确，想看动图的可以访问PyTorch官方给出的动图
以3$\times$3的卷积核将2$\times$2变为4$\times$4的图像为例（没有填充，没有步幅）：
1.第一步就是要将2$\times$2的图像使用零padding成为一个6$\times$6（4+2*1得到）的图像
2.对该填充后的图像做3$\times$3的卷积，得到输出图像
在深度学习的论文中，出现反卷积/跨步卷积/上卷积其实指的就是这种转置卷积。
放一张一维的图用于理解：
指标计算 基本指标 在图像分割中的基本指标通常包括Global Acc、mean Acc、MIOU,``等指标。
Global Acc(Pixel Acc) = $\frac{\sum_in_{ii}}{t_i}$
mean Acc = $\frac{1}{n_{cls}}\sum_i\frac{n_{ii}}{t_i}$
MIOU = $\frac{1}{n_{cls}}\sum_i\frac{n_{ii}}{t_i+\sum_jn_{ji}-n_{ii}}$
$n_{ij}$:类别i被预测成为类别j的像素个数
$n_{cls}$:目标类别个数（包含背景）
$t_i=\sum_jn_{ij}$:目标类别i的总像素个数（真实标签）
通过混淆矩阵理解指标 直接看下面三个图就可以理解了：
实操 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 &amp;#39;&amp;#39;&amp;#39; 混淆矩阵 Recall、Precision、MIOU计算 &amp;#39;&amp;#39;&amp;#39; import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>图像分割入门</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/</link>
      <pubDate>Wed, 10 Aug 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/</guid>
      <description>图像分割 图像分割的分类 语义分割：可以将图片中不同类别的事物用不同的颜色分割出来，同一类的食物使用相同的颜色填充。 实例分割：在语义分割的基础上将同一类别的不同个体分割出来，使用不同的颜色填充。 语义分割如何做？ 语义分割是对图像中的每一个像素做语义判断，对逐个像素进行分类。
损失函数（c分类）： $$ loss=-\sum_{i=1}^c(w_cy\log(\hat{y}))\quad y代表真实值，\hat{y}代表预测值\ w_c=\frac{N-N_c}{N}\quad N代表总的像素个数，N_c代表类别为c的像素个数 $$
Focal loss： Focal loss用来解决难易不同的样本。在损失函数的基础上加入难易程度的奖励，识别准确率越高越容易，权重越低；识别准确率越低越难，权重越高。 $$ loss=-\sum_{i=1}^c(1-\hat{y})^{\gamma}y\log(\hat{y})\quad \gamma值一般取2 $$ 再将之前的样本比例权值$w_c$加上之后，损失函数为 $$ loss=-\sum_{i=1}^cw_c(1-\hat{y})^{\gamma}y\log(\hat{y})\quad $$
IOU计算 在多分类任务时：iou_dog = 正确预测为狗的数量/（真实的狗的数量 + 预测为狗的数量 - 正确预测为狗的数量） 在语义分割时：假设真实的图片标签为A，预测的图片为B，那么计算的公式：A和B的交集/A和B的并集。在多类别时，这个指标会变成MIOU：计算所有类别的平均值。 U-net系列 U-net U-net是一个典型的编码器解码器结构，编码器阶段进行特征提取和下采样（卷积和池化），解码器阶段进行上采样（插值）和特征拼接。模型结构如下：
缺点：进行特征拼接的时候，浅层特征离得比较远，上层拼接效果不佳。
U-net++ 首先看一下网络结构：
特点：在U-net的基础上，把能拼凑的特征全部都用上了。拼接的方式如上图，所有相邻的特征进行拼接。中间连线的部分是因为这部分的图像大小和输出图像大小一致，通过$1\times1$卷积将他们都作为预测的损失函数（也就是经常说的多输出）。
U-net++的优点：
可以更容易剪枝：比如我做到L4层的效果就很好，就可以将不需要的L5的上采样过程给去掉。
U-net+++ 直接看结构，也是在特征融合上下功夫：
DeepLab系列 感受野 假设一个$7\times7$的图片，通过2次$3\times3$的卷积操作，得到一个像素，那么这个像素的感受野就是$7\times7$的。那么感受野的概念其实就类似于当前计算出像素的值和前面原始图像的49个像素都有关。一个像素的感受野越大，那么它提取处的特征信息可能更加准确。
空洞卷积 为了增大感受野，我们通常的做法会采用下采样（也就是池化层），但是池化层有一个缺点是它会丢失一部分信息。
空洞卷积的提出为增大感受野提供了一种新的方法，空洞卷积的做法如下图：
空洞卷积的优势：
1.图像分割任务中需要较大的感受野来完成更好的任务
2.在Pytorch代码中之需要改变一个参数就可以了
3.扩大感受野时，参数的多少不不变的，计算代价没有变化
SPP层的作用 为了使卷积网络模型满足不同分辨率的要求，我们通常会使用spatial pyramid pooling layer达到这种效果。
在卷积网络中，卷积层通常不会对输入图像的分辨率由要求，但是在全连接层，会限制你图像输入的大小。SPP-Layer 的结构如下图：
不管输入的图像大小是多少，该层都把你分别16等分、4等分、分成1份，分别进行池化，再进行特征拼接。无论你的输入大小是多大，得到的结果都是一样的，这样就保障了我们的输出特征是固定的。
ASPP特征融合策略 ASPP其实是在SPP的策略基础上加入了不同倍率的空洞卷积。
其主要结构如下：
DeepLabV3+ 先看网络结构：
可以看到在特征融合层ASPP之前，有一个深度卷积网络（DCNN），这里一般选用市场上效果比较好的特征提取网络。整个网络是一种编码器和解码器的结构，解码器通过DCNN中提取的浅层特征（局部特征）和经过上采样的融合特征（考虑全局的特征）做拼接，再经过一次卷积核一次上采样（插值法）得到输出结果。注意：特征融合层采用不同倍率的空洞卷积来完成。</description>
    </item>
    
    <item>
      <title>深度学习笔记（10-11节） </title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-11%E8%8A%82/</link>
      <pubDate>Fri, 29 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-11%E8%8A%82/</guid>
      <description>深度学习（10-11节） 卷积操作 计算机视觉的例子：
图片分类 目标检测 神经网络实现图片转化迁移 但因为图片的像素高时，每张图片都很是一个很大的维度，如何处理大量的高像素图片呢？这可能就要用到卷积神经网络了。
边缘检测示例 我们通过边缘检测的例子来看卷积操作是如何进行的。
在边缘检测的例子里，卷积核从左到右每列为{1, 1, 1},{0, 0, 0},{-1, -1, -1}。
如图所示，左边是一个6$\times$6的矩阵，中间是一个3$\times$3的卷积核，”*“代表的是卷积操作，但在Python中一般代表乘积的操作，需要注意区分。将卷积核与左边颜色加深的矩阵一一对应相乘后再相加，得到右边绿色的数值。让卷积核在模板上进行移动卷积，可以得到一个4$\times$4的矩阵。假设原图像的维度为m$\times$n，卷积核的大小为a$\times$a，那么得到的矩阵大小为(m-a+1)$\times$(n-a+1)。
对应编程的函数：
python：conv_forward
tensorflow：tf.nn.conv2d
PyTorch：torch.nn.Conv2d
再举个更加明显的例子，如下图：
可以看到很明显的就是，如果左边的图片没有变化，与卷积核进行卷积就会得到0，如果选取的区域图片有变化，那么得到的结果就有正值。上述的过程看一看成如下示意图：
将最左边的变化的部分在最右边得到的结果显现出来。
更多的边缘检测内容 在上节例子中的卷积核可以为我们检测由亮到暗的一个过渡的过程，如果是由暗到亮，那么输出的就是负值。
如果我们把上节检测垂直边缘的卷积核旋转一下，从第一行到第三行分别是{1, 1, 1},{0, 0, 0},{-1, -1, -1}，这就变成了一个水平的边缘检测。
列举几个3$\times$3滤波器：
Sobel滤波器：第一列到第三列分别为：{1, 2, 1},{0, 0, 0},{-1, -2, -1}。 Scharr滤波器：第一列到第三列分别为：{3, 10, 3},{0, 0, 0},{-3, -10, -3}。 Padding 在进行卷积的过程中，会发现很容易将图像最边缘的部分给忽略掉。一般的做法是在进行卷积之前，会在周围再填充一层像素，这样m$\times$n的矩阵就变成了(m+2)$\times$(n+2)的矩阵，这样在每层神经网络里进行卷积，不会损失掉边缘的特征。
填充一层就代表padding=1，填充两层代表padding=2&amp;hellip;
Valid卷积，其卷积过程如下： $$ n\times n\quad*\quad f\times f\xrightarrow{no\quad padding}(n-f+1)\times (n-f+1) $$
Same卷积，顾名思义就是卷积前后的大小是相同的，其卷积过程如下： $$ n\times n\quad*\quad f\times f\xrightarrow[p=\frac{f-1}{2}]{padding=p}n\times n\ f=2p+1,所以我们的f只取奇数 $$
上述过程中所有填充的像素一般使用0来填充！</description>
    </item>
    
    <item>
      <title>PyTorch入门</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/pytorch%E5%85%A5%E9%97%A8/</link>
      <pubDate>Thu, 28 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/pytorch%E5%85%A5%E9%97%A8/</guid>
      <description>PyTorch学习笔记 PyTorch安装及环境配置 conda环境安装 这里我们使用的anaconda，目前它也已经适配了apple芯片。所以我在我的M1 Pro的电脑上将miniforge3的方案替换成了anaconda3。官网：https://www.anaconda.com/
Windows端无需多说，苹果端如果是apple芯片，选择M1版本，如果是intel芯片，选择普通版本。
下载完成之后安装，需要配置一下环境变量（MacOS）。
首先进入根目录，并配置环境变量：
1 2 &amp;gt; cd ~ &amp;gt; vim ~/.zshrc 在配置文件中加入一行：
1 2 3 export PATH=&amp;#34;/Users/caixiongjiang/opt/anaconda3:$PATH&amp;#34; # 其中caixiongjiang是你的用户名 # vim中按i进行编辑模式，按Ese推出编辑模式，在普通模式下输入“:wq”表示保存并退出 启动环境配置，并配置国内镜像源：
1 2 3 4 5 6 7 8 &amp;gt; source ~/.zshrc &amp;gt; conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ &amp;gt; conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ &amp;gt; conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ &amp;gt; conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ &amp;gt; conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ &amp;gt; conda config --add channels https://mirrors.</description>
    </item>
    
    <item>
      <title>深度学习笔记（8-9节） </title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08-9%E8%8A%82/</link>
      <pubDate>Mon, 25 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08-9%E8%8A%82/</guid>
      <description>深度学习（8-9节） 网络模型的优化 ML策略 当你采用一个分类器，得到的准确率为90%，如何提高它的准确率呢？以下有这么多的方法可以使用：
收集更多的数据 提高训练集的多样性（反例集） 尝试使用优化算法 使用规模更大或者更小的网络 使用正则化 修改网络结构 修改激活函数 改变隐藏层单元的数目 &amp;hellip; 修改的方法有很多，但是需要选择一个正确的并不容易。
正交化 如果将神经网络比作一个可调节的电视机，调整电视机的各种按钮来改变电视机的布局，色彩，亮度就如同在神经网络中调整各种超参数来查看神经网络的效果。
对于一个电视来说，我们需要慢慢调整（一个开关一个开关调整）才能将电视机调好，那么这种一个超参数调整，只能改变其神经网络的某个性质的形式就叫做正交化。
单一数字评估指标 理解一下两个概念，Precision和Recall。
Precison：中文为查准率，预测为真的模型中，有多少样本是真的，它的占比值。对于一个猫分类器来说就是，模型预测为猫的类型样本中，有多少占比为真正的猫。
Recall:中文为召回率，对于所有样本标签为真的情况下，有多少占比是你的模型正确预测出来的。对于一个猫分类器来说就是，在所有标签为真猫的样本中，有多少占比是你的模型正确预测的。
对于一个分类器来说，两个指标都同等重要，所以我们需要找到一个结合查准率和召回率的指标，也就是所谓的F1分数，公式如下： $$ F1=\frac{2}{\frac1p+\frac1R}\ 其中p代表查准率，R代表召回率，计算方式在数学上称为调和平均数 $$ 这样算出来的F1分数来判断网络的性能更加合理，称这种形式为单一数字评估指标。
再举一个例子，如下图：
算法在不同地区的错误率都不同，无法统一进行比较，那我们就将其整合为一个值，就是做平均之后再做比较。
满足和优化指标 对于某些多个指标的情况，我们想建立单一实数评估指标是非常困难的。比如，准确率和运行时间，想要合并为一个成本指标是很困难的，因为我们并不知道两个指标哪个更重要，或者说两个指标之间的关联性。所以我们可以采用满足和优化指标，在该例中就是在满足运行时间在多少毫秒之内，优化准确率，这样就可以找到最优的那个算法。
划分训练/开发/测试集 划分dev/test sets： 假设你要开发一个猫分类器，需要在不同区域进行运营：美国，英国，中国，印度，澳大利亚等。你如何设立开发集和测试集呢？
如果你在8个区域中随机选取4个区域作为开发集，4个区域作为测试集，效果可能是非常糟糕的。我们选取的原则是让开发集和测试集尽量来自同一分布。所以我们的做法一般是将所有数据随机洗牌，放入开发集和测试集，这样开发集和测试集都有来自8个区域的数据。
开发集和测试的大小： 在机器学习中，会有一条七三分的比例划分训练集和测试集，如果有开发集，则会按照6:2:2的比例来划分训练集，开发集，测试集。但在如今的数据量在百万级别的情况下，这样做会更加合理：98%作为训练集，1%开发集，%1测试集。
训练集，开发集和测试集的目的： 开发集是为了指定产品的优化目标，训练集决定了你向优化目标迭代的速度，测试集是为了评估投产系统的性能。
何时改变开发_测试集和指标 假设一个猫分类器，使用了算法A和算法B，它们都分别采用分类错误率来衡量算法的性能。算法A的错误率为3%，算法B的错误率为5%，但是算法A在错误分类的图片里，将色情图片分为了猫的图片，这是用户不能接受的。所以在这种情况下，即使你的算法在开发集上的指标更好，依然被认为是不好的产品。当你的指标错误地预测算法，就是你需要修改开发_测试集和指标的时候。
那么如何修改指标？
我们可能会对目标错误率设置一个$W$来赋予不同的图片以不同的权重： $$ W^{(i)}=\begin{cases} 1,&amp;amp;如果x^{(i)}不是色情图片\ 10,&amp;amp;如果x^{(i)}是色情图片 \end{cases} $$ 需要注意的是在目标函数上加上$W$，也需要修改归一化常数
贝叶斯误差和可避免偏差 假设一个两个不同的模型，在训练集和开发集上的错误率如下：
一个问题的错误率是有一个贝叶斯误差（理论最小误差），在大多数时候人类识别的错误率是接近贝叶斯误差的。
问题1的错误率 问题2 训练集 8% 8% 开发集 10% 10% 人类错误率相近 1% 7.5% 在训练集和人类错误率之间的差值被称为可避免偏差，训练集和开发集之间的误差被认为是需要更加优化方差。问题1，训练集与人类错误率相差较远，是训练欠拟合，可以加大训练网络或者迭代时间等来缩小；问题2中的训练集8%和测试集10%，略微过拟合，可以用正则化来降低拟合程度。
那么如果要把人类错误率作为贝叶斯错误的替代，该如何定义人类错误率呢？
假设一个医学图像分类的例子：
普通的人类在该任务上达到了3%的错误率。
普通的医生能达到1%的错误率</description>
    </item>
    
    <item>
      <title>深度学习笔记（6-7节） </title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-7%E8%8A%82/</link>
      <pubDate>Fri, 22 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06-7%E8%8A%82/</guid>
      <description>深度学习（6-7节） 优化算法 Mini-batch梯度下降法 假设我们的样本数量为500w个，那么在进行梯度下降之前，我们需要先将500w个数据整合成一个大的向量$X$。Mini-batch的做法为将500w个样本按照每个子集为1000个样本等分。每个子集标记为$X^{\left{ 1\right} }X^{\left{ 2\right} },\dots,X^{\left{ 5000\right} }$。相应的，除了需要拆分$X$，也需要拆分标签$Y$，拆分的方法和$X$相同。
Mini-batch的原理是将同时原本对所有样本和标签同时进行梯度下降转变为同时只对一个子集进行梯度下降处理，处理5000次。需要注意代价函数也要改变，因为每次训练的样本个数改变了。
当你的训练集大小很大的时候，mini-batch梯度下降法比batch梯度下降法运行地更快。
batch梯度下降法和Mini-batch梯度下降法的代价随迭代的图像如下：
右边的图像出现波动的原因是：每次实现梯度下降的样本集不同，可能$X^{\left{ 1\right} }$和$Y^{\left{ 1\right} }$需要花费的代价更大，而$X^{\left{ 2\right} }$和$Y^{\left{ 2\right} }$花费的代价更少，从而形成一个噪声的现象。
那么mini-bash的大小如何决定呢？
先看两种极端情况：
如果子集的大小为m，那么mini-bash梯度下降就变成了batch梯度下降；
如果子集的大小为1，那么mini-bash梯度下降就变成了随机梯度下降法，每个样本都是一个子集；
batch梯度下降每次下降的噪声会小一点，幅度会大一点（这里的噪声是指梯度下降的方向偏离目标）；而随机梯度下降大部分时间会向着全局最小值逼近，但有时候会远离最小值（刚好该样本是一个&amp;rsquo;&amp;lsquo;坏&amp;rsquo;&amp;lsquo;样本），随机梯度下降法永远不会收敛，而是会一直在最小值附近波动。
batch梯度下降在训练数据很大的时候，单次训练迭代时间过长，如果训练数据量较小的情况下效果较好；而随机梯度下降单次迭代很快，但却无法使用向量化技术对运算进行加速。我们的目的就是选择一个不大不小的size，使得我们的学习速率达到最快（梯度下降）。
最优的情况就是，单次选取的size大小的数据分布比较符合整体数据的分布，这样使得学习速率和运行效率都比较高。
指数加权平均 指数加权平均也称指数加权移动平均，通过它可以来计算局部的平均值，来描述数值的变化趋势，下面通过一个温度的例子来详细介绍一下。
上图是温度随时间变化的图像，我们通过温度的局部平均值（移动平均值）来描述温度的变化趋势，计算公式如下： $$ v_t=\beta v_{t-1}+(1-\beta)\theta_{t}\ v_0=0\ v_1=0.9v_0+0.1\theta_1\ v_2=0.9v_1+0.1\theta_2\ \theta 代表当天的温度，v代表局部平均值 $$ 当$\beta$为0.9时，可以将$v_t$看作$\frac{1}{1-\beta}=\frac{1}{1-0.9}=10$天的平均值。
当$\beta$变得越小，移动平均值的波动越大。
通过上面的公式往下推到，可以得到$v_{100}$的表达式： $$ v_{100}=0.1\times\theta_{100}+0.1\times0.9\times\theta_{99}+\dots+0.1\times0.9^{99}\times\theta_1\ =0.1\times\sum_{i=1}^{100}0.9^{100-i}\times\theta_i $$ 当$\epsilon=1-\beta$时，$(1-\beta)^{\frac{1}{\epsilon}}\approx\frac{1}{e}\approx\frac{1}{1-\beta}$，所以可以将$v_t$看作$\frac{1}{1-\beta}=\frac{1}{1-0.9}=10$天的平均值。
简单来说，普通的加权求平均值的方法每一项的权重是$\frac{1}{n}$，指数加权平均每一项的权重是指数递减的。
指数加权平均的偏差修正 由于我们初始设置的$v_0$为0，这样会使前面几个$v_1,v_2\dots$的值与实际值相比偏小，我们通常会采取以下的办法来修正偏差： $$ v_t=\frac{\beta v_{t-1}+(1-\beta)\theta_t}{1-\beta^t} $$ 这样修正的效果为随着t的增加，分母越来越接近1。相当于时间越短，修正的幅度越大，所以这个公式主要是为了修正早期的偏差。
动量梯度下降法 我们将上面所说的指数加权平均的做法应用于神经网络的反向传播过程，如下： $$ V_{dW}=\beta V_{dW}+(1-\beta)dW\ V_{db}=\beta V_{db}+(1-\beta)db\ W:=W-\alpha V_{dW},b:=b-\alpha V_{db} $$ 这样做可以减缓梯度下降的幅度，因为梯度下降不一定朝着最快的方向前进。如下图所示：
原本为蓝色的梯度下降会变成红色，纵轴摆动的方向变小了且上下摆动的幅度均值大概为0。这样一来，即使我增加学习率或者步长也不会出现紫色线这种偏离函数的情况。</description>
    </item>
    
    <item>
      <title>深度学习笔记（4-5节） </title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-5%E8%8A%82/</link>
      <pubDate>Tue, 19 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-5%E8%8A%82/</guid>
      <description>深度学习（4-5节） 多层的深层神经网络 神经网络的表示 1.L代表神经网络的层数（layers），不包括输入层，比如一个4层网络称为L-4
2.$n^{[l]}$代表$l$层上节点的数量，也可以说是隐藏单元的数量
3.$a^{[l]}$代表$l$层中的激活函数，$a^{[l]}=g^{[l]}(z^{[l]})$
深层网络中的前向传播 神经网络中每层的前向传播过程： $$ Z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}\ a^{[l]}=g^{[l]}(z^{[l]})\ l代表层数 $$ 如果需要计算前向传播的层数过多，可以使用for循环将它们串起来。
核对矩阵中的维数 如果我们在实现一个非常复杂的矩阵时，需要特别注意矩阵的维度问题。
通过一个具体的网络来手动计算一下维度：
可以写出该网络的部分参数如下： $$ n^{[0]}=n_x=2\quad n^{[1]}=3\quad n^{[2]}=5\quad n^{[3]}=4\quad n^{[4]}=2\quad n^{[5]}=1 $$ 由于前向传播的公式为： $$ Z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}\ a^{[l]}=g^{[l]}(z^{[l]}) $$
需要说明的是这里的维度都是只在一个样本的情况下。如果在m个样本的情况下，1都要变成m，但b的维度可以不变，因为通过python中的广播技术，b会自动扩充。
1.$b^{[1]}$的维度为$3\times 1$，所以$Z^{[1]}$的维度也是一样的，为$n^{[1]}\times 1$也就是$3\times 1$。
2.$X$的维度为$n^{[0]}\times 1$，也就是$2\times 1$
所以通过1,2两条可以推出$W^{[1]}$的维度为$n^{[1]}\times n^{[0]}$，也就是$3\times 2$。
可以总结出来的是： $$ W^{[l]}的维度一定是n^{[l]}\times n^{[l-1]}\ b^{[l]}的维度一定是n^{[l]}\times 1 $$ 同理在反向传播时： $$ dW和W的维度必须保持一致，db必须和b保持一致 $$ 因为$Z^{[l]}=g^{[l]}(a^{[l]})$，所以$z$和$a$的维度应该相等。
参数vs超参数 参数（Parameters）：$W^{[1]},b^{[1]},W^{[2]},b^{[2]},\dots$
超参数：学习率$a$；迭代次数$i$ ；隐层数$L$；隐藏单元数$n^{[l]}$；激活函数的选择。
作业三 一个神经网络工作原理的模型如下：
多层网络模型的前向传播和后向传播过程如下：
实现一个L层神经网络 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward import numpy as np # ------------------------------------------ def initialize_parameters_deep(layer_dims): &amp;#34;&amp;#34;&amp;#34; Arguments: layer_dims -- 包含网络中每一层的维度的Python List Returns: parameters -- Python参数字典 &amp;#34;W1&amp;#34;, &amp;#34;b1&amp;#34;, .</description>
    </item>
    
    <item>
      <title>深度学习笔记（1-3节） </title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-3%E8%8A%82/</link>
      <pubDate>Tue, 12 Jul 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01-3%E8%8A%82/</guid>
      <description>深度学习（1-3节） 深度学习介绍 线性整流函数（ReLU函数） 通常意义下，线性整流函数指代数学中的斜坡函数，即 $$ f(x)=max(0,x) $$ 而在神经网络中，线性整流作为神经元的激活函数，定义了该神经元在线性变换$W^Tx+b$之后的非线性输出结果。换言之，对于进入神经元的来自上一层神经网络的输入向量$x$，使用线性整流激活函数的神经元会输出 $$ max(0,W^Tx+b) $$ 到下一层神经元或作为整个神经网络的输出。
神经网络介绍 神经网络的基本模型是神经元，由输入层，隐藏层，输出层组成。最基本的神经网络是计算映射的，输入层为$x$，在实际上一般表现为特征，输出层为y，一般为结果，隐藏层其实就是上面所说的权向量$W^t$。
监督学习 监督学习也称为带标签的学习方式。监督学习是从标记的训练数据来推断一个功能的机器学习任务。训练数据包括一套训练示例。在监督学习中，每个实例都是由一个输入对象（通常为矢量）和一个期望的输出值（也称为监督信号）组成。
结构化数据vs非结构化数据 结构化数据指传统数据库中的数据，非结构化数据库是指音频，图片，文本等数据。
深度学习的准确率 取决于你的神经网络复杂度以及训练集的大小，一般来说神经网络越复杂时，需要的训练数据也越多，这样训练出来的模型效果也更好。
Sigmoid函数 sigmoid函数也叫Logistic函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。Sigmoid作为激活函数有以下优缺点：
优点：平滑、易于求导。
缺点：激活函数计算量大，反向传播求误差梯度时，求导涉及除法；反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。
Sigmoid函数的公式如下： $$ S(x)=\frac{1}{1+e^{-x}} $$ 函数图形如下：
深度学习基础 为了方便学习：
1.使用$(x,y)$来表示一个单独的样本
2.$x\in \R^{n_x}$代表$x$是$n_x$维的特征向量，$y\in {0,1}$代表标签$y$值为0或1
3.训练集由m个训练样本构成，$(x^{(1)},y^{(1)})$代表样本一，$(x^{(m)},y^{(m)})$代表最后一个样本m
4.$m=m_{train}+m_{test}$
5.构建神经网络时使用矩阵$X=\left[ \begin{matrix}|&amp;amp;|&amp;amp;&amp;amp;|\ x^{\left( 1\right) }&amp;amp;x^{\left( 2\right) }&amp;amp;\cdots &amp;amp;x^{\left( m\right) }\ |&amp;amp;|&amp;amp;&amp;amp;|\end{matrix} \right] $，$m$是训练集样本的个数。
6.输出标签时，为了方便，也将y标签放入列中，$Y=\left[ \begin{matrix} y^{\left( 1\right) }&amp;amp;y^{\left( 2\right) }&amp;amp;\cdots &amp;amp;y^{\left( m\right) }\end{matrix} \right] $,$Y\in\R^{1\times m}$
Logistic回归 Logistic回归通常用于二元分类问题。
它通常的做法是将sigmoid函数作用于线性回归： $$ \hat{y} =\sigma\left( W^{T}x+b\right)\quad \quad \text{其中} \sigma(z)=\frac{1}{1+e^{-z}} $$ 这会使得$\hat{y}$的范围在0~1之间</description>
    </item>
    
    <item>
      <title>第十三讲：heap&amp;priority_queue深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC13%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 28 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC13%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第十三讲：heap&amp;amp;priority_queue深入探索 heap概述 heap不是STL容器组件，它是扮演priority queue的助手。priority queue允许用户以任何次序将任何元素推入容器中， 但取出时一定是从优先权最高的元素开始取。binary max heap正具有这样的特性，适合作为priority queue的底层机制。
priority queue选用binary heap来实现，它是一种完全二叉树，也就是说除了最底层的叶子节点之外，是填满的，且 最底层的叶节点由左至右不能右空隙。因为整棵树没有任何节点漏洞，我们可以使用array来存储所有的节点。
binary heap是一颗完全二叉树，那么它就具备完全二叉树的特点：当某个节点位于array的i处，其左子节点必位于array的 2i处，其右子节点一定位于array的2i+1处，其父节点必定位于&amp;quot;i/2&amp;quot;处。
binary heap使用一个array（保存数据）和一组heap算法（用来插入元素、删除元素、取极值）。这种使用array表述 tree的方式，被称为隐式表达。
当然heap要能动态的改变大小，所以用vector存储数据会更好。
heap可以分为max-heap以及min-heap，前者每个节点的键值都大于或等于其子节点键值，后者的每个节点键值都小于或 等于其子节点键值。可以推出，max-heap的最大键值在根节点，min-heap的最小键值在根节点。
heap算法 push_heap算法 在很多书籍当中，通常通过一个上浮的操作来完成push_heap。其基本原理可见下图（假设新加入的元素是50）：
1.将50插入到数组的末尾。
2.将其于父元素相比较，发现24小于50，交换这两个元素。上浮一次
3.继续上述操作直到找到一个合适的位置，也即其父元素大于50的位置，则上浮结束。
一个简易的c++实现：
1 2 3 4 5 6 7 8 9 10 template&amp;lt;typename T&amp;gt; void push_heap(std::vector&amp;lt;T&amp;gt; &amp;amp;vec, T value) { vec.push_back(value); int i = vec.size()-1; while (i &amp;gt; 1 &amp;amp;&amp;amp; vec[i] &amp;gt; vec[i / 2]) { std::swap(vec[i], vec[i / 2]); i = i / 2; } } pop_heap算法 pop操作是类似的：</description>
    </item>
    
    <item>
      <title>程序员趁手的机器</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E9%9A%8F%E7%AC%94/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%B6%81%E6%89%8B%E7%9A%84%E6%9C%BA%E5%99%A8/</link>
      <pubDate>Sat, 25 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E9%9A%8F%E7%AC%94/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%B6%81%E6%89%8B%E7%9A%84%E6%9C%BA%E5%99%A8/</guid>
      <description>程序员的趁手机器 首先声明这里不是广告，不过好像我也接不到广告😅。我自己本身是比较在意数码产品的，用过的电脑也不少，谈谈自己使用电脑多年的体验吧。
电脑分类 台式 vs 笔记本 说到电脑，第一种分法就是台式机和笔记本，前者是为了性能，后者是为了便携。我自己是拥有一台itx主机的，当时买了主要是为了打绝地求生这款游戏的，配了27寸的2k高刷屏幕真的很爽，确实后来我也没用它做过什么其他事。
itx主机指的是比较mini的机箱，把一台电脑需要的东西在这个机箱里全部组装起来。不过不建议新手上itx装机，因为需要考虑很多尺寸大小的因素，还需要考虑许多安装方案，以及itx的配件比较贵，安装难度也比较大。总之做足功课才能上手itx主机！
说说台式机的优点吧，itx主机的缺点是安装方案不好的，散热容易不好，那普通主机不会存在这样的问题。台式机的优点就是同样系列的cpu和显卡，适配在主机上的会比笔记本上高一个档次，性能会比较好。在家里书房适合上手一台，不论是有打游戏还是办公的需求，都可以入手。不过我的建议有动手能力，可以买配件直接组装，这样会便宜很多钱！装机做一下功课，还是比较简单的（不包含itx主机）。
再来说说笔记本吧。作为一名大学生或者研究生来说，笔记本是刚需。笔记本里面也分两类：轻薄本和游戏本。他们两最大的区别就是前者不带独立显卡，后者有。
首先，对于一名大学生来说，如果你没有特别需要大型图形化处理工具，建议直接入手前者。三个优点：便宜、好看、携带方便。即使你想打游戏，也不会愿意在笔记本的那个难用的键盘和小屏幕上打的。如果你想玩大型游戏，建议去网吧玩😅。相对应的游戏本除了能打游戏，有三个缺点：厚重、发热严重、噪音较大。需要给大家排雷的一种的机型就是轻薄游戏本：1.它是比较薄，但真的不轻；2.本身堆料比较严重，散热很差，运行一点小任务就已经70摄氏度往上了；3.性能也不行，这是因为第二个缺点导致的，过热导致性能下降。
大型游戏不是指容量比较大的游戏，而是特指需要比较高的图形处理能力的游戏，比如绝地求生，战地，dota2等。LOL不是大型游戏，轻薄本也能轻松带起。
Windows vs mac 我本人对两个系统都比较熟悉，都使用过很长一段时间了，包括Windows笔记本，Windows台式，苹果笔记本，苹果台式（黑苹果🐶）。对我个人来说，苹果电脑对我来说，体验更好。
黑苹果是指在Windows系统下，通过选取比较适合苹果系统的硬件，来安装双系统，使你用比较便宜的价格用上mac系统。不过技术难度较大，配件要求也很高。我是通过淘宝花钱请人装的，自己折腾不一定能弄出来。
电脑第二种分类方式就根据图形化界面不同可以分为Windows系统电脑和苹果系统电脑。
如果你是一名大学生，我建议你买Windows笔记本。四点原因：1.便宜，苹果电脑最便宜也要7000到8000，而Windows电脑一般在5000左右可以买到性能比较好的机器。2.交互较好，在大学生里，用Windows电脑的人是大多数，包括你的老师。3.软件生态较好，Windows用户是一个较大的群体，软件适配做的更好，你学习需要用到的软件，Windows系统里都能找得到。尤其是工科的学生，如果不想用不了工程软件，就买Winodws。4.上手难度低，Windows电脑在初中高中你都已经接触过了，有基本的了解。
很重要的一点，Windows下的office比mac下的好用
选择了Windows之后，买什么牌子的呢？如果你是学生，我会建议你买联想小新系列和红米系列。如果你是工作党，追求续航，可以选择联想旗下的Thinkpad T系列，戴尔的高端笔记本，LGgram等。
高端笔记本是指在续航，安全性，售后服务，颜值，性能都比较高的笔记本，主要体现在前面三点。
那mac就一无是处了吗？当然不是！mac本身的客户定位就不同，贵有贵的道理。首先说一说mac适合什么群体，我了解到的，主要有两拨群体：一是自媒体工作者，这里一般指视频剪辑，不包括需要高强度视频渲染和3D建模的用户；二就是程序员，不过也不是所有程序员，指大部分。
mac有四个优点：1.颜值真的高，屏幕素质会高很多，还有就是世界上最好用的触控板；2.在已有的软件里用户的体验会比Windows软件做的更好一点；3.苹果系统更加安全，稳定，软件管理更加严格。说实话我的Windows笔记本真的经常出问题。4.第四个优点是专门针对程序员的，因为苹果系统是类Unix系统，与程序员经常Linux系统有异曲同工之妙，在Linux下的指令在mac下很多也都适用。
苹果的触控版的手势操作和ipad上的差不多，非常方便。学个两天，基本摆脱鼠标。
程序员的电脑选购指南 首先需要说明，并不是程序员都需要买苹果电脑，这取决于自己的选择。这两个系统在程序员里的使用率是差不多的，而且Windows系统适用于所有的程序员。
如果你是一名嵌入式开发人员，你可以告别苹果电脑了，苹果系统里没有嵌入式开发软件的生态。 如果你是一名算法工程师，平常需要不断训练模型，你也可以告别苹果电脑了，因为苹果系列都没有很高的显卡性能。 如果你是前端开发或者是后端开发，那么请放心购买苹果电脑，当然买Windows也是可以的。 我购买苹果笔记本最主要看上了两点：颜值，续航。因为续航好的笔记本都很贵，同样是1w多的价格，我干嘛不选择更好看体验更好的苹果电脑呢！
内存和硬盘 对程序员来说，最低的基础就是16GB的内存和512GB的固态硬盘，这应该是最基础的要求了。
从我的日常使用来说，我一般会开一个音乐软件，一个微信，一个翻译软件，1到2个集成开发环境，一两个写文档的软件，一两个虚拟机或者使用docker环境，一个浏览器。内存最大占用大概为12GB左右，16GB在未来5年内应该都是够用的。硬盘的的话，建议512GB往上，因为我的mac笔记本刚买来1个星期，已经用了100多个G了，如果不是苹果的硬盘太贵了，我会上1TB版本的。
苹果电脑型号选择 如果你不想买苹果电脑，下面的内容都可以不用看了。
如果你是前端，直接买macbook air性能就足够，因为日常使用软件一般只有是Vscode编辑器+Chrome浏览器或者是Webstorm开发环境+Chrome浏览器，air性能足够。
如果你是后端开发，建议直接上macbook pro，因为air是没有风扇的，如果在多开软件的情况下再外接显示器，发热会比较严重，如果没有风扇，对笔记本的性能和寿命都会有比较大的影响。
pro用户在13，14，16三个尺寸的选择吗，完全看个人喜欢：
13寸使用的是老模具，带touch bar，屏幕有一圈边框，外表会比较薄。使用的是M1芯片，在M1系列里面性能最低，但它的功耗是最低的，续航在三款中做的最好。 14寸和16寸使用的是新模具，不带touch bar，采用XDR视网膜屏，屏幕边框更小，屏占比更大，不过有一个刘海，用于前置摄像头，六扬声器音响。采用的是M1 pro和M1 max芯片，性能相对较高，功耗相对较高。 刘海可以通过软件全屏使用来规避，因为苹果电脑的黑色可以达到不发光的黑色，全屏之后刘海完全消失了。而且全屏之后，四指切换应用很方便，用了之后我离不开全屏使用的功能了。
我个人比较喜欢新的屏幕，占比更大，14寸应该是我觉得笔记本最好的尺寸了。所以我选购的配置是丐版macbook pro14寸 16GB内存+512GB固态， M1 pro芯片非满血版，虽然依旧很贵，官网的报价是14999（是不是劝退了😷）。
非满血版和满血版相差在核心的数量和神经网络引擎的数量不同。不过M1 pro对于我来说本来就是性能过剩的，我选择非满血版绝对够用了。
教育优惠指南&amp;amp;暑期返校优惠指南 如果你是学生，或者你不是学生都可以在官网使用教育优惠。
如果你是学生，需要在苹果官网进行大学生认证，一般使用学生证认证就可以，1到3个工作日就可以下来。如果你不是学生，你可以通过亲戚或者同学的身份去买，不过首先保证安全；淘宝也是有认证方法的，就算不是学生好像也能成功。
使用了教育优惠，14999直接降到13899。
马上就到暑假了，苹果一年一度的返校优惠要来了，买电脑送airpots 2耳机，价值1000多的耳机，理论上可以晚点入手，参加暑期返校优惠活动。但因为苹果电脑目前处于缺货状态，现在下单也能享受返校优惠，可以补耳机。这一点我问过苹果的客服，他给的回答是只要你电脑的发货日期在返校优惠活动开始前的14天内都可以补耳机,注意是发货日期不是下单日期。去年苹果的返校优惠活动是7月16日开始的，现在入手应该是ok的，因为发货基本要一个月之后。而且如果发货时间突然提早了，也可以退掉再买，完全没有损失。
听说美区那边，今年的返校优惠会从送airpot 2耳机变成送现金礼品卡。买电脑送150美元的礼品卡，买平板之类的送100美元的礼品卡。
预算不足咋办 苹果官网享受了教育优惠之后，是不能使用信用卡或者花呗分24期免息，最高只能到3期免息。如果你预算不够，买Windows吧，如果你一定要买，必须拥有一张建设银行的信用卡。
下载 建行生活app，在首页找到苹果教育优惠专区，找到你想选购的电脑，你会发现它是能享受教育优惠+24期分期免息的，前提是你信用卡的额度够。而且每年的7月中旬，建行生活app也会推出返校优惠活动，和官方的活动是一样的，也可以晚点入手关注一下。</description>
    </item>
    
    <item>
      <title>Docker快速入门</title>
      <link>https://caixiongjiang.github.io/blog/2022/docker%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Fri, 24 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/docker%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>Docker一小时快速入门 Docker简介和安装 Docker 开发部署流程 自己在 Windows/Mac 上开发、测试 &amp;ndash;&amp;gt; 打包为 Docker 镜像（可以理解为软件安装包） &amp;ndash;&amp;gt; 各种服务器上只需要一个命令部署好。
优点:确保了不同机器上跑起来都是一致的运行环境，不会出现不同机器之间切换出现bug的问题。
Docker通常来做什么 应用分发、部署，方便传播给他人安装。特别是开源软件和提供私有部署的应用 快速安装测试/学习软件，用完就丢（类似小程序），不把时间浪费在安装软件上。例如 Redis / MongoDB / ElasticSearch / ELK 多个版本软件共存，不污染系统，例如 Python2、Python3，Redis4.0，Redis5.0 Windows/mac上体验/学习各种 Linux 系统 重要概念：镜像、容器 镜像：可以理解为软件安装包，可以方便进行传播和安装
容器：软件安装后的状态，每个软件运行环境都是独立的、隔离的、称之为容器
安装 桌面版：https://www.docker.com/products/docker-desktop
mac版安装无障碍，Windows版安装还挺麻烦的，可以看一下这个在线文档
服务器版：https://docs.docker.com/engine/install/#server
镜像加速源 镜像加速源 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://&amp;lt;your_code&amp;gt;.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 我配置的是阿里云的镜像源，不过阿里云的镜像源需要自己配置一个账号，也可以配置其他的镜像源。
配置方法如下，在Docker Desktop中点击设置，找到Docker Engine中，在registry-mirrors字段中加上镜像源restart即可。
Docker快速安装软件 Docker安装的优点 一个命令就可以安装好，快速方便 有大量的镜像，可直接使用 没有系统兼容问题，Linux 专享软件也照样跑 支持软件多版本共存 用完就丢，不拖慢电脑速度 不同系统和硬件，只要安装好 Docker 其他都一样了，一个命令搞定所有 演示Docker安装Redis 首先，Docker官方镜像仓库查找Redis：https://hub.</description>
    </item>
    
    <item>
      <title>Git：版本管理工具</title>
      <link>https://caixiongjiang.github.io/blog/2022/git%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Sat, 18 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/git%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid>
      <description>Git版本管理工具 Git安装 mac下有两种安装方法：
官网安装：https://git-scm.com/downloads
命令行通过Homebrew 源安装：
Homebrew官网下载：https://brew.sh
如果官网提供的脚本下载太慢了，可以试试下面这个脚本：
1 $ /bin/zsh -c &amp;#34;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&amp;#34; Homebrew下载完之后，使用brew安装Git：
1 $ brew install git Git简介 Git管理的文件 文本文件（.txt） 脚本文件（.py） 各种基于文本信息的文件 Git不能管理的文件 图片文件（.jpg） MS word（.doc） 创建第一个版本库 创建版本库（init） 首先在桌面创建一个文件夹gitQAQ，在Terminal中打开，并进入该目录:
1 $ cd ~/Desktop/gitQAQ 为了记录每一个对版本记录施加修改的人user.name，我们在git中添加用户名和用户emailuser.email：
1 2 $ git config --global user.name &amp;#34;Jarson Cai&amp;#34; $ git config --global user.email &amp;#34;nau_cxj@163.com&amp;#34; 然后，我们就可以建立git的管理文件：
1 2 $ git init Initialized empty Git repository in /Users/caixiongjiang/Desktop/gitQAQ/.git/ 这样，我们就建立了一个空的Git版本管理库。
添加文件管理（add） 通常执行ls就能看见文件夹中所有的文件，不过git创建的管理库文件.git会被隐藏起来，执行下面语句才能看到：
1 2 $ ls -a .</description>
    </item>
    
    <item>
      <title>LaTeX入门教程</title>
      <link>https://caixiongjiang.github.io/blog/2022/latex%E8%AE%BA%E6%96%87/latex%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</link>
      <pubDate>Mon, 13 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/latex%E8%AE%BA%E6%96%87/latex%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</guid>
      <description>LaTeX入门教程 环境安装和配置的几种方案 mac环境
MacTex发行版：https://www.tug.org/mactex/ texpad(付费，当然某些网站有破解版) texpad不需要任何复杂的配置
MacTex发行版：https://www.tug.org/mactex/ vscode+LaTeX Workshop插件 vscode方案装好插件之后还需要配置.json
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 //注释掉的部分属于代码提示的功能，还需要装插件 { &amp;#34;latex-workshop.</description>
    </item>
    
    <item>
      <title>MySQL进阶篇 学习笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/mysql%E8%BF%9B%E9%98%B6%E7%AF%87/</link>
      <pubDate>Wed, 08 Jun 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/mysql%E8%BF%9B%E9%98%B6%E7%AF%87/</guid>
      <description>MySQL学习目标 面试题demo： 什么是事物，以及事务的四大特性？ 事务的隔离级别有哪些？MySQL默认是哪几个？ 内连接与左外连接的区别是什么？ 常用的存储引擎？InnoDB和MyISAM的区别？ MySQL默认InnoDB引擎的索引是什么数据结构 如何查看MySQL的执行计划？ 索引失效的情况有哪些？ 什么是回表查询？ 什么是MVCC？ MySQL主从复制的原理是什么？ 主从复制之后的读写分离如何实现？ 数据库的分库分表如何实现？ 学习目标： 入门阶段：下载和安装mysql，学习并使用SQL语言 进阶阶段：学习事务，存储引擎，索引，SQL优化，锁 高级阶段：学习日志管理，主从复制，读写分离，分库分表（主要用于集群） 注：本笔记基于b站最新的2022的mysql免费视频：https://www.bilibili.com/video/BV1Kr4y1i7ru?spm_id_from=333.999.0.0 MySQL进阶篇 存储引擎 MySQL体系结构 MySQl服务器分为4层：连接层；服务层；引擎层；存储层。
存储引擎简介 存储引擎就是存储数据，建立索引，更新/查询数据等技术的实现方式。存储引擎是基于表的，而不是基于库的，所以存储引擎也可被称为表类型。
1.在创建表是，可以指定存储引擎
1 2 3 4 5 create table 表名( 字段1 字段1类型 [comment 字段1注释], ...... 字段n 字段n类型 [comment 字段n注释] )engine = innodb [comment 表注释]; 查看当前数据库支持的存储引擎
1 show engines; 存储引擎特点 InnoDB
介绍：InnoDB是一种兼顾搞可靠性和高性能的通用存储引擎，在MySQL5.5之后，InnoDB是默认的MySQL存储引擎。
特点：
DML操作遵循ACID模型，支持事务；
行级锁，提高并发访问性能；
支持外键FOREIGN KEY约束，保证数据的完整性和正确性；
文件
xxx.ibd:xxx代表的是表名，InnoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm，sdi）、数据和索引。
参数：innodb_file_per_table
存储结构：
MyISAM
介绍：MyISAM是MySQL早期的默认存储引擎。
特点：
不支持事务，不支持外键；
支持表锁，不支持行锁；
访问速度快。</description>
    </item>
    
    <item>
      <title>CentOS7安装MySQL</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/centos-7%E5%AE%89%E8%A3%85mysql/</link>
      <pubDate>Fri, 20 May 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/centos-7%E5%AE%89%E8%A3%85mysql/</guid>
      <description>Linux下MySQL安装&amp;amp;远程访问配置 下载安装包 社区免费版下载地址：https://downloads.mysql.com/archives/community/
选择正确的版本：
需要安装Linux版本的MySQL，所以可以选择两个版本：一个是Red Hat Enterprice Linux,另一个是Linux-Generic。我选择的是前者，因为CentOS和它是同一个公司出的！ 选择OS version：如果你是CentOS 7，则选择Linux 7；如果为CentOS 8，则选择Linux 8。至于x86，ARM如何选取，取决于你的cpu： 如果你是mac OS系统，intel芯片，就选择x86 64bit位（现在的电脑基本都是64bit位）；如果是M1系列的芯片，请选择ARM 如果你是Windows系统，就选x86 64bit位 Linux-虚拟机三件套 此次我是在mac OS下操作虚拟机，使用三个软件来部署环境，至于如何配置环境，我在之前的博客里已经讲过了！点击查看
虚拟机软件：VMware Fusion 连接工具：nuoshell 文件传输工具：Transmit 安装MySQL 将下载好的包文件使用Transmit传输到虚拟机的系统。
正式开始安装：
解压包到mysql文件夹：
1 2 3 4 5 6 7 8 # 新建文件夹 mkdir mysql # 把包解压到mysql文件夹下 tar -xvf mysql-8.0.28-1.el7.x86_64.rpm-bundle.tar -C mysql # 进入文件 cd mysql # 查看解压后的文件 ll 会得到如下的结果：
1 2 3 4 5 6 7 8 9 10 11 total 823244 -rw-r--r--.</description>
    </item>
    
    <item>
      <title>MySQL基础篇 学习笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/mysql%E5%9F%BA%E7%A1%80%E7%AF%87/</link>
      <pubDate>Tue, 17 May 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/mysql%E5%9F%BA%E7%A1%80%E7%AF%87/</guid>
      <description>MySQL学习目标 面试题demo：
什么是事物，以及事务的四大特性？ 事务的隔离级别有哪些？MySQL默认是哪几个？ 内连接与左外连接的区别是什么？ 常用的存储引擎？InnoDB和MyISAM的区别？ MySQL默认InnoDB引擎的索引是什么数据结构 如何查看MySQL的执行计划？ 索引失效的情况有哪些？ 什么是回表查询？ 什么是MVCC？ MySQL主从复制的原理是什么？ 主从复制之后的读写分离如何实现？ 数据库的分库分表如何实现？ 学习目标：
入门阶段：下载和安装mysql，学习并使用SQL语言 进阶阶段：学习事务，存储引擎，索引，SQL优化，锁 高级阶段：学习日志管理，主从复制，读写分离，分库分表（主要用于集群） 注：本笔记基于b站最新的2022的mysql免费视频：https://www.bilibili.com/video/BV1Kr4y1i7ru?spm_id_from=333.999.0.0
MySQL基础篇 MySQL概述 数据库相关概念 数据库，也就是存储数据的仓库，简称DataBase（DB） 数据库管理系统，也就是操纵和管理数据库的软件，DataBase ManageMent System（DBMS） SQL是操作关系型数据库的编程语言，定义了一套操作关系型数据库统一标准，Structure Query Language（SQL） 主流的关系型数据库管理系统：Oracle，MySQL，SQL Server,SQLite3(嵌入式微型数据库) 下载&amp;amp;安装MySQL（mac版本） 版本：MySQL Community Server 8.0.29（社区免费版）
下载：https://www.mysql.com/
mac版本下安装完之后，可以打开系统偏好设置，就可以找到mysql
需要设置root密码
启动和停止：
连接mysql（命令行工具）：
打开Terminal，修改配置文件（Windows下为环境变量配置）：
输入：
1 sudo vim .bash_profile 加入路径：
PATH=$PATH:/usr/local/mysql/bin 保存退出（:wq），并启用该文件(每次新建一个Terminal都需要重新启用)
1 source .bash_profile 连接数据库并输入root密码：
1 mysql [-h 127.0.0.1] [-p 3306] -u root -p 其中带[]的部分可以省略，默认连接自身电脑。然后输入密码，出现MySQL版本就成功了！
关系型数据库 关系型数据库是建立在关系模型的基础上，由多张相互连接的二维表组成的数据库：
特性：
1.使用表存储，格式统一，便于维护 2.使用SQL语言操作，标准统一 MySQL数据库数据模型 SQL SQL通用语法 SQL语句可以单行或者多行书写，以分号结尾 SQL语句可以使用空格/缩进来增强语句的可读性 MySQL数据库的SQL语句不区分大小写，关键字建议使用大写 注释： 单行注释：--注释内容 或 # 注释内容（MySQL特有） 多行注释：/* 注释内容 */ SQL分类 DDL语句 DDL-数据库操作</description>
    </item>
    
    <item>
      <title>第十二讲：hashtable深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC12%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 12 May 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC12%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第十二讲：hashtable深度探索 为什么要使用hashtable？ 如上图所示，如果空间足够，我们当然可以按照次序进行存储，但往往存储是比较有限的，我们就可以使用 hashtable的结构来存储！
如何处理hashtable的碰撞现象？ 如果我们使用hashtable的结构，一定会存在取余之后相等的情况：例如15%7和22%7就会发生碰撞！
我们解决的办法是：如果发生碰撞，就将它们以一个链表的形式串在一起，如下图所示。
特点：
发生碰撞时使用形成链表的形式来解决碰撞。
链表的搜寻时间是线性增长的（ 平均时间复杂度为O(n) ），但如果list够小，搜寻的速度荏苒很快。
如果所有链表的总节点数超过了bucket（这里指模的值，图中为53，也是GNU中使用的初始值）的数量， 采用再哈希的方法:
方式为将bucket的数量扩充到原来的值的2倍，然后选取离它最近的素数作为新的bucket值。 每次扩充都需要对每个元素重新计算新的位置。 在源码中已经将所有bucket的值全部算好了，需要扩充时，直接取就ok！ hashtable部分源码（GNU2.9）：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 template &amp;lt;class Value, class Key, class HashFcn, class ExtractKey, class EqualKey, class Alloc&amp;gt; class hashtable { public: //将传进来的参数重新换了一个名称 typedef HashFcn hasher; typedef EqualKey key_equal; typedef size_t size_type; private: // 以下三者都是function objects。&amp;lt;stl_hash_fun.</description>
    </item>
    
    <item>
      <title>第十一讲：set/multiset &amp; map/multimap深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC11%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 10 May 2022 08:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC11%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第十一讲：set/multiset &amp;amp; map/multimap深度探索 set和multiset特性 set/multiset以红黑树为底层结构，因此有自动排序的特性，排序的依据是key，而set和multiset的value和key 是合二为一的：value就是key（key和data合成value） set和multiset提供遍历的操作以及iterator，按照正常的规则遍历就能获得排序状态。 无法使用iterator来改变元素值（底层为将iterator设为const），因为key有其严谨的排序规则。 set的key必须独一无二，因此其insert()用的是rb_tree的insert_unique() multiset元素的key可以重复，因此其insert()用的是rb_tree的insert_equal() set容器 模版定义：（GNU2.9）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //set默认采用key值降序排列 template &amp;lt;class Key, class Compare = less&amp;lt;Key&amp;gt;, class Alloc = alloc&amp;gt; class set { public: // typedefs: typedef Key key_type; typedef Key value_type; // 注意，以下 key_compare 和 value_compare 使用相同的比較函式 typedef Compare key_compare; typedef Compare value_compare; private: typedef rb_tree&amp;lt;key_type, value_type, identity&amp;lt;value_type&amp;gt;, key_compare, Alloc&amp;gt; rep_type; rep_type t; // 采用紅黑树（RB-tree）來表現 set public: typedef typename rep_type::const_iterator iterator;//这里的迭代器不能改变 //set的所有操作都转而呼叫底层（红黑树）的操作 .</description>
    </item>
    
    <item>
      <title>《数字图像处理》课程设计——表格图片文字识别</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E8%A1%A8%E6%A0%BC%E5%9B%BE%E7%89%87%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/</link>
      <pubDate>Thu, 05 May 2022 19:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E8%A1%A8%E6%A0%BC%E5%9B%BE%E7%89%87%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/</guid>
      <description>《数字图像处理》课程设计——表格图片文字识别 目标任务 1、将图片中的信息提取为表格：提取“姓名”、“准考证号”、“已录取”，保存为新表格 2、在已有表格中查找指定数据并进行标注；将“已录取”数据增加到原有表格中 思路步骤 1.使用灰度方法读取图片，并利用局部阈值分割方法分割为像素只有0和255的图片 2.使用基于形态学腐蚀操作和膨胀操作，分别识别横线和竖线 3.找出横线和竖线的交点，并把交点像素的位置保存起来 4.通过图片相减得到纯文字的图片，根据像素位置来分割图片 5.对分割好的图片使用cnocr文字识别识别中文，使用tesseract识别数字，并将其保存到数组中 6.将书组中的内容分别放入新的excel表格并保存，并根据名字信息对原有表格进行修改 思路具体实现 灰度读取图片&amp;amp;自适应阈值分割 灰度读取图片的目的是为了消除色彩对后续处理的影响 自适应阈值分割的目的是为了将图片的背景变为纯黑色（像素值为0），文字以及其他信息变为纯白色（像素值为255） 为什么使用阈值分割的方法？
图像分割思想：控制背景环境，降低分割难度；聚焦于感兴趣的部分。在这里其实就是将图片中的文字信息都集中起来，将图片的背景设置为黑色 基本策略：根据图像的像素灰度值的相似性来选择分割的阈值 为什么使用自适应阈值分割？
整副图像的对比度较低，存在多个目标（多个单峰灰度分布），需要使用多阈值分割方法。 自适应阈值分割的阈值选取的方法：根据图像不同区域亮度分布，计算其局部阈值，所以对于图像不同区域，能够自适应计算不同的阈值。 自适应的阈值确定方法有两种：计算某个邻域(局部)的均值、高斯加权平均(高斯滤波)来确定阈值，这里采用高斯加权平均。 二值化方法：这里采用THRESH_BINARY方法;超过阈值则设为最大像素值，不超过则设为0 形态学腐蚀 形态学腐蚀原理
使用卷积模版在图像上移动，如果发现有像素等于目标图像，就将其模板中原点的位置变成1 使用基于形态学的腐蚀和膨胀，可以将不同于该形态的区域剔除，保留相似的部分 实现
构建一个类似于横线和竖线的形态学模版，对目标图像进行腐蚀和膨胀操作，单独提取出横线和竖线 寻找横线竖线的交点 横线竖线交点寻找很简单，但因为交点的大小不一，可能一个交点包含很多个像素，但我们只需要一个。所以在选取像素的横纵坐标时需要进行特别的处理
根据交点进行图片分割 首先通过原图减去横线图和竖线图得到纯文字图片，再进行图片分割 这里的图片分割不同于上面，其代表的是字面意思，也就是根据保存好的横纵坐标选取不同的区域的图片 注意根据提取的信息，还需要对子图片再次进行分割，还有就是一些冗余信息的去除。 包含多个信息： 包含冗余信息： 中英文文字识别 为什么不自己写文字识别？因为本课程主要是为了学习opencv而不是机器学习，所以这里只调用第三方库。 中文使用cnocr库识别。 英文或数字使用tesseract程序+pytesseract库进行识别。 其中tesseract需要下载文件，下载地址：https://digi.bib.uni-mannheim.de/tesseract/ 向表格添加数据 使用openpyxl库进行excel表格的操作。 注意添加数据的函数，因为需要识别多张图片进行多次添加数据，每次添加时索引需要重新定位没有数据的第一行位置。 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 import math import cv2 as cv import openpyxl #图像二值化 &amp;#39;&amp;#39;&amp;#39; 使用自适应阈值分割： 它的思想不是计算全局图像的阈值，而是根据图像不同区域亮度分布，计算其局部阈值，所以对于图像不同区域，能够自适应计算不同的阈值，因此被称为自适应阈值法。 如何确定局部阈值呢？可以计算某个邻域(局部)的均值、中值、高斯加权平均(高斯滤波)来确定阈值。 cv2.</description>
    </item>
    
    <item>
      <title>爬虫：使用selenium模拟12306购票</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E4%BD%BF%E7%94%A8selenium%E6%A8%A1%E6%8B%9F12306%E8%B4%AD%E7%A5%A8/</link>
      <pubDate>Thu, 28 Apr 2022 10:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E4%BD%BF%E7%94%A8selenium%E6%A8%A1%E6%8B%9F12306%E8%B4%AD%E7%A5%A8/</guid>
      <description>使用selenium模拟12306购票 selenium介绍 selenium是一种自动化测试工具，可以通过浏览器引擎来自动化帮人类做某些事。 selenium也可以作为一种轻量化爬虫工具。优点是它能绕过网站自身加密后的源码，通过浏览器解析后来获取网页中的元素，也就是文本信息；缺点也很明显，就是它本身是通过浏览器去运行的，非常容易受浏览器访问时网络波动的影响，因此通常要设置睡眠短暂时间来等待浏览器的加载，整体效率就不高。 总体来说，selenium适合轻量化数据的爬虫。 本小程序原理介绍 通过python使用selenium自动操控浏览器引擎模拟人的购票动作。 通过第三方图像识别破解复杂验证码。（以前的12306登录有这个环节，现在取消了） 本小程序没有涉及UI界面的设计，只为学习爬虫工具，粗浅了解网页结构。 资源准备 1.谷歌浏览器（你也可以使用火狐浏览器）
2.下载谷歌浏览器驱动：
查看浏览器的版本：点击浏览器右上角的三个点按钮，找到帮助中的关于Google Chrome，点击就可以看到自己的版本号了 打开网址：https://registry.npmmirror.com/binary.html?path=chromedriver/,选择浏览器版本对应的镜像，根据操作系统来选择下载哪一个镜像 下载解压后，将文件改为chromedriver，放入python解释器所在的文件夹，也就是你python环境配置的地方，这里我使用的PyCharm,所以把它放在了我的项目目录下的bin文件中。 3.下载selenium库（哪种ok就哪种）:
1 2 pip install selenium pip install selenium -i 清华源 破解12306检测自动化控制 12306的滑窗验证会自动检测自动化测试，导致机器滑窗验证失败。
反识别自动化控制工具使用：
如果你的chrome版本小于88，在启动浏览器的时候（此时没有加载任何内容），向页面潜入js代码，去掉webdriver：
1 2 3 4 5 6 7 8 9 10 11 from selenium.webdriver import Chrome web = Chrome() web.execute_cdp_cmd(&amp;#34;Page.addScriptToEvaluateOnDocument&amp;#34;, { &amp;#34;source&amp;#34; : &amp;#34;&amp;#34;&amp;#34; navigator.webdriver = undefined Object.defineProperty(navigator, &amp;#39;webdriver&amp;#39;, { get: () =&amp;gt; undefined }) &amp;#34;&amp;#34;&amp;#34; }) 如果你的chrome版本大于88，引入option:
1 2 3 4 5 6 7 from selenium.</description>
    </item>
    
    <item>
      <title>第十讲：rb_tree深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC10%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 20 Apr 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC10%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第十讲：rb_tree深度探索 rb_tree vs AVL树 AVL是一个高度平衡的二叉树，而红黑树不是 红黑树每次插入一个元素，最多只需要两次旋转；而AVL可能需要更多次平衡操作 搜索速度：AVL树更加快，因为其严格遵守高度平衡，搜索查找的平均时间复杂度为log2(n) 插入速度：红黑树更加快，因为最多只需要两次旋转再加一些重新着色。 AVL树是rb_tree的子集 红黑树的结构 红黑树是平衡二分搜索树中常常使用的一种，平衡二分搜索树的特性：排列规则有利search和insert，并保持适度平衡。
红黑树提供遍历的功能及iterators。按正常规则（++ite）遍历，便能获得排序状态。
红黑树的结构样例：
排序的状态为红黑树的中序遍历，begin()在左下，end()是在右下
红黑树的规则(首先需要是一颗二分查找树{BST})：
1.每个节点不是红色就是黑色 2.根节点为黑色 3.如果节点为红，其子节点必须是黑（如果节点为黑，其子节点既可以是红也可以是黑） 4.任一节点至NULL(树尾端)的任何路径，所含黑色节点数必须相同 根据规则4，新增节点必须为红；根据规则3，新增节点之父节点必须为黑，当新节点根据二叉搜索树的规则到达其插入点， 但未能符合上述要求，就必须调整颜色并旋转树形
我们不应该用红黑树的iterators改变元素值（因为元素有其严谨的排序规则）。但是编程层面并未阻止此事，rb_tree将会为set和map服务，而map允许元素的data被改变， 只有元素的key才是不能被改变的。
rb_tree提供两种insertion操作（红黑树本身对重复与否没有限制，而取决于insert的方式）：insert_unique()和insert_equal()。前者表示节点的key一定在整个树中独一无二， 否则安插失败；后者表示节点的key可以重复。
部分源码（在这里将key和data合起来的节点合成value）：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //这里的Value是key和data的组合，如果value只传一个值说明没有value（set） template &amp;lt;class Key, class Value, class KeyOfValue, class Compare, class Alloc = alloc&amp;gt; class rb_tree { protected: typedef __rb_tree_node&amp;lt;Value&amp;gt; rb_tree_node;//红黑树的结构 ··· public: // 注意，没有定义iterator（喔，不，定义在后面） typedef rb_tree_node* link_type;//指向红黑树节点的指针 ··· protected: //rb_tree只以三个资料表现它自己 size_type node_count;//rb_tree的大小（节点数量） link_type header; Compare key_compare;//key的大小比较准则；应会是个function object ··· } 测试rb_tree（GNU2.</description>
    </item>
    
    <item>
      <title>第九讲：deque，queue，stack深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC9%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 20 Apr 2022 18:14:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC9%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第九讲：deque，queue，stack深度探索 容器deque deque的结构和设计 deque的底层结构：
如上图所示：
deque的迭代器是一个class，内部有四个元素cur，first，last，node node指向某一个buffer，first和last分别指向这一个buffer的头部和尾部，cur指向当前元素 cur一旦走到了一个buffer的边界，则直接走到下一个buffer的开头（维持左闭右开） deque向前扩充和向后扩充都是使用buffer来进行的（之前已经讲过了） start和finish是为了维护改容器的begin()和end() 源码如下(GNU2.9)：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 template&amp;lt;class T, class Alloc=alloc, size_t BufSiz=0&amp;gt; class deque { public: typedef T value_type; typedef __deque_iterator&amp;lt;T, T&amp;amp;, T*, BufSiz&amp;gt; iterator; protected: typedef pointer* map_pointer;//T** 指向指针的指针 protected: iterator start;//对应begin()的iterator类 iterator finish;//对应end()的iterator类 map_pointer map;//单个buffer size_type map_size;//控制中心的大小（也就是有多少个buffer） public: iterator begin() { return start; } iterator edn() { return finish; } size_type size() const { return finish - start; } }; 谈一谈参数的设置：如果BufSiz传入5，则为5；如果没有指定，则默认为0；如果元素大小sz大于512Bytes ，它就让一个缓冲区只放一个元素；如果小于512Bytes,则传回512/sz。（不过新版本不允许指定大小）</description>
    </item>
    
    <item>
      <title>第八讲：array和forward_list深度探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC8%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 19 Apr 2022 18:14:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC8%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第八讲：array和forward_list深度探索 容器array array在c中本身就存在，为什么array要成为一个容器？
array成为容器的好处：array可以使用迭代器，可以使用标准算法，更加地快捷。
使用标准array的方法：
1 2 3 4 5 array&amp;lt;int, 10&amp;gt; myArray; auto it = myArray.begin(); //array&amp;lt;int, 10&amp;gt;::iterator it = myArray.begin(); it += 3; cout &amp;lt;&amp;lt; *it; 源码如下图，较简单(TR1版本)：
forward_list 单向链表的结构与list双向链表的结构类似，可以类推。（c++11以前为slist）</description>
    </item>
    
    <item>
      <title>第七讲：vector容器深入探索</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC7%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 17 Apr 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC7%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第七讲：vector容器深入探索 vector是动态空间，随着元素的加入，它的内部机制会自动扩充空间以容纳新元素。
vector扩容机制(GNU 2.9版) 从途中可以看出，有三个非常关键的指针start，finish，end_of_storage:
start指向第一个元素的内存空间，也就是begin()方法指向的内存空间。 finish指向当前使用中的最后一个元素的后一个位置的内存空间，也就是end()方法指向的内存空间！ end_of_storage指向当前最大可用空间的尾。 源码：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 template &amp;lt;class T, class Alloc = alloc&amp;gt; // 預設使用 alloc 為配置器 class vector { public: // 以下標示 (1),(2),(3),(4),(5)，代表 iterator_traits&amp;lt;I&amp;gt; 所服務的5個型別。 typedef T value_type;	// (1) typedef value_type* pointer; // (2) typedef const value_type* const_pointer; typedef const value_type* const_iterator; typedef value_type&amp;amp; reference; // (3) typedef const value_type&amp;amp; const_reference; typedef size_t size_type; typedef ptrdiff_t difference_type; // (4) // 以下，由於vector 所維護的是一個連續線性空間，所以不論其元素型別為何， // 原生指標都可以做為其迭代器而滿足所有需求。 typedef value_type* iterator; /* 根據上述寫法，如果客端寫出這樣的碼： vector&amp;lt;Shape&amp;gt;::iterator is; is 的型別其實就是Shape* 而STL 內部運用 iterator_traits&amp;lt;is&amp;gt;::reference 時，獲得 Shape&amp;amp; 運用iterator_traits&amp;lt;is&amp;gt;::iterator_category 時，獲得 random_access_iterator_tag	(5) （此乃iterator_traits 針對原生指標的特化結果） */ // vector採用簡單的線性連續空間。以兩個迭代器start和end分別指向頭尾， // 并以迭代器end_of_storage指向容量尾端。容量可能比(尾-头)还大 protected: iterator start; iterator finish; iterator end_of_storage; public: iterator begin() { return start; } const_iterator begin() const { return start; } iterator end() { return finish; } /*通过函数相减有利于后期修改指针时，不需要修改size()方法*/ size_type size() const { return size_type(end() - begin()); } /*capacity代表最大容量*/ size_type capacity() const { return size_type(end_of_storage - begin()); } bool empty() const { return begin() == end(); } /*连续空间的容器都会有[]的运算符重载*/ reference operator[](size_type n) { return *(begin() + n); } // 取出第一個元素內容 reference front() { return *begin(); } // 取出最後一個元素內容 reference back() { return *(end() - 1); } } 通过push_back()方法来看扩容机制：</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 24 章 制作 HTTP 服务器端 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-24-%E7%AB%A0-%E5%88%B6%E4%BD%9C-http-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 13 Apr 2022 20:16:48 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-24-%E7%AB%A0-%E5%88%B6%E4%BD%9C-http-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 24 章 制作 HTTP 服务器端 24.1 HTTP 概要 本章将编写 HTTP（HyperText Transfer Protocol，超文本传输协议）服务器端，即 Web 服务器端。
24.1.1 理解 Web 服务器端 web服务器端就是要基于 HTTP 协议，将网页对应文件传输给客户端的服务器端。
24.1.2 HTTP 无状态的 Stateless 协议
从上图可以看出，服务器端相应客户端请求后立即断开连接。换言之，服务器端不会维持客户端状态。即使同一客户端再次发送请求，服务器端也无法辨认出是原先那个，而会以相同方式处理新请求。因此，HTTP 又称「无状态的 Stateless 协议」
24.1.3 请求消息（Request Message）的结构 下面是客户端向服务端发起请求消息的结构：
从图中可以看出，请求消息可以分为请求头、消息头、消息体 3 个部分。其中，请求行含有请求方式（请求目的）信息。典型的请求方式有 GET 和 POST ，GET 主要用于请求数据，POST 主要用于传输数据。为了降低复杂度，我们实现只能响应 GET 请求的 Web 服务器端，下面解释图中的请求行信息。其中「GET/index.html HTTP/1.1」 具有如下含义：
请求（GET）index.html 文件，通常以 1.1 版本的 HTTP 协议进行通信。
请求行只能通过 1 行（line）发送，因此，服务器端很容易从 HTTP 请求中提取第一行，并分别分析请求行中的信息。
请求行下面的消息头中包含发送请求的浏览器信息、用户认证信息等关于 HTTP 消息的附加信息。最后的消息体中装有客户端向服务端传输的数据，为了装入数据，需要以 POST 方式发送请求。但是我们的目标是实现 GET 方式的服务器端，所以可以忽略这部分内容。另外，消息体和消息头与之间以空行隔开，因此不会发生边界问题
24.1.4 响应消息（Response Message）的结构 下面是 Web 服务器端向客户端传递的响应信息的结构。从图中可以看出，该响应消息由状态行、头信息、消息体等 3 个部分组成。状态行中有关于请求的状态信息，这是与请求消息相比最为显著地区别。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 18 章 多线程服务器端的实现 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-18-%E7%AB%A0-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%9A%84%E5%AE%9E%E7%8E%B0-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 10 Apr 2022 16:05:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-18-%E7%AB%A0-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E7%9A%84%E5%AE%9E%E7%8E%B0-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 18 章 多线程服务器端的实现 18.1 理解线程的概念 18.1.1 引入线程背景 第 10 章介绍了多进程服务端的实现方法。多进程模型与 select 和 epoll 相比的确有自身的优点，但同时也有问题。如前所述，创建（复制）进程的工作本身会给操作系统带来相当沉重的负担。而且，每个进程都具有独立的内存空间，所以进程间通信的实现难度也会随之提高。换言之，多进程的缺点可概括为：
创建进程的过程会带来一定的开销 为了完成进程间数据交换，需要特殊的 IPC 技术。 但是更大的缺点是下面的：
每秒少则 10 次，多则千次的「上下文切换」是创建进程的最大开销 只有一个 CPU 的系统是将时间分成多个微小的块后分配给了多个进程。为了分时使用 CPU ，需要「上下文切换」的过程。「上下文切换」是指运行程序前需要将相应进程信息读入内存，如果运行进程 A 后紧接着需要运行进程 B ，就应该将进程 A 相关信息移出内存，并读入进程 B 相关信息。这就是上下文切换。但是此时进程 A 的数据将被移动到硬盘，所以上下文切换要很长时间，即使通过优化加快速度，也会存在一定的局限。
为了保持多进程的优点，同时在一定程度上克服其缺点，人们引入的线程（Thread）的概念。这是为了将进程的各种劣势降至最低程度（不是直接消除）而设立的一种「轻量级进程」。线程比进程具有如下优点：
线程的创建和上下文切换比进程的创建和上下文切换更快 线程间交换数据无需特殊技术 18.1.2 线程和进程的差异 线程是为了解决：为了得到多条代码执行流而复制整个内存区域的负担太重。
每个进程的内存空间都由保存全局变量的「数据区」、向 malloc 等函数动态分配提供空间的堆（Heap）、函数运行时间使用的栈（Stack）构成。每个进程都有独立的这种空间，多个进程的内存结构如图所示：
但如果以获得多个代码执行流为目的，则不应该像上图那样完全分离内存结构，而只需分离栈区域。通过这种方式可以获得如下优势：
上下文切换时不需要切换数据区和堆 可以利用数据区和堆交换数据 实际上这就是线程。线程为了保持多条代码执行流而隔开了栈区域，因此具有如下图所示的内存结构：
如图所示，多个线程共享数据区和堆。为了保持这种结构，线程将在进程内创建并运行。也就是说，进程和线程可以定义为如下形式：
进程：在操作系统构成单独执行流的单位 线程：在进程构成单独执行流的单位 如果说进程在操作系统内部生成多个执行流，那么线程就在同一进程内部创建多条执行流。因此，操作系统、进程、线程之间的关系可以表示为下图：
18.2 线程创建及运行 可移植操作系统接口（英语：Portable Operating System Interface，缩写为POSIX）是IEEE为要在各种UNIX操作系统上运行软件，而定义API的一系列互相关联的标准的总称，其正式称呼为IEEE Std 1003，而国际标准名称为ISO/IEC 9945。此标准源于一个大约开始于1985年的项目。POSIX这个名称是由理查德·斯托曼（RMS）应IEEE的要求而提议的一个易于记忆的名称。它基本上是Portable Operating System Interface（可移植操作系统接口）的缩写，而X则表明其对Unix API的传承。
Linux基本上逐步实现了POSIX兼容，但并没有参加正式的POSIX认证。
微软的Windows NT声称部分实现了POSIX标准。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 17 章 优于 select 的 epoll 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-17-%E7%AB%A0-%E4%BC%98%E4%BA%8E-select-%E7%9A%84-epoll-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 09 Apr 2022 19:06:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-17-%E7%AB%A0-%E4%BC%98%E4%BA%8E-select-%E7%9A%84-epoll-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 17 章 优于 select 的 epoll 17.1 epoll 理解及应用 select 复用方法由来已久，因此，利用该技术后，无论如何优化程序性能也无法同时介入上百个客户端。这种 select 方式并不适合以 web 服务器端开发为主流的现代开发环境，所以需要学习 Linux 环境下的 epoll
17.1.1 基于 select 的 I/O 复用技术速度慢的原因 第 12 章实现了基于 select 的 I/O 复用技术服务端，其中有不合理的设计如下：
调用 select 函数后常见的针对所有文件描述符的循环语句 每次调用 select 函数时都需要向该函数传递监视对象信息 上述两点可以从 echo_selectserv.c 得到确认，调用 select 函数后，并不是把发生变化的文件描述符单独集中在一起，而是通过作为监视对象的 fd_set 变量的变化，找出发生变化的文件描述符（54,56行），因此无法避免针对所有监视对象的循环语句。而且，作为监视对象的 fd_set 会发生变化，所以调用 select 函数前应该复制并保存原有信息，并在每次调用 select 函数时传递新的监视对象信息。
select 性能上最大的弱点是：每次传递监视对象信息，准确的说，select 是监视套接字变化的函数。而套接字是操作系统管理的，所以 select 函数要借助操作系统才能完成功能。select 函数的这一缺点可以通过如下方式弥补：
仅向操作系统传递一次监视对象，监视范围或内容发生变化时只通知发生变化的事项
这样就无需每次调用 select 函数时都想操作系统传递监视对象信息，但是前提操作系统支持这种处理方式。Linux 的支持方式是 epoll ，Windows 的支持方式是 IOCP。
17.1.2 select 也有有点 select 的兼容性比较高，这样就可以支持很多的操作系统，不受平台的限制，使用 select 函数满足以下两个条件：</description>
    </item>
    
    <item>
      <title>第六讲：迭代器设计的原则&amp;iterator traits的作用与设计</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC6%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 08 Apr 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC6%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第六讲：迭代器设计的原则&amp;amp;iterator traits的作用与设计 iterator traits iterator traits是为了提取出迭代器的特点，迭代器必须有能力回答algorithm提出的问题。
c++标准库设计了5种回答方式,集成在class中（迭代器相关的类型，迭代器模版中本身必须定义出来）：
iterator_category：迭代器的类型，具体表现在能否++或者&amp;ndash;或者一下加减很多步 difference_type：代表两个iterator的距离应该用什么type来表现（随机访问：unsign interger，实现链表的都用ptrdiff_t类型） value_type：iterator所指元素的类型 reference：引用（暂未使用） pointer：指针（暂未使用） 但如果iterator本身不是class，例如native pointer（退化的iterator），如何回答算法的5个问题？
iterator traits用于分离class iiterators和non-class iterators</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 16 章 关于 I/O 流分离的其他内容 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-16-%E7%AB%A0-%E5%85%B3%E4%BA%8E-i-o-%E6%B5%81%E5%88%86%E7%A6%BB%E7%9A%84%E5%85%B6%E4%BB%96%E5%86%85%E5%AE%B9-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 08 Apr 2022 14:38:38 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-16-%E7%AB%A0-%E5%85%B3%E4%BA%8E-i-o-%E6%B5%81%E5%88%86%E7%A6%BB%E7%9A%84%E5%85%B6%E4%BB%96%E5%86%85%E5%AE%B9-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 16 章 关于 I/O 流分离的其他内容 16.1 分离 I/O 流 「分离 I/O 流」是一种常用表达。有 I/O 工具可区分二者，无论采用哪种方法，都可以认为是分离了 I/O 流。
16.1.1 2次 I/O 流分离 之前有两种分离方法：
第一种是第 10 章的「TCP I/O 过程」分离。通过调用 fork 函数复制出一个文件描述符，以区分输入和输出中使用的文件描述符。虽然文件描述符本身不会根据输入和输出进行区分，但我们分开了 2 个文件描述符的用途，因此，这也属于「流」的分离。 第二种分离是在第 15 章。通过 2 次 fdopen 函数的调用，创建读模式 FILE 指针（FILE 结构体指针）和写模式 FILE 指针。换言之，我们分离了输入工具和输出工具，因此也可视为「流」的分离。下面是分离的理由。 16.1.2 分离「流」的好处 首先是第 10 章「流」的分离目的：
通过分开输入过程（代码）和输出过程降低实现难度 与输入无关的输出操作可以提高速度 下面是第 15 章「流」分离的目的：
为了将 FILE 指针按读模式和写模式加以区分 可以通过区分读写模式降低实现难度 通过区分 I/O 缓冲提高缓冲性能 16.1.3 「流」分离带来的 EOF 问题 第 7 章介绍过 EOF 的传递方法和半关闭的必要性。有一个语句：
1 shutdown(sock,SHUT_WR); 当时说过调用 shutdown 函数的基于半关闭的 EOF 传递方法。第十章的 echo_mpclient.</description>
    </item>
    
    <item>
      <title>第五讲：深入理解容器</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC5%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 08 Apr 2022 13:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC5%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第五讲：深入理解容器 容器的结构再分类 heap 和 priority_queue中有vector的结构 stack 和 queue中有deque的结构 set 和 map系列有rb_tree的结构 unordered系列容器中有hashtable的结构 在c++11中：slist &amp;ndash;&amp;gt; forward_list； hash_~ &amp;ndash;&amp;gt; unordered_~。 深度探索list list（环状双向链表）其本身是一个指针，指向一个node节点，其结构为两个指针（一个向前一个向后）+数据值
1 sizeof(list&amp;lt;int&amp;gt;()) //其值为4Bytes（GNU2.9） 8Bytes(GNU4.9) list的结构 node的设计（GNU2.9）： 1 2 3 4 5 6 7 tempalate&amp;lt;class T&amp;gt; struct __list_node { typedef void* void_pointer;//一个空的指针置于尾端的一个空白节点，符合&amp;#34;前闭后开&amp;#34;的要求 void_pointer prev;//向前的指针 void_pointer next;//向后的指针 T data;//数据 }; iterator的设计（GNU2.9）： 1 2 3 4 5 6 7 8 tempalte&amp;lt;class T, class Ref, class Ptr&amp;gt; struct __list_iterator { typedef T value_type; typedef Ptr pointer; typedef Ref reference; ··· //具体看《STL源码剖析》p131 }; G4.</description>
    </item>
    
    <item>
      <title>第四讲：深入理解分配器</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC4%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 08 Apr 2022 10:54:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC4%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第四讲：深入理解分配器 operator new() &amp;amp; malloc() operator() new会调用malloc(), malloc()作用是分配内存。
看图：
size部分为我们所需要的内存，可以看出malloc()分配的内存比所需要的内存多。多分配的内存空间如果称为开销的话，也就是说我们的单个内存越大，开销所占比例就越小！
分配器最重要的两个函数：allocate &amp;amp; deallocate VC++下和BC++下：
申请内存：allocator--&amp;gt;operator new()--&amp;gt;malloc() 释放内存：deallocator--&amp;gt;operator delete()--&amp;gt;free() 分配512个int整数：
1 2 int *p = allocator&amp;lt;int&amp;gt;().allocate(512, (int*)0); allocator&amp;lt;int&amp;gt;().deallocate(p, 512); 注：一个type +（）形成了一个临时对象，才能调用其中的成员函数。举例：queue&amp;lt;int&amp;gt;()
alloc的优点 GNU2.9下：
申请内存：allocator--&amp;gt;allocate()--&amp;gt;operator new()--&amp;gt;malloc() 释放内存：deallocator--&amp;gt;deallocate()-&amp;gt;operator delete()--&amp;gt;free() 注：虽然GNU标准allocator被设计出来，但它的容器基本都不用标准的allocator，而是使用alloc
使用malloc()和free()会带来很大的额外开销，如果区块小，开销比例会很大。 额外开销中的cookie记录内存的大小，但因为容器元素的大小是一样的，所以alloc使用一个长链表（i = 0～15），第i个对应cookie大小为8(i + 1)Bytes的内存大小，容器的内存大小会被调整为8的倍数，这样就只需要用少量cookie来记录内存大小！ 所以使用alloc存放1000000个元素，可以省掉cookie开销大约8000000个Bytes GNU4.9下：
容器使用的分配器又变为了allocator，继承于new_allocator，使用operator new() 和 operator delete() 4.9下的alloc被更名为__pool_alloc，属于__gnu_cxx::__pool_alloc </description>
    </item>
    
    <item>
      <title>第三讲:泛型编程和模版技术</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC3%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 07 Apr 2022 15:21:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC3%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第三讲:泛型编程和模版技术 源代码之分布 VC的标准库文件夹: GNU c++标准库文件夹: OOP(面向对象编程) vs GP(泛型编程) OOP将datas和methods关联在一起（成员变量和成员函数都放在类里面） demo:list内部本身存在有sort()算法，使用语法如下：
1 c.sort() GP是将datas和methods分开来
demo：vector和deque内部都没有sort()函数，sort()函数是放在算法里面的，使用语法如下：
1 ::sort(c.begin(), c.end()); 注：list本身是链式容器，无法支持随机访问，所以需要本身自己重新定义sort()。
采用GP的好处：
容器和算法团队可以各自写自己的东西，其间用迭代器来进行关联。 算法通过迭代器确定操作范围，并通过迭代器取用容器的元素。 两个石头如何比较大小不需要类来决定，而是用仿函数来决定。 max()算法的demo：
第二个版本的参数3接收的是函数对象或者是仿函数，用于自定义的比较规则制定！
操作符重载复习 操作符操作单个数或者多个数，以及能否成为类内部的成员函数
模版Template复习 类模版: 函数模版: 成员模版 模版中泛化 vs 特化 泛化的特点是可以接收大多数type的数据结构 特化的特点是为了某些特殊的数据（数据有不同的特点）进行的模版中特殊化的写法 demo:
特化中的偏特化（局部特化） 个数的偏特化: 范围的偏特化： </description>
    </item>
    
    <item>
      <title>第二讲:容器之分类及各种测试</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC2%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 07 Apr 2022 10:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC2%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第二讲:容器之分类及各种测试 容器结构及分类 序列式容器 数组（Array）：定长数组，无法扩充 vector：可扩充的数组（分配器做内存扩充） Deque：双端队列 List：双向链表 Forward-List：单向链表 关联式容器（key-&amp;gt;value） Set/Multiset（Multiset中的值可以重复）：内部为红黑数 Map/Multimap（Multimap中的value值可以重复）：内部为红黑树 无序容器（unordered,大类上属于关联式容器） 介绍一个常用的结构hashtable：根据公式进行分类， 但会产生碰撞， 产生碰撞的元素全部放在一个链表中。但如果链表太长如何做呢？后面会继续介绍。
先写用于测试的几个辅助函数:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 using std::cin; using std::cout; using std::string; long get_a_target_long() { long target = 0; cout &amp;lt;&amp;lt; &amp;#34;target (0~&amp;#34; &amp;lt;&amp;lt; RAND_MAX &amp;lt;&amp;lt; &amp;#34;):&amp;#34;; return target; } string get_a_target_string() { long target = 0; char buf[10]; cout &amp;lt;&amp;lt; &amp;#34;target (0~&amp;#34; &amp;lt;&amp;lt; RAND_MAX &amp;lt;&amp;lt; &amp;#34;):&amp;#34;; cin &amp;gt;&amp;gt; target; //snprintf功能为格式化成字符串 // 1-- 目标字符串 2 -- 拷贝字节数 3 -- 格式化成字符串。4 -- 可变参数。 snprintf(buf, 10, &amp;#34;%d&amp;#34;, target); return string(buf); } //比较两个long数据是否相等 int compareLongs(const void* a, const void* b) { return (*(long*)a - *(long*)b); } //比较两个string数据是否相等 int compareStrings(const void* a, const void* b) { if(*(string*)a &amp;gt; *(string*)b) return 1; else if(*(string*)a &amp;lt; *(string*)b) return -1; else return 0; } 顺序容器使用及测试 使用容器array：array.</description>
    </item>
    
    <item>
      <title>第一讲:STL体系结构介绍</title>
      <link>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC1%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 07 Apr 2022 08:15:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/stl%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC1%E8%AE%B2-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>第一讲:STL体系结构介绍 c++标准库 vs c++ Standard Library 总体来说 c++标准库 &amp;gt; c++ Standard Library
标准库以头文件（.h）的形式呈现:
c++标准库的header files不带副档名（.h）, 例如#include 新式c header files 不带副档名（.h），例如 #include 旧式c header files 带有副档名（.h）仍然可用，例如 #include &amp;lt;stdio.h&amp;gt; 新式headers内的组件封装为 namespace &amp;ldquo;std&amp;rdquo; using namespace std;（相当于把std文件全部打开） using std::cout; 旧式headers内的组件不封装在namespace &amp;ldquo;std&amp;rdquo; demo：
1 2 3 4 5 6 #include &amp;lt;string&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;vector&amp;gt; #include &amp;lt;algorithm&amp;gt; #include &amp;lt;functional&amp;gt; using namespace std; 重要的网站（c++标准库） cplusplus.com cppreference.com gcc.gnu.org STL六大部件 容器（containers） 分配器（allocators） 算法（algorithms） 迭代器（iterators） 适配器（addpters） 仿函数（functors） 六大部件的关系：
容器可以使我们不用管c++的内存，分配器支持容器进行内存管理。 容器的数据操作使用算法，访问数据使用迭代器，迭代器（类似于指针）是算法操作容器内部数据的桥梁。 仿函数类似于函数，暂时可以用函数来理解。 适配器是用来转换的，可以对容器，仿函数，迭代器进行转换。 模版编程和面向对象编程的区别</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 15 章 套接字和标准I/O 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-15-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E5%92%8C%E6%A0%87%E5%87%86i-o-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 06 Apr 2022 17:53:25 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-15-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E5%92%8C%E6%A0%87%E5%87%86i-o-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 15 章 套接字和标准I/O 15.1 标准 I/O 的优点 15.1.1 标准 I/O 函数的两个优点 下面是标准 I/O 函数的两个优点：
标准 I/O 函数具有良好的移植性 标准 I/O 函数可以利用缓冲提高性能 创建套接字时，操作系统会准备 I/O 缓冲。此缓冲在执行 TCP 协议时发挥着非常重要的作用。此时若使用标准 I/O 函数，将得到额外的缓冲支持。如下图：
假设使用 fputs 函数进行传输字符串 「Hello」时，首先将数据传递到标准 I/O 缓冲，然后将数据移动到套接字输出缓冲，最后将字符串发送到对方主机。
设置缓冲的主要目的是为了提高性能。从以下两点可以说明性能的提高：
传输的数据量 数据向输出缓冲移动的次数。 比较 1 个字节的数据发送 10 次的情况和 10 个数据包发送 1 次的情况。发送数据时，数据包中含有头信息。头信与数据大小无关，是按照一定的格式填入的。假设头信息占 40 个字节，需要传输的数据量也存在较大区别：
1 个字节 10 次：40*10=400 字节 10个字节 1 次：40*1=40 字节。 15.1.2 标准 I/O 函数和系统函数之间的性能对比 下面是利用系统函数的示例：
syscpy.c 下面是使用标准 I/O 函数复制文件
stdcpy.c 对于以上两个代码进行测试，明显基于标准 I/O 函数的代码跑的更快</description>
    </item>
    
    <item>
      <title>《模式识别&amp;机器学习》课后作业（2）</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E4%BD%9C%E4%B8%9A2/</link>
      <pubDate>Tue, 05 Apr 2022 18:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E4%BD%9C%E4%B8%9A2/</guid>
      <description>《模式识别&amp;amp;机器学习》课后作业 作业二 根据最小均方误差算法（hk算法）对0~9的中任意两个数进行分类。
代码实现 h_k.m:(主函数) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 %h_k.</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 14 章 多播与广播 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-14-%E7%AB%A0-%E5%A4%9A%E6%92%AD%E4%B8%8E%E5%B9%BF%E6%92%AD-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 05 Apr 2022 13:54:59 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-14-%E7%AB%A0-%E5%A4%9A%E6%92%AD%E4%B8%8E%E5%B9%BF%E6%92%AD-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 14 章 多播与广播 14.1 多播 多播（Multicast）方式的数据传输是基于 UDP 完成的。因此 ，与 UDP 服务器端/客户端的实现方式非常接近。区别在于，UDP 数据传输以单一目标进行，而多播数据同时传递到加入（注册）特定组的大量主机。换言之，采用多播方式时，可以同时向多个主机传递数据。
14.1.1 多播的数据传输方式以及流量方面的优点 多播的数据传输特点可整理如下：
多播服务器端针对特定多播组，只发送 1 次数据。 即使只发送 1 次数据，但该组内的所有客户端都会接收数据 多播组数可以在 IP 地址范围内任意增加 多播组是 D 类IP地址（224.0.0.0~239.255.255.255），「加入多播组」可以理解为通过程序完成如下声明：
在 D 类IP地址中，我希望接收发往目标 239.234.218.234 的多播数据
多播是基于 UDP 完成的，也就是说，多播数据包的格式与 UDP 数据包相同。只是与一般的 UDP 数据包不同。向网络传递 1 个多播数据包时，路由器将复制该数据包并传递到多个主机。像这样，多播需要借助路由器完成。如图所示：
若通过 TCP 或 UDP 向 1000 个主机发送文件，则共需要传递 1000 次。但是此时如果用多播网络传输文件，则只需要发送一次。这时由 1000 台主机构成的网络中的路由器负责复制文件并传递到主机。就因为这种特性，多播主要用于「多媒体数据实时传输」。
另外，理论上可以完成多播通信，但是不少路由器并不支持多播，或即便支持也因网络拥堵问题故意阻断多播。因此，为了在不支持多播的路由器中完成多播通信，也会使用隧道（Tunneling）技术。
14.1.2 路由（Routing）和 TTL（Time to Live,生存时间），以及加入组的办法 为了传递多播数据包，必须设置 TTL 。TTL 是 Time to Live的简写，是决定「数据包传递距离」的主要因素。TTL 用整数表示，并且每经过一个路由器就减一。TTL 变为 0 时，该数据包就无法再被传递，只能销毁。因此，TTL 的值设置过大将影响网络流量。当然，设置过小，也无法传递到目标。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 13 章 多种 I/O 函数 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-13-%E7%AB%A0-%E5%A4%9A%E7%A7%8D-i-o-%E5%87%BD%E6%95%B0-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 04 Apr 2022 23:08:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-13-%E7%AB%A0-%E5%A4%9A%E7%A7%8D-i-o-%E5%87%BD%E6%95%B0-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 13 章 多种 I/O 函数 13.1 send &amp;amp; recv 函数 13.1.1 Linux 中的 send &amp;amp; recv 首先看 sned 函数定义：
1 2 3 4 5 6 7 8 9 #include &amp;lt;sys/socket.h&amp;gt; ssize_t send(int sockfd, const void *buf, size_t nbytes, int flags); /* 成功时返回发送的字节数，失败时返回 -1 sockfd: 表示与数据传输对象的连接的套接字和文件描述符 buf: 保存带传输数据的缓冲地址值 nbytes: 待传输字节数 flags: 传输数据时指定的可选项信息 */ 下面是 recv 函数的定义：
1 2 3 4 5 6 7 8 9 #include &amp;lt;sys/socket.h&amp;gt; ssize_t recv(int sockfd, void *buf, size_t nbytes, int flags); /* 成功时返回接收的字节数（收到 EOF 返回 0），失败时返回 -1 sockfd: 表示数据接受对象的连接的套接字文件描述符 buf: 保存接受数据的缓冲地址值 nbytes: 可接收的最大字节数 flags: 接收数据时指定的可选项参数 */ send 和 recv 函数都是最后一个参数是收发数据的可选项，该选项可以用位或（bit OR）运算符（| 运算符）同时传递多个信息。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 12 章 I/O 复用 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-12-%E7%AB%A0-i-o-%E5%A4%8D%E7%94%A8-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 02 Apr 2022 17:38:29 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-12-%E7%AB%A0-i-o-%E5%A4%8D%E7%94%A8-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 12 章 I/O 复用 12.1 基于 I/O 复用的服务器端 12.1.1 多进程服务端的缺点和解决方法 为了构建并发服务器，只要有客户端连接请求就会创建新进程。这的确是实际操作中采用的一种方案，但并非十全十美，因为创建进程要付出很大的代价。这需要大量的运算和内存空间，由于每个进程都具有独立的内存空间，所以相互间的数据交换也要采用相对复杂的方法（IPC 属于相对复杂的通信方法）
I/O 复用技术可以解决这个问题。
12.1.2 理解复用 「复用」在电子及通信工程领域很常见，向这些领域的专家询问其概念，可能会得到如下答复：
在 1 个通信频道中传递多个数据（信号）的技术
「复用」的含义：
为了提高物理设备的效率，只用最少的物理要素传递最多数据时使用的技术
上述两种方法的内容完全一致。可以用纸电话模型做一个类比：
上图是一个纸杯电话系统，为了使得三人同时通话，说话时要同事对着两个纸杯，接听时也需要耳朵同时对准两个纸杯。为了完成 3 人通话，可以进行如下图的改进：
如图做出改进，就是引入了复用技术。
复用技术的优点：
减少连线长度 减少纸杯个数 即使减少了连线和纸杯的量仍然可以进行三人同时说话，但是如果碰到以下情况：
「好像不能同时说话？」
实际上，因为是在进行对话，所以很少发生同时说话的情况。也就是说，上述系统采用的是**「时分复用」**技术。因为说话人声频率不同，即使在同时说话也能进行一定程度上的区分（杂音也随之增多）。因此，也可以说是「频分复用技术」。
12.1.3 复用技术在服务器端的应用 纸杯电话系统引入复用技术之后可以减少纸杯数量和连线长度。服务器端引入复用技术可以减少所需进程数。下图是多进程服务端的模型：
下图是引入复用技术之后的模型：
从图上可以看出，引入复用技术之后，可以减少进程数。重要的是，无论连接多少客户端，提供服务的进程只有一个。
12.2 理解 select 函数并实现服务端 select 函数是最具代表性的实现复用服务器的方法。在 Windows 平台下也有同名函数，所以具有很好的移植性。
12.2.1 select 函数的功能和调用顺序 使用 select 函数时可以将多个文件描述符集中到一起统一监视，项目如下：
是否存在套接字接收数据？ 无需阻塞传输数据的套接字有哪些？ 哪些套接字发生了异常？ 术语：「事件」。当发生监视项对应情况时，称「发生了事件」。
select 函数的使用方法与一般函数的区别并不大，更准确的说，他很难使用。但是为了实现 I/O 复用服务器端，我们应该掌握 select 函数，并运用于套接字编程当中。认为「select 函数是 I/O 复用的全部内容」也并不为过。select 函数的调用过程如下图所示：
12.2.2 设置文件描述符 利用 select 函数可以同时监视多个文件描述符。当然，监视文件描述符可以视为监视套接字。此时首先需要将要监视的文件描述符集中在一起。集中时也要按照监视项（接收、传输、异常）进行区分，即按照上述 3 种监视项分成 3 类。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 11 章 进程间通信 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-11-%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 01 Apr 2022 11:40:18 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-11-%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 11 章 进程间通信 进程间通信，意味着两个不同的进程中可以交换数据
11.1 进程间通信的基本概念 11.1.1 通过管道实现进程间通信 下图是基于管道（PIPE）的进程间通信的模型：
可以看出，为了完成进程间通信，需要创建进程。管道并非属于进程的资源，而是和套接字一样，属于操作系统（也就不是 fork 函数的复制对象）。所以，两个进程通过操作系统提供的内存空间进行通信。下面是创建管道的函数。
1 2 3 4 5 6 7 #include &amp;lt;unistd.h&amp;gt; int pipe(int filedes[2]); /* 成功时返回 0 ，失败时返回 -1 filedes[0]: 通过管道接收数据时使用的文件描述符，即管道出口 filedes[1]: 通过管道传输数据时使用的文件描述符，即管道入口 */ 父进程创建函数时将创建管道，同时获取对应于出入口的文件描述符，此时父进程可以读写同一管道。但父进程的目的是与子进程进行数据交换，因此需要将入口或出口中的 1 个文件描述符传递给子进程。下面的例子是关于该函数的使用方法：
pipe1.c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #define BUF_SIZE 30 int main(int argc, char *argv[]) { int fds[2]; char str[] = &amp;#34;Who are you?</description>
    </item>
    
    <item>
      <title>《模式识别&amp;机器学习》课后作业（1）</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E4%BD%9C%E4%B8%9A1/</link>
      <pubDate>Thu, 31 Mar 2022 18:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E4%BD%9C%E4%B8%9A1/</guid>
      <description>《模式识别&amp;amp;机器学习》课后作业 作业一 写一个感知器算法，用来区分1到10里的任意两个数字，并与真实结果进行比较。
代码实现 Perceptron.m(主函数)： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 %Perceptron.</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 10 章 多进程服务器端 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-10-%E7%AB%A0-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 30 Mar 2022 15:59:25 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-10-%E7%AB%A0-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 10 章 多进程服务器端 10.1 进程概念及应用 10.1.1 并发服务端的实现方法 通过改进服务端，使其同时向所有发起请求的客户端提供服务，以提高平均满意度。而且，网络程序中数据通信时间比 CPU 运算时间占比更大，因此，向多个客户端提供服务是一种有效的利用 CPU 的方式。接下来讨论同时向多个客户端提供服务的并发服务器端。下面列出的是具有代表性的并发服务端的实现模型和方法：
多进程服务器：通过创建多个进程提供服务 多路复用服务器：通过捆绑并统一管理 I/O 对象提供服务 多线程服务器：通过生成与客户端等量的线程提供服务 先是第一种方法：多进程服务器
10.1.2 理解进程 进程的定义如下：
占用内存空间的正在运行的程序
假如你下载了一个游戏到电脑上，此时的游戏不是进程，而是程序。只有当游戏被加载到主内存并进入运行状态，这是才可称为进程。
10.1.3 进程 ID 在说进程创建方法之前，先要简要说明进程 ID。无论进程是如何创建的，所有的进程都会被操作系统分配一个 ID。此 ID 被称为「进程ID」，其值为大于 2 的证书。1 要分配给操作系统启动后的（用于协助操作系统）首个进程，因此用户无法得到 ID 值为 1 。接下来观察在 Linux 中运行的进程。
1 ps au 通过上面的命令可查看当前运行的所有进程。需要注意的是，该命令同时列出了 PID（进程ID）。参数 a 和 u列出了所有进程的详细信息。
10.1.4 通过调用 fork 函数创建进程 创建进程的方式很多，此处只介绍用于创建多进程服务端的 fork 函数。
1 2 3 #include &amp;lt;unistd.h&amp;gt; pid_t fork(void); // 成功时返回进程ID,失败时返回 -1 fork 函数将创建调用的进程副本。也就是说，并非根据完全不同的程序创建进程，而是复制正在运行的、调用 fork 函数的进程。另外，两个进程都执行 fork 函数调用后的语句（准确的说是在 fork 函数返回后）。但因为是通过同一个进程、复制相同的内存空间，之后的程序流要根据 fork 函数的返回值加以区分。即利用 fork 函数的如下特点区分程序执行流程。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 9 章 套接字的多种可选项 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-9-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E5%A4%9A%E7%A7%8D%E5%8F%AF%E9%80%89%E9%A1%B9-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 29 Mar 2022 17:37:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-9-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E5%A4%9A%E7%A7%8D%E5%8F%AF%E9%80%89%E9%A1%B9-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 9 章 套接字的多种可选项 9.1 套接字可选项和 I/O 缓冲大小 我们进行套接字编程时往往只关注数据通信，而忽略了套接字具有的不同特性。但是，理解这些特性并根据实际需要进行更改也很重要
9.1.1 套接字多种可选项 我们之前写得程序都是创建好套接字之后直接使用的，此时通过默认的套接字特性进行数据通信，这里列出了一些套接字可选项。
协议层 选项名 读取 设置 SOL_SOCKET SO_SNDBUF O O SOL_SOCKET SO_RCVBUF O O SOL_SOCKET SO_REUSEADDR O O SOL_SOCKET SO_KEEPALIVE O O SOL_SOCKET SO_BROADCAST O O SOL_SOCKET SO_DONTROUTE O O SOL_SOCKET SO_OOBINLINE O O SOL_SOCKET SO_ERROR O X SOL_SOCKET SO_TYPE O X IPPROTO_IP IP_TOS O O IPPROTO_IP IP_TTL O O IPPROTO_IP IP_MULTICAST_TTL O O IPPROTO_IP IP_MULTICAST_LOOP O O IPPROTO_IP IP_MULTICAST_IF O O IPPROTO_TCP TCP_KEEPALIVE O O IPPROTO_TCP TCP_NODELAY O O IPPROTO_TCP TCP_MAXSEG O O 从表中可以看出，套接字可选项是分层的。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 8 章 域名及网络地址 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-8-%E7%AB%A0-%E5%9F%9F%E5%90%8D%E5%8F%8A%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 28 Mar 2022 18:09:27 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-8-%E7%AB%A0-%E5%9F%9F%E5%90%8D%E5%8F%8A%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 8 章 域名及网络地址 8.1 域名系统 DNS 是对IP地址和域名进行相互转换的系统，其核心是 DNS 服务器
8.1.1 什么是域名 域名就是我们常常在地址栏里面输入的地址，将比较难记忆的IP地址变成人类容易理解的信息。
8.1.2 DNS 服务器 相当于一个字典，可以查询出某一个域名对应的IP地址
如图所示，显示了 DNS 服务器的查询路径。
8.2 IP地址和域名之间的转换 8.2.1 程序中有必要使用域名吗？ 一句话，需要，因为IP地址可能经常改变，而且也不容易记忆，通过域名可以随时更改解析，达到更换IP的目的
8.2.2 利用域名获取IP地址 使用以下函数可以通过传递字符串格式的域名获取IP地址
1 2 3 4 5 #include &amp;lt;netdb.h&amp;gt; struct hostent *gethostbyname(const char *hostname); /* 成功时返回 hostent 结构体地址，失败时返回 NULL 指针 */ 这个函数使用方便，只要传递字符串，就可以返回域名对应的IP地址。只是返回时，地址信息装入 hostent 结构体。此结构体的定义如下：
1 2 3 4 5 6 7 8 struct hostent { char *h_name; /* Official name of host. */ char **h_aliases; /* Alias list.</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 7 章 优雅的断开套接字的连接 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-7-%E7%AB%A0-%E4%BC%98%E9%9B%85%E7%9A%84%E6%96%AD%E5%BC%80%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E8%BF%9E%E6%8E%A5-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 26 Mar 2022 11:25:41 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-7-%E7%AB%A0-%E4%BC%98%E9%9B%85%E7%9A%84%E6%96%AD%E5%BC%80%E5%A5%97%E6%8E%A5%E5%AD%97%E7%9A%84%E8%BF%9E%E6%8E%A5-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 7 章 优雅的断开套接字的连接 本章讨论如何优雅的断开套接字的连接，之前用的方法不够优雅是因为，我们是调用 close 函数或 closesocket 函数单方面断开连接的。
7.1 基于 TCP 的半关闭 TCP 的断开连接过程比建立连接更重要，因为连接过程中一般不会出现大问题，但是断开过程可能发生预想不到的情况。因此应该准确掌控。所以要掌握半关闭（Half-close），才能明确断开过程。
7.1.1 单方面断开连接带来的问题 Linux 和 Windows 的 closesocket 函数意味着完全断开连接。完全断开不仅指无法传输数据，而且也不能接收数据。因此在某些情况下，通信一方单方面的断开套接字连接，显得不太优雅。如图所示：
图中描述的是 2 台主机正在进行双向通信，主机 A 发送完最后的数据后，调用 close 函数断开了最后的连接，之后主机 A 无法再接受主机 B 传输的数据。实际上，是完全无法调用与接受数据相关的函数。最终，由主机 B 传输的、主机 A 必须要接受的数据也销毁了。
为了解决这类问题，「只关闭一部分数据交换中使用的流」的方法应运而生。断开一部分连接是指，可以传输数据但是无法接收，或可以接受数据但无法传输。顾名思义就是只关闭流的一半。
7.1.2 套接字和流（Stream） 两台主机通过套接字建立连接后进入可交换数据的状态，又称「流形成的状态」。也就是把建立套接字后可交换数据的状态看作一种流。
此处的流可以比作水流。水朝着一个方向流动，同样，在套接字的流中，数据也止呕能向一个方向流动。因此，为了进行双向通信，需要如图所示的两个流：
一旦两台主机之间建立了套接字连接，每个主机就会拥有单独的输入流和输出流。当然，其中一个主机的输入流与另一个主机的输出流相连，而输出流则与另一个主机的输入流相连。另外，本章讨论的「优雅的断开连接方式」只断开其中 1 个流，而非同时断开两个流。Linux 和 Windows 的 closesocket 函数将同时断开这两个流，因此与「优雅」二字还有一段距离。
7.1.3 针对优雅断开的 shutdown 函数 shutdown 用来关闭其中一个流：
1 2 3 4 5 6 7 #include &amp;lt;sys/socket.h&amp;gt; int shutdown(int sock, int howto); /* 成功时返回 0 ，失败时返回 -1 sock: 需要断开套接字文件描述符 howto: 传递断开方式信息 */ 调用上述函数时，第二个参数决定断开连接的方式，其值如下所示：</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 6 章 基于 UDP 的服务端/客户端 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-6-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-udp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 25 Mar 2022 16:10:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-6-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-udp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 6 章 基于 UDP 的服务端/客户端 TCP 是内容较多的一个协议，而本章中的 UDP 内容较少，但是也很重要。
6.1 理解 UDP 6.1.1 UDP 套接字的特点 通过寄信来说明 UDP 的工作原理，这是讲解 UDP 时使用的传统示例，它与 UDP 的特点完全相同。寄信前应现在信封上填好寄信人和收信人的地址，之后贴上邮票放进邮筒即可。当然，信件的特点使我们无法确认信件是否被收到。邮寄过程中也可能发生信件丢失的情况。也就是说，信件是一种不可靠的传输方式，UDP 也是一种不可靠的数据传输方式。
因为 UDP 没有 TCP 那么复杂，所以编程难度比较小，性能也比 TCP 高。在更重视性能的情况下可以选择 UDP 的传输方式。
TCP 与 UDP 的区别很大一部分来源于流控制。也就是说 TCP 的生命在于流控制。
6.1.2 UDP 的工作原理 如图所示：
从图中可以看出，IP 的作用就是让离开主机 B 的 UDP 数据包准确传递到主机 A 。但是把 UDP 数据包最终交给主机 A 的某一 UDP 套接字的过程是由 UDP 完成的。UDP 的最重要的作用就是根据端口号将传到主机的数据包交付给最终的 UDP 套接字。
6.1.3 UDP 的高效使用 UDP 也具有一定的可靠性。对于通过网络实时传递的视频或者音频时情况有所不同。对于多媒体数据而言，丢失一部分数据也没有太大问题，这只是会暂时引起画面抖动，或者出现细微的杂音。但是要提供实时服务，速度就成为了一个很重要的因素。因此流控制就显得有一点多余，这时就要考虑使用 UDP 。TCP 比 UDP 慢的原因主要有以下两点：</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 5 章 基于 TCP 的服务端/客户端（2） 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-5-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-tcp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF2-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 24 Mar 2022 15:57:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-5-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-tcp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF2-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 5 章 基于 TCP 的服务端/客户端（2） 上一章仅仅是从编程角度学习实现方法，并未详细讨论 TCP 的工作原理。因此，本章将想次讲解 TCP 中必要的理论知识，还将给出第 4 章客户端问题的解决方案。
5.1 回声客户端的完美实现 5.1.1 回声服务器没有问题，只有回声客户端有问题？ 问题不在服务器端，而在客户端，只看代码可能不好理解，因为 I/O 中使用了相同的函数。先回顾一下服务器端的 I/O 相关代码：
1 2 while ((str_len = read(clnt_sock, message, BUF_SIZE)) != 0) write(clnt_sock, message, str_len); 接着是客户端代码:
1 2 write(sock, message, strlen(message)); str_len = read(sock, message, BUF_SIZE - 1); 二者都在村换调用 read 和 write 函数。实际上之前的回声客户端将 100% 接受字节传输的数据，只不过接受数据时的单位有些问题。扩展客户端代码回顾范围，下面是，客户端的代码:
1 2 3 4 5 6 7 8 9 10 11 12 13 while (1) { fputs(&amp;#34;Input message(Q to quit): &amp;#34;, stdout); fgets(message, BUF_SIZE, stdin); if (!</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 4 章 基于 TCP 的服务端/客户端（1） 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-4-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-tcp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF1-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 20 Mar 2022 13:10:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-4-%E7%AB%A0-%E5%9F%BA%E4%BA%8E-tcp-%E7%9A%84%E6%9C%8D%E5%8A%A1%E7%AB%AF-%E5%AE%A2%E6%88%B7%E7%AB%AF1-%E7%AC%94%E8%AE%B0/</guid>
      <description>第 4 章 基于 TCP 的服务端/客户端（1） 4.1 理解 TCP 和 UDP 根据数据传输方式的不同，基于网络协议的套接字一般分为 TCP 套接字和 UDP 套接字。因为 TCP 套接字是面向连接的，因此又被称为基于流（stream）的套接字。
TCP 是 Transmission Control Protocol （传输控制协议）的简写，意为「对数据传输过程的控制」。因此，学习控制方法及范围有助于正确理解 TCP 套接字。
4.1.1 TCP/IP 协议栈 TCP/IP 协议栈共分为 4 层，可以理解为数据收发分成了 4 个层次化过程，通过层次化的方式来解决问题
4.1.2 链路层 链路层是物理链接领域标准化的结果，也是最基本的领域，专门定义LAN、WAN、MAN等网络标准。若两台主机通过网络进行数据交换，则需要物理连接，链路层就负责这些标准。
4.1.3 IP 层 转备好物理连接候就要传输数据。为了再复杂网络中传输数据，首先要考虑路径的选择。向目标传输数据需要经过哪条路径？解决此问题的就是IP层，该层使用的协议就是IP。
IP 是面向消息的、不可靠的协议。每次传输数据时会帮我们选择路径，但并不一致。如果传输过程中发生错误，则选择其他路径，但是如果发生数据丢失或错误，则无法解决。换言之，IP协议无法应对数据错误。
4.1.4 TCP/UDP 层 IP 层解决数据传输中的路径选择问题，秩序照此路径传输数据即可。TCP 和 UDP 层以 IP 层提供的路径信息为基础完成实际的数据传输，故该层又称为传输层。UDP 比 TCP 简单，现在我们只解释 TCP 。 TCP 可以保证数据的可靠传输，但是它发送数据时以 IP 层为基础（这也是协议栈层次化的原因）
IP 层只关注一个数据包（数据传输基本单位）的传输过程。因此，即使传输多个数据包，每个数据包也是由 IP 层实际传输的，也就是说传输顺序及传输本身是不可靠的。若只利用IP层传输数据，则可能导致后传输的数据包B比先传输的数据包A提早到达。另外，传输的数据包A、B、C中可能只收到A和C，甚至收到的C可能已经损毁 。反之，若添加 TCP 协议则按照如下对话方式进行数据交换。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 3 章 网络地址的初始化与分配 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-3-%E7%AB%A0-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E5%88%86%E9%85%8D-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sat, 19 Mar 2022 13:13:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-3-%E7%AB%A0-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E5%88%86%E9%85%8D-%E7%AC%94%E8%AE%B0/</guid>
      <description>第三章.地址族与数据序列 3.1 分配给套接字的ip地址与端口号 IP是为了收发网络数据而分配给计算机的值；端口号是为了区分程序中创建的套接字的序号。
3.1.1 网络地址 IP地址分为两类：
Ipv4：4字节地址 IPv6：16字节地址 地址分为网络号和主机号： 3.1.2 网络地址分类与主机地址边界 只需通过IP地址的第一个字节即可判断网络地址占用的总字节数，因为我们根据IP地址的边界区分网络地址，如下所示：
A 类地址的首字节范围为：0~127
B 类地址的首字节范围为：128~191
C 类地址的首字节范围为：192~223 还有如下这种表示方式：
A 类地址的首位以 0 开始
B 类地址的前2位以 10 开始
C 类地址的前3位以 110 开始
3.1.3 用于区分套接字的端口号 端口号用于同一操作系统内区分不同的套接字而设立的。端口号由16位构成，范围为0～65536，但0～1023是知名端口，一般分配给特定应用程序。
虽然端口号不能重复，但是 TCP 套接字和 UDP 套接字不会共用端接口号，所以允许重复。
3.2 地址信息的表示 3.2.1 IPv4地址结构体 结构体的定义:
1 2 3 4 5 6 7 struct sockaddr_in { sa_family_t sin_family; //地址族（Address Family） uint16_t sin_port; //16 位 TCP/UDP 端口号 struct in_addr sin_addr; //32位 IP 地址 char sin_zero[8]; //不使用 }; 该结构体中提到的另一个结构体 in_addr 定义如下，它用来存放 32 位IP地址:</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 2 章 套接字类型与协议设置 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-2-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8D%8F%E8%AE%AE%E8%AE%BE%E7%BD%AE-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 18 Mar 2022 11:15:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-2-%E7%AB%A0-%E5%A5%97%E6%8E%A5%E5%AD%97%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8D%8F%E8%AE%AE%E8%AE%BE%E7%BD%AE-%E7%AC%94%E8%AE%B0/</guid>
      <description>第二章.套接字类型和协议设置 2.1 套接字类型和数据传输特性 如果两个端口需要通信，必须使用相同的协议。协议就是为了完成数据交换定好的约定。
2.1.1 创建套接字 1 2 3 4 5 6 7 8 #include &amp;lt;sys/socket.h&amp;gt; int socket(int domain, int type, int protocol); /* 成功时返回文件描述符，失败时返回-1 domain: 套接字中使用的协议族（Protocol Family） type: 套接字数据传输的类型信息 protocol: 计算机间通信中使用的协议信息 */ 2.1.2 协议族 协议族其实就是协议分类信息。
头文件sys/socket.h中声明的协议族
名称 协议族 PF_INET IPV4互联网协议族 PF_INET6 IPV6互联网协议族 PF_LOCAL 本地通信Unix协议族 PF_PACKET 底层套接字的协议族 PF_IPX IPX Novel协议族 本书着重讲 PF_INET 对应的 IPV4 互联网协议族。其他协议并不常用，或并未普及。另外，套接字中采用的最终的协议信息是通过 socket 函数的第三个参数传递的。在指定的协议族范围内通过第一个参数决定第三个参数。
2.1.3 面向连接的套接字（SOCK_DGRAM） 首先说明，socket函数的第一个参数决定使用的协议族，第二个参数指定数据传输类型。也就是说一个协议族中有多种传输方式。
面向连接的数据传输方式特征（有连接）：
传输过程中数据不会消失 按序传输数据 传输的数据不存在数据边界（Boundary） 这里的不存在数据边界是指接收方会制定数据的大小，但发送方不需要一次性发送这么大的消息，可以分多次传输。接收方可以在没有达到指定大小就接受数据，也可以收集够指定大小的数据才会打包接收数据！
收发数据的套接字内部有缓冲（buffer），简言之就是字节数组。只要不超过数组容量，那么数据填满缓冲后过 1 次 read 函数的调用就可以读取全部，也有可能调用多次来完成读取。</description>
    </item>
    
    <item>
      <title>《TCP/IP网络编程》第 1 章 理解网络编程和套接字 笔记</title>
      <link>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-1-%E7%AB%A0-%E7%90%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%92%8C%E5%A5%97%E6%8E%A5%E5%AD%97-%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 17 Mar 2022 13:12:00 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/tcp-ip%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC-1-%E7%AB%A0-%E7%90%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%92%8C%E5%A5%97%E6%8E%A5%E5%AD%97-%E7%AC%94%E8%AE%B0/</guid>
      <description>第一章.理解网络编程和套接字 系统环境：CentOS 7 宿主机：macOS Big Sur
1.1 理解网络编程和套接字 1.1.1 “打电话”过程 服务器端：
1.调用socket函数创建套接字 2.调用bind函数分配IP地址和端口号 3.调用listen函数转为可接收请求状态 4.调用accept函数受理连接请求 客户端：
1.调用socket函数创建套接字 2.调用connect函数向服务器端发送连接请求 1.1.2 实操 文件编写：
hello_server.c hello_client.c 进入文件所在的根目录，编译并进行“打电话”：
服务器端： 1 2 gcc hello_server.c -o hserver //编译生成hserver ./hserver 9190 //运行hserver生成9190端口等待客户端的连接请求 客户端(这里的ip地址为服务器端的ip地址)： 1 2 gcc hello_client.c -o hclient //编译生成hserver ./hclient 172.16.127.128 9190 //运行hserver生成9190端口等待客户端的连接请求 结果：服务器端输出“Hello World!”
注意：
1.服务端和客户端要分开：如果为同一台电脑，可以使用两个终端进行；如果不同的电脑需要搞清楚输入ip为服务端的本地ip。
2.通过终端ifcong，查看分配的本地ip
3.顺序一定是先服务器端再客户端
4.运行一次过后就需要更改服务器的端口号
1.2 基于Linux的文件操作 在Linux中，socket也被认为是一种文件，因此在网络数据传输时可以使用文件I/O的相关函数，而Windows需要调用特殊的数据传输相关的函数。
1.2.1 文件描述符 文件描述符是指为了方便称呼操作系统创建的文件或套接字而赋予的数。
1.2.2 打开/关闭/读/写文件/文件描述符和套接字 打开文件用open函数 打开模式有5种：
打开模式 含义 O_CREAT 必要时创建文件 O_TRUNC 删除全部现有数据 O_APPEND 维持现有数据，保存到其后面 O_RDONLY 只读打开 O_WRONLY 只写打开 O_RDWR 读写打开 关闭文件使用close函数 数据写入使用write函数 数据读取使用read函数 创建文件和套接字，并用整数形态比较返回的文件描述符值 1.</description>
    </item>
    
    <item>
      <title>《数字图像处理》第三章——图像增强</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/</link>
      <pubDate>Mon, 14 Mar 2022 19:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/</guid>
      <description>《数字图像处理》第三章——图像增强 图像增强是突出图像中的某些部分，将图像变得易于人眼观察，通常用于去噪，平滑，锐化，阈值处理。
处理方式：
空间域处理 点处理 邻域处理 频率域处理 点像素处理法 阈值处理：最常用的是二分阈值，也就是像素值大于某个阈值全部变成255，小于该阈值全部变成0。 图像反转：常用于灰度图的黑白反转，使得想要显示的图像细节变成低像素值，其他变成高像素值，公式如下： $$ s = L - 1 -r $$ 伽马校正：原理是将图像的像素点再有效范围内分布更加均匀。它通常用于常用显示器显示图像或者对整体过亮的图像进行延展。公式如下： $$ s = cr^{\gamma} $$ 注：这里通过调整上标伽马的参数来进行校正 像素拉伸：原理是在低像素和高像素区域的像素值都乘以一个小于1的系数，处于中间像素区域的像素值都乘以一个大于1的系数。 图像均衡 直方图均衡化 直方图的定义：横坐标为像素值，纵坐标为像素的个数。 直方图归一化：横坐标依然为像素值，纵坐标变成了该像素值出现的概率。 直方图的目的是通过一个函数来使原图像的直方图分布从不均匀到一个均匀分布，公式如下： $$ s = T(r) = (L - 1)\int_{0}^{r}P_{r}(w)dw $$
注：其中L为256（8bit的最大数加1），P为概率分布函数
该函数为一个递增函数，由旧的像素值（整数）变成新的像素值（浮点数），又一个取整的过程，所以直方图均衡化之后，直方图分布并不是完全平均
直方图匹配 直方图匹配是指给定一张图像，要将其直方图分布变换成特定直方图分布。
直方图匹配的实现：
1.先对原图像进行直方图均衡化处理，得到结果T 2.对目标直方图进行直方图均衡化处理，得到映射关系 3.对T进行步骤2的逆映射处理 邻域矩阵处理法 这也就是我们通常所说的滤波。通常使用一个n×n矩阵和图像中的所有n×n子块进行求内积的操作
均值滤波（局部）：使用全为1的矩阵进行求内积。注意矩阵乘法之前必须进行归一化，防止数据超过原有的范围。 $$\sum_{i}(a - a_{i})^2取最小时就是其均值（误差较大）$$
高斯滤波：使用高斯滤波进行局部平均，相当于离中间像素值越大的其权重分配的越小，差值越小的权重分配的越大。
中值滤波：对图像的n×n子块，排序取中间值来替代原像素的值。（通常用于去除椒盐噪声，效果很好）
$$\sum_{i}\lvert a - a_{i} \rvert取最小时就是其中值（误差鲁棒性更小）$$
非局部均值滤波：根据图像的自相似性，我们可以将相似的局部区域一起做一个平均。 1 2 3 4 5 6 7 -p0指所有相似区域p1～pn的相同的部分 -s1～sn指所有区域不同的部分 p1 = p0 + s1 p2 = p0 + s2 ··· pn = p0 + sn 如何进行相似区域的寻找？</description>
    </item>
    
    <item>
      <title>Open cv模块学习</title>
      <link>https://caixiongjiang.github.io/blog/2022/opencv%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 04 Mar 2022 18:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/opencv%E5%AD%A6%E4%B9%A0/</guid>
      <description>图像基本操作 数据读取-图像 cv2.IMREAD_COLOR:彩色图像 cv2.IMREAD_GRAYSCALE:灰度图像 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import cv2 as cv # opencv模块，读取图片的的格式是BGR import matplotlib.pyplot as plt # 制做图表的模块 import numpy as np # 数据处理模块 img1 = cv.imread(&amp;#34;cat.jpg&amp;#34;) # 读取图片（彩色图片） # 输出img1为一个三个的二维矩阵，dtype为 uint8（代表0～255之间的整数） # 图像的显示 cv.imshow(&amp;#34;image&amp;#34;, img1) #参数：（图片标题，图片名） # 等待时间，毫秒级，0表示按任意键终止图像显示 cv.watKey(0) cv.destroyAllWindows() # 可以将显示图像放到一个函数当中 def cv_show(name, img): cv.</description>
    </item>
    
    <item>
      <title>《Effective C&#43;&#43;》导读&amp;条款1~3</title>
      <link>https://caixiongjiang.github.io/blog/2022/effective-c&#43;&#43;/effective-c&#43;&#43;%E5%AF%BC%E8%AF%BB%E6%9D%A1%E6%AC%BE1~3/</link>
      <pubDate>Tue, 01 Mar 2022 18:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/effective-c&#43;&#43;/effective-c&#43;&#43;%E5%AF%BC%E8%AF%BB%E6%9D%A1%E6%AC%BE1~3/</guid>
      <description>《Effective c++》学习笔记 导读部分 正式开始55条条款之前，这本书的目的是为了让c++程序员如何写出更加安全高效的程序准备的，属于进阶书籍，如果观看本书还有很多不明白的地方，还需要去学基础，推荐《c++ Primer》,看本书前需要知道的有：c++面向过程，c++面向对象，c++泛型编程，c++ STL标准库， c++多线程编程。
术语 1.std命名空间是几乎所有c++标准程序库元素的栖息地，所以在导入c++头文件的时候，一定要在std命名空间内写程序
2.size_t是一个typedef，是c++计算个数（字符串内的个数或者STL容器内的元素个数）时使用的，它属于无符号整数
3.一个类的构造函数使用explicit关键字可以阻止它们被用来隐式类型转换，但他们仍然可被用于显示类型转化。被声明为explicit关键字的构造函数通常比没有它更受欢迎，因为它们禁止编译器执行非预期的类型
demo：
头文件（.h）:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 class A{ public: A(); //default构造函数 }; class B{ public: explicit B(int x = 0, bool b = true);//default构造函数 两个参数都已经设置默认值 }; class C{ public: explicit C(int x);//不是default构造函数 }; 执行文件（.cpp）:
1 2 3 4 5 6 7 8 9 10 void doSomething(B bObject); //函数声明，接收一个类型为B的对象 B bObj1; doSomething(bObj1); B bObj2(28);//正确，根据int28建立一个B doSomething(28);//错误！doSomething应该接收一个B //int至B之间没有隐式类型转化 doSomething(B(28));//正确，使用B构造函数将int显示转换 4.</description>
    </item>
    
    <item>
      <title>《数字图像处理》第二章——图像压缩</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/</link>
      <pubDate>Mon, 28 Feb 2022 18:07:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/</guid>
      <description>《数字图像处理》第二章——图像压缩 图像压缩基本概念 压缩比： Cr = n1 / n2 相对数据冗余： Rd = 1 - 1 / Cr 无损压缩： 压缩编码冗余和像素冗余称为无损压缩 图像压缩标准（包括视频） 主流的静态图像压缩标准（JPEG家族）：JPEG, JPEG-LS(无损压缩), JPEG-2000 主流的视频压缩标准（MPEG家族）：MPEG-1, MPEG-2, MPEG-3, MPEG-4 AVC 图像压缩的流程 以JPEG的压缩流程为例：
输入的图像——&amp;gt;图像分块——&amp;gt;映射器——&amp;gt;量化器——&amp;gt;编码器 解码器——&amp;gt;反映射——&amp;gt;输出图片 量化器是该过程中唯一对图像质量有损耗的
JPEG压缩 编码器 JPEG使用的是哈夫曼编码，哈夫曼编码得到的是一种无前缀编码，这会使得出现概率越高的元素编码长度越短，出现概率越低的元素编码长度越长，最后总的编码长度编程最短
哈夫曼编码使用规则：
1.每次取集合中最小的两个值，相加之后再加入原有的集合，再重复取最小的两个值，到最后只剩一个元素 2.将原有集合的数字进行编码，层数越高，编码长度越短 在JPEG中应用为：对像素出现的概率高低进行编码！
demo：
a1 - 0.4 a2 - 0.3 a3 - 0.1 对应编码： a1 - 1 a2 - 01 a3 - 00 编码熵：$ -\sum_{i = 1}^n p(s)log_2^{p(s)}$ （概率*对应的自信息）
图像分块 在JPEG中采用8✖️8的小块进行分别处理，这么做的原因是分别对小块进行处理比对整张图像进行处理更加高效、
若JPEG为RGB的彩色图像，我们需要先将RGB通道转化为YCbCr通道，再对每个通道进行分块处理
模式“RGB”转换为“YCbCr”的公式如下：
Y= 0.</description>
    </item>
    
    <item>
      <title>Linux环境搭建：虚拟机上运行CentOS</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/linux%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Sun, 30 Jan 2022 20:55:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/linux%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>为什么选择CentOS环境而不选择Ubuntu 原本我的windows笔记本上已经装了Ubuntu,已经有了Linux环境。
最近听了网上大佬的说法，说国内的互联网公司基本都在使用另一个Linux操作系统CentOS,加之其比Ubuntu更加稳定，最重要的是可视化界面更少，这一点是我选择它的原因。
windows端部署 大家有mac就用mac，没有条件就用windows，毕竟macbook这么贵。
不得不说mac系统真的比windows好用很多，特别是配置环境和下载软件这方面真的有些操蛋！
软件准备 1.虚拟机软件VMware workstation
社区免费版下载地址：	https://customerconnect.vmware.com/en/downloads/info/slug/desktop_end_user_computing/vmware_workstation_player/16_0
2.CentOS 7 镜像文件：
复制这段内容后打开百度网盘手机App，操作更方便哦 链接：https://pan.baidu.com/s/1tmxews_LiAWS9DXLIi8egA 提取码：6wZd
3.SSH终端连接工具：
因为SecurCRT软件不是免费的，需要破解，windows端找软件真的找破天，非常多站点下的都有问题，甚至有病毒。我在这里提供两种下载方式，安装版和解压版：
Securecrt安装版破解版 v8.5下载地址：https://www.32r.com/soft/49437.html
此种方式的破解方法视频：https://www.bilibili.com/video/BV1QC4y1H7zR?spm_id_from=333.1007.top_right_bar_window_history.content.click
注意注册机文件的放入位置和patch，以及各种信息的填写。如果这种方式无效，就直接去下解压版吧。
Securecrt解压版下载地址：
复制这段内容后打开百度网盘手机App，操作更方便哦 链接：https://pan.baidu.com/s/1ebeOqNtbdEkGVdJOCOvAQQ 提取码：6wZd
解压完就可以使用了。
4.SFTP传输工具WinSCP:
这个软件可以在windows端和Linux端传文件的工具，下载地址：https://winscp.net/eng/docs/guide_install#downloading
CentOS安装 首先说一下用虚拟机安装系统的好处：
如果系统被你玩坏了，重新装就好了，不会让你的电脑的文件丢失，而如果装双系统极有可能会丢失文件。 而虚拟机可以设置多个节点，可以做服务器集群，而双系统就只能用一个。 如果你觉得虚拟机装Linux没得灵魂，记住你这句话，你会说“真香“的！ 1.安装好虚拟机软件之后，打开，点击新建虚拟机，浏览找到安装镜像源的位置，点击下一步，输入节点的名字
2.设置好登录的用户名和密码以及root密码（root密码要记住，以后在命令行中使用root操作需要输入此密码）
3.进入一段黑屏绿字的安装时间之后进入设置安装内容界面。
安装设置界面：
语言支持选择中文，安装位置选择自动配置分区，然后再点击软件选择，考虑到以后可能用到很多服务器开发有关的东西，我选择开发及生成工作站，勾选如下选项。
然后开始你漫长的安装过程，出现如下画面,就代表装好了。
初始界面：
检查连通性以及SSH连接 在windows端一般来说都是直接配好的，可以通过命令行检查与外网和宿主机的连通性：
与外网连通性：
1 $ ping www.baidu.com 如果出现跳出毫秒信息等信息，说明已经连通了，按Ctrl+c取消。
如果跳出未知的名称或服务，说明不连通
与宿主机连通性：
Linux连接宿主机：
1.宿主机按Ctrl+R，输入cmd运行，输入：
1 ipconfig/all 找到ipv4地址，复制，在命令行输入：
1 $ ping 192.168.31.11 查看连通性。
宿主机连接Linux：
1.在Linux命令行输入：
1 ifconfig 出现如下画面：
复制第一个inet后面的ip地址，注意这个ip地址虽然是DHCP动态分配的，但在windows上基本每次分配都是同一个ip地址
然后打开windows终端，输入：
1 ping 192.</description>
    </item>
    
    <item>
      <title>Docsify：最简易的知识库生成器</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/docsify%E7%9F%A5%E8%AF%86%E5%BA%93%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 28 Jan 2022 16:15:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/docsify%E7%9F%A5%E8%AF%86%E5%BA%93%E6%90%AD%E5%BB%BA/</guid>
      <description>我的个人知识库搭建：蜜蜂网 docsify是一款比Hugo更加轻便的网站部署软件，它比Hugo少了生成html文件这一步，而且少了许多配置文件，真正的本地文件也就只有几个。
许多人用它来搭建博客，但我认为正因为它参数配置很少，不利于搭建自己想要的风格，反而作为自己的知识库会更加便利。我们都不想哪里忘了去翻那厚重的书本吧！
下面是一些参考网站：
docsify官网 Codesheep程序羊关于个人知识库搭建的b站视频 为了书写方便，后文中提到的命令在windows端在Git中运行，在mac端在terminal中运行。
环境配置 Node.js安装 Node.js是为你使你的电脑上确保有npm工具，因为docsify的安装需要用到npm工具。
Node.js官网下载地址 下载安装好之后，可以查看一下npm是否已经安装好了：
windows端：在桌面点击右键，选择Git bash here，如果出现了，其实就已经安装好了。如果不放心还是可以输入：
1 npm -v 如果出现了版本号信息，则表示已经安装好了。
mac端：打开终端terminal同样输入上述的命令：
1 npm -v 如果出现了版本号信息，则表示已经安装好了。
docsify安装 这里的docsify安装其实安装的是它的二进制命令行工具。
windows/mac端输入：
1 npm install -g docsify-cli 安装完成后输入：
1 docsify -v 如果出现版本号则说明安装好了。
新建站点 这里用我的站点名称jarson-cai-blog作为例子：
1.新建知识库的文件夹jarson-cai-blog
2.使用命令行工具进入知识库文件夹（根据你的路径不同而不同），并对其进行初始化，输入：
1 2 3 cd Desktop/jarson-cai-blog docsify init y //提示你是否初始化，选择y 你的站点已经生成了，进入之后会有两个文件，一个是html文件，一个是Markdown文件。
本地启动服务端口（https） 这个功能主要用于修改配置参数时，查看预览效果的功能，是非常重要的。
输入：
1 docsify serve 会提示Web Server is available at //localhost:3000/，复制//localhost:3000/在网页端预览。
写知识库文件 docsify统一采用Markdown格式进行书写。而且其中的语法与markdown基本一致，没有个人特殊的配置。
新建Github仓库，作为部署网站的仓库 注意事项：新建的仓库名必须与你的github用户名相同，以我的github名字caixiongjiang为例。
我的仓库名为：caixiongjiang.github.io，点击创建，注意先不要生成README.md文件，否则你在第一次推送文件前还需要先拉取文件。
如果你没有VPN，不能稳定访问github，可以使用Gitee，这个仓库名就没有限制了
生成知识库站点 这里特别要说的一点就是docsify不需要生成站点，也就是没有Hugo中有.</description>
    </item>
    
    <item>
      <title>Hugo：最轻量级博客框架</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Wed, 26 Jan 2022 10:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/hugo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
      <description>我的Hugo博客搭建 原本想使用hexo搭建我的个人静态博客，但是前两天使用了之后发现写了大量文章之后生成博客会特别慢。
所以采用了新的基于go语言的博客框架Hugo来搭建我的个人博客
下面是一些参考文档：
Hugo官网 Hugo中文文档 Codesheep程序羊关于Hugo博客搭建的b站视频 环境配置 Git安装 这个工具是在后序部署博客到github pages上必须的，mac端和windows端都是ok的
Git官网下载地址 下载安装好之后，可以查看一下Git是否已经安装好了：
windows端：在桌面点击右键，选择Git bash here，如果出现了，其实就已经安装好了。如果不放心还是可以输入：
1 git version 如果出现了版本号信息，则表示已经安装好了。
mac端：打开终端terminal同样输入上述的命令：
1 git version 如果出现了版本号信息，则表示已经安装好了。
Hugo安装 Hugo安装总共有两种方式：
1.文件下载方式（Linux，mac，windows）：
Hugo最新releases版本下载官网
2.命令行下载的方式：
​	Hugo普通版本：
windows端：最好采用文件下载方式，因为后续还要找到hugo.exe的地址，并配置环境变量。
mac端：使用brew安装：
1 brew install hugo Hugo配置 这是windows端特有的步骤(与java的jdk配置相似)：
1.找到安装好的hugo.exe
2.点击复制文件路径
3.找到到windows系统设置的高级系统设置，点击环境变量,在用户变量的path中添加你复制好的hugo路径,应用了之后就配好了
4.右键桌面，点击Git bash here，输入
1 hugo version 若能显示版本信息，就说明安装成功了。
Hugo扩展版本： 这个是否选择安装与你安装的主题有关，如果你选择的主题需要扩展版本，那么就需要安装，如果不需要则忽略这个模块的内容！
windows端：
1.在桌面右键Git bash here输入：
1 iwr -useb get.scoop.sh | iex 如果出错了，就输入：
1 Set-ExecutionPolicy RemoteSigned -scope CurrentUser 2.使用scoop安装扩展版本，输入:
1 scoop install hugo-extended mac端：我没有试过，应该命令是差不多的</description>
    </item>
    
    <item>
      <title>我的力扣刷题笔记</title>
      <link>https://caixiongjiang.github.io/blog/2021/%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%E5%AE%9E%E4%B9%A0%E6%84%9F%E6%82%9F/%E6%88%91%E7%9A%84%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 26 Aug 2021 10:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2021/%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%E5%AE%9E%E4%B9%A0%E6%84%9F%E6%82%9F/%E6%88%91%E7%9A%84%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/</guid>
      <description>本仓库代码攻略部分在代码随想录的基础上写的 转载自代码随想录主页 仅用于个人学习。
强烈推荐小白的刷题顺序，经过上万网友的印证！
🌱vim命令使用指南，让你摆脱鼠标敲代码
🌱力扣周赛+双周赛 数组 🔥关于数组 🔥二分法 🔥移除元素 🔥滑动窗口 🔥螺旋矩阵(绕晕人的循环) 链表 🔥关于链表 🔥移除链表元素 🔥链表的常用操作 🔥反转链表 🔥删除倒数第N个节点(经典双指针法) 🔥寻找环的入口 哈希表 🔥关于哈希表 🔥用数组实现哈希表（表长固定的情况） 🔥Set使用：两个数组的交集 🔥用Set来判断快乐数 🔥map使用：两数之和 🔥map使用：四数相加Ⅱ 🔥map使用：赎金信 🔥map使用：三数之和 字符串 🔥简单字符串反转 🔥进阶字符串反转 🔥替换空格 🔥翻转字符串里的单词(花式翻转) 🔥左旋字符串 🔥KMP算法核心：next数组的生成 栈与队列 🔥关于栈和队列 🔥用栈实现队列 🔥用队列实现栈 🔥栈的应用(括号匹配) 🔥栈的应用(删除字符串中所有相邻重复项，本质同为匹配问题) 🔥栈的应用(计算后缀表达式) 🔥队列应用(单调队列经典题目) 🔥前k个高频元素和队列有什么关系 二叉树 二叉树的题目类型分类：
🔥关于二叉树 🔥二叉树的递归遍历 🔥二叉树的迭代遍历 🔥二叉树的层序遍历 🔥翻转二叉树 🔥判断二叉树是否对称 🔥求树的最大深度 🔥求树的最小深度 🔥完全二叉树的节点个数 🔥判断是否是平衡二叉树 🔥寻找二叉树的所有路径 🔥二叉树的左叶子值之和 🔥二叉树：判断是否存在根节点到叶子节点值的和等于给定值 🔥二叉树：找到所有根节点到叶子节点值的和等于给定值的所有路径 🔥构造二叉树(中序+后序) 🔥构造二叉树(前序+中序) 🔥构造最大的二叉树 🔥合并两个二叉树 🔥二叉搜索树：搜索给定的值的节点为根节点的子树 🔥判断是否为二叉搜索树 🔥搜索树的最小绝对差 🔥二叉搜索树中的众数 🔥二叉树的最近公共祖先 🔥二叉搜索树的最近公共祖先 🔥二叉搜索树中的插入操作 🔥二叉搜索树中的删除操作 🔥修剪二叉搜索树 🔥有序数组构造二叉搜索树 🔥二叉搜索树转换为累加树 回溯算法 题目类型大纲如下： 🔥关于回溯算法 🔥回溯算法：组合问题 🔥回溯算法：组合总和Ⅲ 🔥回溯算法:电话号码的字母组合 🔥回溯算法:求组合总和(二) 🔥回溯算法:求组合总和(三) 🔥回溯算法:分割回文串 🔥回溯算法:复制IP地址 🔥回溯算法:子集 🔥回溯算法:子集Ⅱ 🔥回溯算法:递增子序列 🔥回溯算法:全排列 🔥回溯算法:全排列Ⅱ (!</description>
    </item>
    
  </channel>
</rss>
