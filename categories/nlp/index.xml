<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on 🌀Jarson Cai&#39;s Blog</title>
    <link>https://caixiongjiang.github.io/categories/nlp/</link>
    <description>Recent content in NLP on 🌀Jarson Cai&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 25 Aug 2024 18:18:05 +0800</lastBuildDate><atom:link href="https://caixiongjiang.github.io/categories/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Advanced-RAG: RAG进阶使用技巧</title>
      <link>https://caixiongjiang.github.io/blog/2024/rag/advanced_rag/</link>
      <pubDate>Sun, 25 Aug 2024 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2024/rag/advanced_rag/</guid>
      <description>Naive RAG 前言：目前下述的代码都基于Langchain 0.1的版本进行，目前Langchain已经更新到0.2，还有在构建RAG应用的时候还是不要过分依赖框架，降低灵活性，这有时候会让你的工程开发陷入被动！
首先先介绍一下最简单的RAG的流程，其主要的流程如下图所示：
将知识库文本拆分为块，然后使用一些Transformer Encoder模型将这些块嵌入向量中，将所有这些向量放入索引中，最后为LLM创建一个提示，告诉模型根据我们在搜索步骤中发现的上下文，回答用户的查询。
在运行时，我们使用相同的编码器模型矢量化用户的查询，然后针对索引执行此查询矢量的搜索，找到top-k结果，从我们的数据库中检索相应的文本块，并将其作为上下文输入LLM提示符。
示例的RAG提示词模版如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 英文提示词 prompt_template = &amp;#34;&amp;#34;&amp;#34;Give the answer to the user query delimited by triple backticks ```{query}```\ using the information given in context delimited by triple backticks ```{context}```.\ If there is no relevant information in the provided context, try to answer yourself, but tell user that you did not have any relevant context to base your answer on.</description>
    </item>
    
    <item>
      <title>Document-AI: 使用模型工具处理非结构化、复杂的各类文档</title>
      <link>https://caixiongjiang.github.io/blog/2024/rag/document_ai/</link>
      <pubDate>Tue, 06 Aug 2024 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2024/rag/document_ai/</guid>
      <description>Document-AI 随着RAG的爆火，目前市面上出现了许多做文档解析的工具，它们相比传统的文档解析，增加了许多非结构化数据的读取和识别。现在我将会介绍几款目前市面上比较火的工具。
Datalab开源工具 Datalab目前开源了三款免费使用的工具，不过12个月内超过500w美元收入的组织进行商业使用时需要收费。旗下有三款文档解析工具，分别是Surya、Texify、Marker。
Datalab门户：https://www.datalab.to
Surya Surya是一个文档OCR工具包，它可以胜任：
90多种语言的OCR，与云服务相比，具有良好的基准 任何语言的行级文本检测 布局分析（表、图像、标题等检测） 阅读顺序检测 官方Github:https://github.com/VikParuchuri/surya
下载
首先下载好Python3.9+和Pytorch环境，然后再安装surya-ocr。
1 2 3 4 5 conda create -n parser python=3.10 conda activate parser # 我这里使用的 MacOS 系统 pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pip install surya-ocr OCR（文本识别）
命令行执行： 1 surya_ocr DATA_PATH --images --langs hi,en 常用参数说明：
DATA_PATH可以是图片，pdf，或者是包含图片和pdf的文件夹 --langs用于指定OCR的语言，可以通过逗号指定多种语言，但不建议同时超过4种。这里使用语言名称或双字母ISO代码来指定。语言相关的ISO代码查询：https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes --lang_file可以为不同的pdf/图像分别使用不同的语言，可以通过该参数自行指定语言。格式为JSON dict，键为文件名，值为列表，如{&amp;quot;file1.pdf&amp;quot;: [&amp;quot;en&amp;quot;, &amp;quot;hi&amp;quot;], &amp;quot;file2.pdf&amp;quot;: [&amp;quot;en&amp;quot;]}。 --images参数将保存页面的图像和检测到的文本行（可选） --results_dir参数指定要保存结果的目录 --max参数指定要处理的最大页数 --start_page参数指定要开始处理的页码 结果results.json文件的格式说明，其中key是没有扩展名（.pdf）的输入文件名。每个value将会是一个字典列表，输入文档每页一个，每页字典都包含：
text_lines - 每行检测到的文本和边界框 text - 行中的文本 confidence - 检测到的文本中的模型置信度（0～1） polygon -（x1，y1），（x2，y2），（x3，y3），（x4，y4）格式的文本行的多边形。这些点从左上角按顺时针顺序排列。 bbox - 文本行（x1，y1，x2，y2）格式的轴对齐矩形。（x1，y1）是左上角，（x2，y2）是右下角。 language - 该页面指定的语言 page - 文件中的页码 image_bbox - （X1，y1，x2，y2）格式的图像的bbox。（x1，y1）是左上角，（x2，y2）是右下角。所有行bbox都将包含在这个bbox中。 结果示例：</description>
    </item>
    
  </channel>
</rss>
