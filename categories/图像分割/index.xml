<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>图像分割 on 🌀Jarson Cai&#39;s Blog</title>
    <link>https://caixiongjiang.github.io/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/</link>
    <description>Recent content in 图像分割 on 🌀Jarson Cai&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 09 Sep 2022 18:18:05 +0800</lastBuildDate><atom:link href="https://caixiongjiang.github.io/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>充分利用你的显存，智能调节学习率</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%E4%BD%A0%E7%9A%84%E6%98%BE%E5%AD%98/</link>
      <pubDate>Fri, 09 Sep 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%E4%BD%A0%E7%9A%84%E6%98%BE%E5%AD%98/</guid>
      <description>一些新手比较容易踩的坑 batch_size 大小设置 先讲batch_size的功效：
增大batch_size的大小，可以加快训练速度 增大batch_size的大小，可以使得你使用的batch normalization更稳定，训练效果最好。 副作用：
batch_size越大，需要的显存就越大 相信所有人都经历过cuda out of memory报错，让人很心烦！那原因真的一定是batch_size过大吗？
第一种情况，是在验证的时候，没有加with torch.no_grad()，在验证的时候是不需要梯度反向传播的！ 第二种情况是确实模型太大，超显存了。 相信小伙伴都遇到过第三种情况：你设batch_size为2还报out of memory，任务管理器里明明显示还有很多显存，那就需要注意你的num_worker数量了。 如果你的num_worker比较大的话，cpu多线程读取图片的速度是快于你的GPU速度的，这时候会增加你的显存。这和你的GPU以及CPU的性能都是有关的，需要合理设置！ 学习率设置 学习率设置太大，容易让模型训练不动 batch_size调大之后，学习率是需要相应调大的 调参的时候通常使用大的学习率先开始训练，如果模型收敛不了再调更小 训练的时候一般采用学习率衰减的方法防止过拟合，一般使用step步进或者是模拟余弦退火算法来控制学习率大小。 </description>
    </item>
    
    <item>
      <title>图像分割之迁移学习</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 02 Sep 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</guid>
      <description>Unet，Attention_Unet网络修改之替换主干网络 对于算力有限的机器来说，从零开始训练实际效果并不好。使用迁移学习的预训练权重对于缺少参数调优的机器的炼丹人是非常重要的！
为了使用预训练权重，就需要将特征提取网络替换成知名的主干网络，比如VGG，Resnet，mobilenet等
Unet的修改——特征提取网络替换成VGG Unet论文地址：https://arxiv.org/abs/1505.04597
为了使替换主干网络后，保持维度匹配，需要对网络结构进行修改。所以我重构了网络结构图：
代码如下：
vgg.py:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 import torch.</description>
    </item>
    
    <item>
      <title>图像分割的边角料</title>
      <link>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E8%BE%B9%E8%A7%92%E6%96%99%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Sun, 21 Aug 2022 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E8%BE%B9%E8%A7%92%E6%96%99%E7%9F%A5%E8%AF%86/</guid>
      <description>图像分割中的上采样方法 反最大池化的方法 在下采样中，我们通常采用最大池化的方法来进行。那么对应在上采样中，反最大池化的方法其实就是记住最大池化时得到像素在原图中的位置，将其他位置填充为0。如图所示：
最早的SegNet所使用的上采样就是这种方式！
转置卷积 第二种方法就是转置卷积,这种方法和前面的反最大池化方法的最大区别就是转置卷积的参数是可以用于学习训练的，它不是一个固定的策略！
这个图可能看的不是很准确，想看动图的可以访问PyTorch官方给出的动图
以3$\times$3的卷积核将2$\times$2变为4$\times$4的图像为例（没有填充，没有步幅）：
1.第一步就是要将2$\times$2的图像使用零padding成为一个6$\times$6（4+2*1得到）的图像
2.对该填充后的图像做3$\times$3的卷积，得到输出图像
在深度学习的论文中，出现反卷积/跨步卷积/上卷积其实指的就是这种转置卷积。
放一张一维的图用于理解：
指标计算 基本指标 在图像分割中的基本指标通常包括Global Acc、mean Acc、MIOU,``等指标。
Global Acc(Pixel Acc) = $\frac{\sum_in_{ii}}{t_i}$
mean Acc = $\frac{1}{n_{cls}}\sum_i\frac{n_{ii}}{t_i}$
MIOU = $\frac{1}{n_{cls}}\sum_i\frac{n_{ii}}{t_i+\sum_jn_{ji}-n_{ii}}$
$n_{ij}$:类别i被预测成为类别j的像素个数
$n_{cls}$:目标类别个数（包含背景）
$t_i=\sum_jn_{ij}$:目标类别i的总像素个数（真实标签）
通过混淆矩阵理解指标 直接看下面三个图就可以理解了：
实操 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 &amp;#39;&amp;#39;&amp;#39; 混淆矩阵 Recall、Precision、MIOU计算 &amp;#39;&amp;#39;&amp;#39; import numpy as np from sklearn.</description>
    </item>
    
  </channel>
</rss>
