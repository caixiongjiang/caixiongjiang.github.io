<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>推理框架 on 🌀Jarson Cai&#39;s Blog</title>
    <link>https://caixiongjiang.github.io/series/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/</link>
    <description>Recent content in 推理框架 on 🌀Jarson Cai&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Aug 2023 18:18:05 +0800</lastBuildDate><atom:link href="https://caixiongjiang.github.io/series/%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>从零自制深度学习推理框架</title>
      <link>https://caixiongjiang.github.io/blog/2023/hpc/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Tue, 01 Aug 2023 18:18:05 +0800</pubDate>
      
      <guid>https://caixiongjiang.github.io/blog/2023/hpc/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/</guid>
      <description>KuiperDatawhale 本次课程为KuiperInfer的子项目（学习项目）。
完整推理框架项目地址：https://github.com/zjhellofss/kuiperInfer
B站课程地址：https://www.bilibili.com/video/BV118411f7yM/?spm_id_from=333.788&amp;amp;vd_source=841bd3506b40b195573d34fef4c5bdf7
本人学习项目地址：https://github.com/caixiongjiang/HPC
一：环境搭建 推理框架要完成的功能
对已经训练完成的神经网络模型文件进行加载 根据网络结构和权重参数对输入图像进行预测 推理阶段的权重已经固定，不需要后向传播技术 推理框架的模块
Operator:深度学习计算图中的计算节点，包含： 存储输入输出的张量 计算节点的类型和名称 计算节点参数信息（Params：卷积的步长，卷积核的大小等） 计算节点的权重信息（attributes：存储weights和bias） Graph:多个Operator串联得到的有向无环图，规定了各个节点（Operator）执行的流程和顺序。 Layer:计算节点运算具体的执行者，Layer类先读入输入张量中的数据，然后对输入张量进行计算，不同的算子中Layer的计算过程会不一致！ Tensor：用于存放多维数据的数据结构，方便数据在计算节点之间传递，同时该结构也封装矩阵乘、点积等与矩阵相关的基本操作。 使用的模块
C++运算库：Armadillo+OpenBLAS。
算子加速：OpenMP
单元测试：Google Test
性能测试：Google Benchmark
作业：完成测试用例
目的是了解Armadillo数学库的基本用法。
二：张量的设计与实现 张量类的设计
这里在arma::fmat和arma::fcube的基础上进行开发，f代表float，fcube可以看做是fmat的堆叠而成的结构。
与Pytorch中的矩阵存储不同的是，fmat是列主序的，需要进行区分。
张量类的方法
创建张量以及返回张量的维度信息：主要有4个属性，rows，cols，channels，raw_shapes。 其中创建的方法调用了fcube的创建方法：arma::fcube(rows, cols, channels)。返回维度信息的方法分别是rows()，cols()，channels()，size()。
张量的填充方法（Fill）：需要注意转置的过程（列主序和行主序的区别） 对张量进行变形（Reshape） 返回是否为空（empty） 作业为实现Flatten和Padding方法
Flatten:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void Tensor&amp;lt;float&amp;gt;::Flatten(bool row_major) { CHECK(!</description>
    </item>
    
  </channel>
</rss>
